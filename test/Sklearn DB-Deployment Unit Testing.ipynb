{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'sklearn model deployment' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "from splicemachine.spark import PySpliceContext\n",
    "from splicemachine.mlflow_support.utilities import get_user\n",
    "from splicemachine.mlflow_support import *\n",
    "\n",
    "splice = PySpliceContext(spark)\n",
    "mlflow.set_experiment('sklearn model deployment')\n",
    "mlflow.register_splice_context(splice)\n",
    "schema = get_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<font size=\"+1\"><a target=\"_blank\" href=/mlflow/#/experiments/0>MLFlow UI</a></font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"700px\"\n",
       "            src=\"/mlflow/#/experiments/0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5079d704d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splicemachine.notebook import *\n",
    "get_mlflow_ui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving artifact of size: 0.988 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated Parameter 'verbose'. Use mlflow.watch_job(<job id>) or mlflow.fetch_logs(<job id>) to get verbose output. Ignoring...\n",
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "---Job Logs---\n",
      "INFO     2020-09-14 18:21:58.582 - A service worker has found your request\n",
      "INFO     2020-09-14 18:21:58.605 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-09-14 18:21:58.642 - Handler is available\n",
      "INFO     2020-09-14 18:21:58.657 - Retrieving Run from MLFlow Tracking Server...INFO     2020-09-14 18:21:58.657 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-09-14 18:21:58.742 - Retrieved MLFlow Run\n",
      "INFO     2020-09-14 18:21:58.756 - Updating MLFlow Run for the UI\n",
      "INFO     2020-09-14 18:21:58.791 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-09-14 18:21:58.804 - Extracting Model from DB with Name: regression_model\n",
      "INFO     2020-09-14 18:21:58.831 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-09-14 18:21:58.895 - Decompressing Model Artifact\n",
      "INFO     2020-09-14 18:21:58.911 - Creating raw model representation from MLModel\n",
      "INFO     2020-09-14 18:21:58.924 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-09-14 18:21:58.941 - Registering Raw Model Representation...\n",
      "INFO     2020-09-14 18:21:58.955 - Done.\n",
      "INFO     2020-09-14 18:21:58.968 - Adding Model Schema and DF...\n",
      "INFO     2020-09-14 18:21:59.012 - Creating Alternative Scikit Representations\n",
      "INFO     2020-09-14 18:21:59.026 - Registering Serialized Representation\n",
      "INFO     2020-09-14 18:21:59.066 - Updating Artifact with serialized representation\n",
      "INFO     2020-09-14 18:21:59.080 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-09-14 18:21:59.093 - Prepare Scikit-learn metadata for deployment\n",
      "INFO     2020-09-14 18:21:59.107 - Adding Schema String to model metadata...\n",
      "INFO     2020-09-14 18:21:59.127 - Starting 'creating model deployment table'...\n",
      "INFO     2020-09-14 18:21:59.170 - Executing\n",
      "CREATE TABLE ben.sk_regression (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT 'a56168571fda',\n",
      "                col1 BIGINT, col2 BIGINT,MOMENT_KEY INT,PREDICTION DOUBLE,PRIMARY KEY(MOMENT_KEY))                col1 BIGINT, col2 BIGINT,MOMENT_KEY INT,PREDICTION DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-09-14 18:22:00.008 - Done with 'creating model deployment table' [in 880.913496017456 ms]\n",
      "INFO     2020-09-14 18:22:00.021 - Starting 'creating trigger'...\n",
      "INFO     2020-09-14 18:22:00.034 - Creating Prediction Trigger...\n",
      "INFO     2020-09-14 18:22:00.046 - Executing\n",
      "CREATE TRIGGER ben.runModel_sk_regression_a56168571fda\n",
      "                           BEFORE INSERT ON ben.sk_regression REFERENCING NEW AS NEWROW \n",
      "                           FOR EACH ROW SET NEWROW.PREDICTION=MLMANAGER.PREDICT_REGRESSION('a56168571fda',TRIM(CAST(NEWROW.COL1 as CHAR(41)))||','||TRIM(CAST(NEWROW.COL2 as CHAR(41))),\n",
      "'col1 BIGINT, col2 BIGINT')\n",
      "INFO     2020-09-14 18:22:00.199 - Done with 'creating trigger' [in 178.10988426208496 ms]\n",
      "INFO     2020-09-14 18:22:00.212 - Starting 'add model to metadata table'...\n",
      "INFO     2020-09-14 18:22:00.224 - Adding Model to Metadata table\n",
      "INFO     2020-09-14 18:22:00.315 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-09-14 18:22:00.368 - Done executing.\n",
      "INFO     2020-09-14 18:22:00.381 - Done with 'add model to metadata table' [in 168.75696182250977 ms]\n",
      "INFO     2020-09-14 18:22:00.393 - Flushing\n",
      "WARNING  2020-09-14 18:22:00.406 - Committing Transaction to Database\n",
      "INFO     2020-09-14 18:22:00.443 - Committed.\n",
      "INFO     2020-09-14 18:22:00.456 - Cleaning up deployment\n",
      "INFO     2020-09-14 18:22:00.497 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-09-14 18:22:00.523 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Data\n",
    "d = {'col1': [1, 2], 'col2': [3, 4], 'y': [0.2, 5.3]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df\n",
    "# Model\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(df[['col1', 'col2']], df['y'])\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='regression')\n",
    "mlflow.log_model(reg, 'regression_model')\n",
    "splice.execute(f'drop table if exists {schema}.sk_regression')\n",
    "jid = mlflow.deploy_db(schema, 'sk_regression', mlflow.current_run_id(), primary_key=[('MOMENT_KEY', 'INT')], df=df[['col1', 'col2']],create_model_table=True, verbose=True)\n",
    "mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0cc4b66-54df-46e8-8b62-013e4b520797",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be31e85d-4eb4-4edc-8537-d9f948e3da74",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c150715-4828-4815-96eb-51d5a51c66f3",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "insert into sk_regression (col1, col2, moment_key) values(1,5,4347861);\n",
    "insert into sk_regression (col1, col2, moment_key) values(2,7,4908084);\n",
    "select * from sk_regression;\n",
    "select col1, col2, prediction into ${data_and_preds} from sk_regression;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    c1, c2, p = row\n",
    "    raw_p = reg.predict([[float(c1),float(c2)]])[0]\n",
    "    assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving artifact of size: 1.245 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated Parameter 'verbose'. Use mlflow.watch_job(<job id>) or mlflow.fetch_logs(<job id>) to get verbose output. Ignoring...\n",
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "---Job Logs---\n",
      "INFO     2020-09-14 18:22:49.832 - A service worker has found your request\n",
      "INFO     2020-09-14 18:22:49.854 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-09-14 18:22:49.884 - Handler is available\n",
      "INFO     2020-09-14 18:22:49.899 - Retrieving Run from MLFlow Tracking Server...INFO     2020-09-14 18:22:49.899 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-09-14 18:22:49.987 - Retrieved MLFlow Run\n",
      "INFO     2020-09-14 18:22:50.000 - Updating MLFlow Run for the UI\n",
      "INFO     2020-09-14 18:22:50.035 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-09-14 18:22:50.048 - Extracting Model from DB with Name: bayesian_model\n",
      "INFO     2020-09-14 18:22:50.073 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-09-14 18:22:50.141 - Decompressing Model Artifact\n",
      "INFO     2020-09-14 18:22:50.156 - Creating raw model representation from MLModel\n",
      "INFO     2020-09-14 18:22:50.170 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-09-14 18:22:50.187 - Registering Raw Model Representation...\n",
      "INFO     2020-09-14 18:22:50.200 - Done.\n",
      "INFO     2020-09-14 18:22:50.213 - Adding Model Schema and DF...\n",
      "INFO     2020-09-14 18:22:50.252 - Creating Alternative Scikit Representations\n",
      "INFO     2020-09-14 18:22:50.266 - Registering Serialized Representation\n",
      "INFO     2020-09-14 18:22:50.300 - Updating Artifact with serialized representation\n",
      "INFO     2020-09-14 18:22:50.313 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-09-14 18:22:50.326 - Prepare Scikit-learn metadata for deployment\n",
      "INFO     2020-09-14 18:22:50.339 - Found predict arguments... classes are ['prediction', 'std']\n",
      "INFO     2020-09-14 18:22:50.353 - Adding Schema String to model metadata...\n",
      "INFO     2020-09-14 18:22:50.371 - Starting 'creating model deployment table'...\n",
      "INFO     2020-09-14 18:22:50.418 - Executing\n",
      "CREATE TABLE ben.sk_bayesian (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT 'ddef00ebc8ba',\n",
      "                col1 BIGINT, col2 BIGINT,MOMENT_KEY INT,\"prediction\" DOUBLE,\"std\" DOUBLE,PRIMARY KEY(MOMENT_KEY))                col1 BIGINT, col2 BIGINT,MOMENT_KEY INT,\"prediction\" DOUBLE,\"std\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-09-14 18:22:51.249 - Done with 'creating model deployment table' [in 877.6230812072754 ms]\n",
      "INFO     2020-09-14 18:22:51.262 - Starting 'creating trigger'...\n",
      "INFO     2020-09-14 18:22:51.275 - Creating VTI Prediction Trigger...\n",
      "INFO     2020-09-14 18:22:51.290 - Managing Sklearn prediction args\n",
      "INFO     2020-09-14 18:22:51.302 - Executing\n",
      "CREATE TRIGGER ben.runModel_sk_bayesian_ddef00ebc8ba \n",
      "                        AFTER INSERT ON ben.sk_bayesian REFERENCING NEW AS NEWROW FOR EACH ROW\n",
      "                        UPDATE ben.sk_bayesian SET (\"prediction\",\"std\") = (SELECT b.\"prediction\",b.\"std\" FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', 'ddef00ebc8ba', TRIM(CAST(NEWROW.COL1 as CHAR(41)))||','||TRIM(CAST(NEWROW.COL2 as CHAR(41))), \n",
      "        'col1 BIGINT, col2 BIGINT', 'predict', 'return_std') as b (\"prediction\" INT,\"std\" DOUBLE) WHERE 1=1) WHERE MOMENT_KEY = NEWROW.MOMENT_KEY\n",
      "INFO     2020-09-14 18:22:51.596 - Done with 'creating trigger' [in 333.568811416626 ms]\n",
      "INFO     2020-09-14 18:22:51.610 - Starting 'add model to metadata table'...\n",
      "INFO     2020-09-14 18:22:51.623 - Adding Model to Metadata table\n",
      "INFO     2020-09-14 18:22:51.709 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-09-14 18:22:51.758 - Done executing.\n",
      "INFO     2020-09-14 18:22:51.772 - Done with 'add model to metadata table' [in 162.16564178466797 ms]\n",
      "INFO     2020-09-14 18:22:51.785 - Flushing\n",
      "WARNING  2020-09-14 18:22:51.800 - Committing Transaction to Database\n",
      "INFO     2020-09-14 18:22:51.836 - Committed.\n",
      "INFO     2020-09-14 18:22:51.850 - Cleaning up deployment\n",
      "INFO     2020-09-14 18:22:51.891 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-09-14 18:22:51.914 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "import pandas as pd\n",
    "# Data\n",
    "d = {'col1': [1, 2], 'col2': [3, 4], 'y': [0.2, 5.3]}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "# Model\n",
    "model = BayesianRidge(compute_score=True,normalize = True)\n",
    "model.fit(df[['col1', 'col2']], df['y'])\n",
    "x = model.predict([[1,2]], return_std=True)\n",
    "\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='bayesian with std')\n",
    "mlflow.log_model(model, 'bayesian_model')\n",
    "splice.execute(f'drop table if exists {schema}.sk_bayesian')\n",
    "jid = mlflow.deploy_db(schema, 'sk_bayesian', mlflow.current_run_id(), primary_key=[('MOMENT_KEY', 'INT')], df=df[['col1', 'col2']], create_model_table=True, verbose=True, library_specific={'predict_call':'predict', 'predict_args':'return_std'})\n",
    "mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3552a6c7-f8b5-4542-a693-9748587498e3",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ea02a1-6012-48dd-adb4-fc06b32d97d8",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48314d73-6634-4ce5-b2e8-048a3c127fec",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b094f21d-4fa3-4a82-885c-2e245c5322d8",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 ms, sys: 3.28 ms, total: 15.4 ms\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%sql\n",
    "\n",
    "insert into sk_bayesian (col1, col2, moment_key) values(-4,-5,1);\n",
    "insert into sk_bayesian (col1, col2, moment_key) values(100,22,2);\n",
    "insert into sk_bayesian (col1, col2, moment_key) values(7,8,3);\n",
    "\n",
    "select * from sk_bayesian;\n",
    "select col1, col2, \"prediction\", \"std\" into ${data_and_preds} from sk_bayesian;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    c1, c2, p, std = row\n",
    "    raw_p, raw_std = model.predict([[float(c1),float(c2)]], return_std=True)\n",
    "    assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "    assert raw_std == std, f'Something is wrong. Model Table gives {std} but raw model gives {raw_std}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Bayesian model into existing table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a72993-1cb6-434f-9e53-e9c8909bee32",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d64ade-ea1e-4ca7-b5c7-90e1cb675b66",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c419eb29-8455-41c5-97ad-10b28b80d3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc0681b-958e-4485-a00a-93f1c401bcb3",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c314e257-5ea4-4aa0-8460-e734989f0d62",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "drop table if exists bayesian_table;\n",
    "create table bayesian_table(col1 int, col2 int, moment_key int primary key);\n",
    "insert into bayesian_table values(4,2,1);\n",
    "insert into bayesian_table values(9,8,7);\n",
    "select * from bayesian_table;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated Parameter 'verbose'. Use mlflow.watch_job(<job id>) or mlflow.fetch_logs(<job id>) to get verbose output. Ignoring...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "---Job Logs---\n",
      "INFO     2020-09-14 18:23:23.555 - A service worker has found your request\n",
      "INFO     2020-09-14 18:23:23.580 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-09-14 18:23:23.617 - Handler is available\n",
      "INFO     2020-09-14 18:23:23.632 - Retrieving Run from MLFlow Tracking Server...INFO     2020-09-14 18:23:23.632 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-09-14 18:23:23.708 - Retrieved MLFlow Run\n",
      "INFO     2020-09-14 18:23:23.728 - Updating MLFlow Run for the UIINFO     2020-09-14 18:23:23.728 - Updating MLFlow Run for the UI\n",
      "INFO     2020-09-14 18:23:25.878 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-09-14 18:23:25.891 - Extracting Model from DB with Name: bayesian_model\n",
      "INFO     2020-09-14 18:23:25.911 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-09-14 18:23:25.973 - Decompressing Model Artifact\n",
      "INFO     2020-09-14 18:23:25.989 - Creating raw model representation from MLModel\n",
      "INFO     2020-09-14 18:23:26.004 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-09-14 18:23:26.022 - Registering Raw Model Representation...INFO     2020-09-14 18:23:26.022 - Registering Raw Model Representation...\n",
      "INFO     2020-09-14 18:23:26.035 - Done.\n",
      "INFO     2020-09-14 18:23:26.338 - Creating Alternative Scikit Representations\n",
      "INFO     2020-09-14 18:23:26.352 - Registering Serialized Representation\n",
      "INFO     2020-09-14 18:23:26.381 - Updating Artifact with serialized representation\n",
      "INFO     2020-09-14 18:23:26.394 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-09-14 18:23:26.408 - Prepare Scikit-learn metadata for deployment\n",
      "INFO     2020-09-14 18:23:26.424 - Found predict arguments... classes are ['prediction', 'std']\n",
      "INFO     2020-09-14 18:23:26.437 - Adding Schema String to model metadata...\n",
      "INFO     2020-09-14 18:23:26.454 - Starting 'altering existing table'...\n",
      "INFO     2020-09-14 18:23:26.467 - Altering existing model...\n",
      "INFO     2020-09-14 18:23:26.722 - Executing\n",
      "ALTER TABLE ben.bayesian_table ADD COLUMN CUR_USER VARCHAR(50) DEFAULT CURRENT_USER)\n",
      "INFO     2020-09-14 18:23:26.876 - Executing\n",
      "ALTER TABLE ben.bayesian_table ADD COLUMN EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP)\n",
      "INFO     2020-09-14 18:23:27.040 - Executing\n",
      "ALTER TABLE ben.bayesian_table ADD COLUMN RUN_ID VARCHAR(50) DEFAULT 'ddef00ebc8ba')ALTER TABLE ben.bayesian_table ADD COLUMN RUN_ID VARCHAR(50) DEFAULT 'ddef00ebc8ba')\n",
      "INFO     2020-09-14 18:23:27.220 - Executing\n",
      "ALTER TABLE ben.bayesian_table ADD COLUMN \"prediction\" DOUBLE)\n",
      "INFO     2020-09-14 18:23:27.334 - Executing\n",
      "ALTER TABLE ben.bayesian_table ADD COLUMN \"std\" DOUBLE)\n",
      "INFO     2020-09-14 18:23:27.450 - Done with 'altering existing table' [in 995.654821395874 ms]\n",
      "INFO     2020-09-14 18:23:27.463 - Starting 'creating trigger'...\n",
      "INFO     2020-09-14 18:23:27.477 - Creating VTI Prediction Trigger...\n",
      "INFO     2020-09-14 18:23:27.489 - Managing Sklearn prediction args\n",
      "INFO     2020-09-14 18:23:27.502 - Executing\n",
      "CREATE TRIGGER ben.runModel_bayesian_table_ddef00ebc8ba \n",
      "                        AFTER INSERT ON ben.bayesian_table REFERENCING NEW AS NEWROW FOR EACH ROW\n",
      "                        UPDATE ben.bayesian_table SET (\"prediction\",\"std\") = (SELECT b.\"prediction\",b.\"std\" FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', 'ddef00ebc8ba', TRIM(CAST(NEWROW.COL1 as CHAR(41)))||','||TRIM(CAST(NEWROW.COL2 as CHAR(41))), \n",
      "        'COL1 INTEGER, COL2 INTEGER', 'predict', 'return_std') as b (\"prediction\" INT,\"std\" DOUBLE) WHERE 1=1) WHERE MOMENT_KEY = NEWROW.MOMENT_KEY\n",
      "INFO     2020-09-14 18:23:27.794 - Done with 'creating trigger' [in 330.9202194213867 ms]\n",
      "INFO     2020-09-14 18:23:27.807 - Starting 'add model to metadata table'...\n",
      "INFO     2020-09-14 18:23:27.821 - Adding Model to Metadata table\n",
      "INFO     2020-09-14 18:23:27.917 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-09-14 18:23:27.971 - Done executing.\n",
      "INFO     2020-09-14 18:23:27.984 - Done with 'add model to metadata table' [in 176.32055282592773 ms]\n",
      "INFO     2020-09-14 18:23:27.995 - Flushing\n",
      "WARNING  2020-09-14 18:23:28.009 - Committing Transaction to Database\n",
      "INFO     2020-09-14 18:23:28.085 - Committed.\n",
      "INFO     2020-09-14 18:23:28.099 - Cleaning up deployment\n",
      "INFO     2020-09-14 18:23:28.138 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-09-14 18:23:28.159 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "run_id = mlflow.get_run_ids_by_name('bayesian with std')[0]\n",
    "jid = mlflow.deploy_db(schema, 'bayesian_table', run_id, verbose=True, model_cols=['COL1','COL2'], library_specific={'predict_call':'predict', 'predict_args':'return_std'})\n",
    "mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 2 rows should have <b>NO</b> values for prediction and std (we inserted those rows before model deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb97b05-9347-49a4-af0e-4a095787ce64",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b677507e-8806-4518-ac25-1a581f076240",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c984c5a-51bb-4cb9-93d9-207de8aaef9e",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d26c39-637e-461f-8c1b-7bb9f5bcf2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 ms, sys: 6.37 ms, total: 18.6 ms\n",
      "Wall time: 3.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%sql\n",
    "\n",
    "insert into bayesian_table (col1, col2, moment_key) values(4,5,20);\n",
    "insert into bayesian_table (col1, col2, moment_key) values(-4,-5,21);\n",
    "insert into bayesian_table (col1, col2, moment_key) values(7,8,22);\n",
    "\n",
    "select * from bayesian_table;\n",
    "select col1, col2, \"prediction\", \"std\" into ${data_and_preds} from bayesian_table;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    c1, c2, p, std = row\n",
    "    if index in (0, 1):\n",
    "        assert math.isnan(p), f\"Something is wrong. prediction should be NaN for the first 2 rows but has value {p}\"\n",
    "        assert math.isnan(std), f\"Something is wrong. std should be NaN for the first 2 rows but has value {std}\"\n",
    "    else:\n",
    "        raw_p, raw_std = model.predict([[float(c1),float(c2)]], return_std=True)\n",
    "        assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "        assert raw_std == std, f'Something is wrong. Model Table gives {std} but raw model gives {raw_std}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM Model\n",
    "## GMM with Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving artifact of size: 3.971 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated Parameter 'verbose'. Use mlflow.watch_job(<job id>) or mlflow.fetch_logs(<job id>) to get verbose output. Ignoring...\n",
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "---Job Logs---\n",
      "INFO     2020-09-14 18:24:01.531 - A service worker has found your request\n",
      "INFO     2020-09-14 18:24:01.551 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-09-14 18:24:01.577 - Handler is available\n",
      "INFO     2020-09-14 18:24:01.590 - Retrieving Run from MLFlow Tracking Server...INFO     2020-09-14 18:24:01.590 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-09-14 18:24:01.660 - Retrieved MLFlow Run\n",
      "INFO     2020-09-14 18:24:01.674 - Updating MLFlow Run for the UI\n",
      "INFO     2020-09-14 18:24:01.706 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-09-14 18:24:01.719 - Extracting Model from DB with Name: gmm_model\n",
      "INFO     2020-09-14 18:24:01.741 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-09-14 18:24:01.761 - Decompressing Model Artifact\n",
      "INFO     2020-09-14 18:24:01.776 - Creating raw model representation from MLModel\n",
      "INFO     2020-09-14 18:24:01.788 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-09-14 18:24:01.814 - Registering Raw Model Representation...\n",
      "INFO     2020-09-14 18:24:01.826 - Done.\n",
      "INFO     2020-09-14 18:24:01.840 - Adding Model Schema and DF...\n",
      "INFO     2020-09-14 18:24:01.878 - Creating Alternative Scikit Representations\n",
      "INFO     2020-09-14 18:24:01.892 - Registering Serialized Representation\n",
      "INFO     2020-09-14 18:24:01.930 - Updating Artifact with serialized representation\n",
      "INFO     2020-09-14 18:24:01.944 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-09-14 18:24:01.956 - Prepare Scikit-learn metadata for deployment\n",
      "INFO     2020-09-14 18:24:01.969 - Found predict arguments... classes are ['prediction', 'std']\n",
      "INFO     2020-09-14 18:24:01.981 - Adding Schema String to model metadata...\n",
      "INFO     2020-09-14 18:24:02.000 - Starting 'creating model deployment table'...\n",
      "INFO     2020-09-14 18:24:02.044 - Executing\n",
      "CREATE TABLE ben.sk_gmm (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '4d7e03e3e259',\n",
      "                col1 BIGINT, col2 BIGINT,MOMENT_KEY INT,\"prediction\" DOUBLE,\"std\" DOUBLE,PRIMARY KEY(MOMENT_KEY))                col1 BIGINT, col2 BIGINT,MOMENT_KEY INT,\"prediction\" DOUBLE,\"std\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-09-14 18:24:02.874 - Done with 'creating model deployment table' [in 874.2201328277588 ms]\n",
      "INFO     2020-09-14 18:24:02.887 - Starting 'creating trigger'...\n",
      "INFO     2020-09-14 18:24:02.901 - Creating VTI Prediction Trigger...\n",
      "INFO     2020-09-14 18:24:02.913 - Managing Sklearn prediction args\n",
      "INFO     2020-09-14 18:24:02.926 - Executing\n",
      "CREATE TRIGGER ben.runModel_sk_gmm_4d7e03e3e259 \n",
      "                        AFTER INSERT ON ben.sk_gmm REFERENCING NEW AS NEWROW FOR EACH ROW\n",
      "                        UPDATE ben.sk_gmm SET (\"prediction\",\"std\") = (SELECT b.\"prediction\",b.\"std\" FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', '4d7e03e3e259', TRIM(CAST(NEWROW.COL1 as CHAR(41)))||','||TRIM(CAST(NEWROW.COL2 as CHAR(41))), \n",
      "        'col1 BIGINT, col2 BIGINT', 'predict', 'return_std') as b (\"prediction\" INT,\"std\" DOUBLE) WHERE 1=1) WHERE MOMENT_KEY = NEWROW.MOMENT_KEY\n",
      "INFO     2020-09-14 18:24:03.184 - Done with 'creating trigger' [in 296.61059379577637 ms]\n",
      "INFO     2020-09-14 18:24:03.196 - Starting 'add model to metadata table'...\n",
      "INFO     2020-09-14 18:24:03.207 - Adding Model to Metadata table\n",
      "INFO     2020-09-14 18:24:03.287 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-09-14 18:24:03.332 - Done executing.\n",
      "INFO     2020-09-14 18:24:03.347 - Done with 'add model to metadata table' [in 151.503324508667 ms]\n",
      "INFO     2020-09-14 18:24:03.360 - Flushing\n",
      "WARNING  2020-09-14 18:24:03.372 - Committing Transaction to Database\n",
      "INFO     2020-09-14 18:24:03.408 - Committed.\n",
      "INFO     2020-09-14 18:24:03.422 - Cleaning up deployment\n",
      "INFO     2020-09-14 18:24:03.464 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-09-14 18:24:03.487 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process.gpr import GaussianProcessRegressor\n",
    "# Data\n",
    "d = {'col1': [1, 2], 'col2': [3, 4], 'y': [0.2, 5.3]}\n",
    "df = pd.DataFrame(data=d)\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "\n",
    "# Model\n",
    "g = GaussianProcessRegressor()\n",
    "g.fit(df[['col1','col2']],df['y'])\n",
    "# print(g.predict([[5,5]],return_std=True))\n",
    "# print(g.predict([[5,5]],return_cov=True))\n",
    "\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='gmm with std')\n",
    "mlflow.log_model(g, 'gmm_model')\n",
    "splice.execute(f'drop table if exists {schema}.sk_gmm')\n",
    "jid = mlflow.deploy_db(schema, 'sk_gmm', mlflow.current_run_id(), df=df[['col1', 'col2']], primary_key=[('MOMENT_KEY', 'INT')], create_model_table=True, verbose=True, library_specific={'predict_call':'predict', 'predict_args':'return_std'})\n",
    "mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9f7e6a-7390-4e2a-872a-4698edc7cf81",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de03205a-5be7-48fd-a19f-3d15ce5fac34",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfca68c6-7638-4e98-b929-557e18d4d2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb674ec-5bfb-4945-bd57-c5f16efb24ea",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 ms, sys: 3.64 ms, total: 17.2 ms\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%sql\n",
    "\n",
    "insert into sk_gmm (col1,col2,moment_key) values(4,5,1);\n",
    "insert into sk_gmm (col1,col2,moment_key) values(-4,-5,2);\n",
    "insert into sk_gmm (col1,col2,moment_key) values(7,8,3);\n",
    "\n",
    "select * from sk_gmm;\n",
    "select col1, col2, \"prediction\", \"std\" into ${data_and_preds} from sk_gmm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    c1, c2, p, std = row\n",
    "    raw_p, raw_std = g.predict([[float(c1),float(c2)]], return_std=True)\n",
    "    assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "    assert raw_std == std, f'Something is wrong. Model Table gives {std} but raw model gives {raw_std}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM with Covarience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving artifact of size: 3.971 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated Parameter 'verbose'. Use mlflow.watch_job(<job id>) or mlflow.fetch_logs(<job id>) to get verbose output. Ignoring...\n",
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "---Job Logs---\n",
      "INFO     2020-09-14 18:24:35.237 - A service worker has found your request\n",
      "INFO     2020-09-14 18:24:35.257 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-09-14 18:24:35.294 - Handler is available\n",
      "INFO     2020-09-14 18:24:35.308 - Retrieving Run from MLFlow Tracking Server...INFO     2020-09-14 18:24:35.308 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-09-14 18:24:35.382 - Retrieved MLFlow Run\n",
      "INFO     2020-09-14 18:24:35.394 - Updating MLFlow Run for the UI\n",
      "INFO     2020-09-14 18:24:35.425 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-09-14 18:24:35.438 - Extracting Model from DB with Name: gmm\n",
      "INFO     2020-09-14 18:24:35.460 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-09-14 18:24:35.478 - Decompressing Model Artifact\n",
      "INFO     2020-09-14 18:24:35.491 - Creating raw model representation from MLModel\n",
      "INFO     2020-09-14 18:24:35.504 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-09-14 18:24:35.521 - Registering Raw Model Representation...\n",
      "INFO     2020-09-14 18:24:35.534 - Done.\n",
      "INFO     2020-09-14 18:24:35.547 - Adding Model Schema and DF...\n",
      "INFO     2020-09-14 18:24:35.583 - Creating Alternative Scikit Representations\n",
      "INFO     2020-09-14 18:24:35.596 - Registering Serialized Representation\n",
      "INFO     2020-09-14 18:24:35.628 - Updating Artifact with serialized representation\n",
      "INFO     2020-09-14 18:24:35.642 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-09-14 18:24:35.655 - Prepare Scikit-learn metadata for deployment\n",
      "INFO     2020-09-14 18:24:35.668 - Found predict arguments... classes are ['prediction', 'cov']\n",
      "INFO     2020-09-14 18:24:35.681 - Adding Schema String to model metadata...\n",
      "INFO     2020-09-14 18:24:35.699 - Starting 'creating model deployment table'...\n",
      "INFO     2020-09-14 18:24:35.740 - Executing\n",
      "CREATE TABLE ben.sk_gmm_cov (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '877ff39e27a2',\n",
      "                col1 BIGINT, col2 BIGINT,MOMENT_KEY INT,\"prediction\" DOUBLE,\"cov\" DOUBLE,PRIMARY KEY(MOMENT_KEY))                col1 BIGINT, col2 BIGINT,MOMENT_KEY INT,\"prediction\" DOUBLE,\"cov\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-09-14 18:24:36.557 - Done with 'creating model deployment table' [in 858.2091331481934 ms]\n",
      "INFO     2020-09-14 18:24:36.569 - Starting 'creating trigger'...\n",
      "INFO     2020-09-14 18:24:36.581 - Creating VTI Prediction Trigger...\n",
      "INFO     2020-09-14 18:24:36.593 - Managing Sklearn prediction args\n",
      "INFO     2020-09-14 18:24:36.605 - Executing\n",
      "CREATE TRIGGER ben.runModel_sk_gmm_cov_877ff39e27a2 \n",
      "                        AFTER INSERT ON ben.sk_gmm_cov REFERENCING NEW AS NEWROW FOR EACH ROW\n",
      "                        UPDATE ben.sk_gmm_cov SET (\"prediction\",\"cov\") = (SELECT b.\"prediction\",b.\"cov\" FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', '877ff39e27a2', TRIM(CAST(NEWROW.COL1 as CHAR(41)))||','||TRIM(CAST(NEWROW.COL2 as CHAR(41))), \n",
      "        'col1 BIGINT, col2 BIGINT', 'predict', 'return_cov') as b (\"prediction\" INT,\"cov\" DOUBLE) WHERE 1=1) WHERE MOMENT_KEY = NEWROW.MOMENT_KEY\n",
      "INFO     2020-09-14 18:24:36.886 - Done with 'creating trigger' [in 316.7147636413574 ms]\n",
      "INFO     2020-09-14 18:24:36.899 - Starting 'add model to metadata table'...\n",
      "INFO     2020-09-14 18:24:36.912 - Adding Model to Metadata table\n",
      "INFO     2020-09-14 18:24:36.994 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-09-14 18:24:37.044 - Done executing.\n",
      "INFO     2020-09-14 18:24:37.056 - Done with 'add model to metadata table' [in 157.1183204650879 ms]\n",
      "INFO     2020-09-14 18:24:37.068 - Flushing\n",
      "WARNING  2020-09-14 18:24:37.081 - Committing Transaction to Database\n",
      "INFO     2020-09-14 18:24:37.116 - Committed.\n",
      "INFO     2020-09-14 18:24:37.130 - Cleaning up deployment\n",
      "INFO     2020-09-14 18:24:37.169 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-09-14 18:24:37.192 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process.gpr import GaussianProcessRegressor\n",
    "# Data\n",
    "d = {'col1': [1, 2], 'col2': [3, 4], 'y': [0.2, 5.3]}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "\n",
    "# Model\n",
    "g = GaussianProcessRegressor()\n",
    "g.fit(df[['col1','col2']],df['y'])\n",
    "# print(g.predict([[5,5]],return_std=True))\n",
    "# print(g.predict([[5,5]],return_cov=True))\n",
    "\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='gmm with cov')\n",
    "mlflow.log_model(g, 'gmm')\n",
    "splice.execute(f'drop table if exists {schema}.sk_gmm_cov')\n",
    "jid = mlflow.deploy_db(schema, 'sk_gmm_cov', mlflow.current_run_id(), df=df[['col1', 'col2']], primary_key=[('MOMENT_KEY', 'INT')], create_model_table=True, verbose=True, library_specific={'predict_call':'predict', 'predict_args':'return_cov'})\n",
    "mlflow.watch_job(jid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06abb663-9ca1-48ed-a00b-061dc0cfa455",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ad0595-99a9-474d-8544-9f89a97a4bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e795c6-b13d-4f4d-8bee-3f215bc02887",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b1d300-df03-475b-811f-7f161d0cf529",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 ms, sys: 3.79 ms, total: 14.9 ms\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%sql\n",
    "\n",
    "insert into sk_gmm_cov (col1,col2,moment_key) values(4,5,1);\n",
    "insert into sk_gmm_cov (col1,col2,moment_key) values(-4,-5,2);\n",
    "insert into sk_gmm_cov (col1,col2,moment_key) values(7,8,3);\n",
    "\n",
    "select * from sk_gmm_cov;\n",
    "select col1, col2, \"prediction\", \"cov\" into ${data_and_preds} from sk_gmm_cov;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    c1, c2, p, std = row\n",
    "    raw_p, raw_std = g.predict([[float(c1),float(c2)]], return_cov=True)\n",
    "    assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "    assert raw_std == std, f'Something is wrong. Model Table gives {std} but raw model gives {raw_std}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving artifact of size: 391.909 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated Parameter 'verbose'. Use mlflow.watch_job(<job id>) or mlflow.fetch_logs(<job id>) to get verbose output. Ignoring...\n",
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "---Job Logs---\n",
      "INFO     2020-09-14 18:25:03.585 - A service worker has found your request\n",
      "INFO     2020-09-14 18:25:03.606 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-09-14 18:25:03.632 - Handler is available\n",
      "INFO     2020-09-14 18:25:03.648 - Retrieving Run from MLFlow Tracking Server...INFO     2020-09-14 18:25:03.648 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-09-14 18:25:03.729 - Retrieved MLFlow Run\n",
      "INFO     2020-09-14 18:25:03.742 - Updating MLFlow Run for the UI\n",
      "INFO     2020-09-14 18:25:03.776 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-09-14 18:25:03.791 - Extracting Model from DB with Name: kpca\n",
      "INFO     2020-09-14 18:25:03.816 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-09-14 18:25:03.843 - Decompressing Model Artifact\n",
      "INFO     2020-09-14 18:25:03.862 - Creating raw model representation from MLModel\n",
      "INFO     2020-09-14 18:25:03.876 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-09-14 18:25:03.903 - Registering Raw Model Representation...\n",
      "INFO     2020-09-14 18:25:03.916 - Done.\n",
      "INFO     2020-09-14 18:25:03.929 - Adding Model Schema and DF...\n",
      "INFO     2020-09-14 18:25:03.965 - Creating Alternative Scikit Representations\n",
      "INFO     2020-09-14 18:25:03.978 - Registering Serialized Representation\n",
      "INFO     2020-09-14 18:25:04.057 - Updating Artifact with serialized representation\n",
      "INFO     2020-09-14 18:25:04.071 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-09-14 18:25:04.084 - Prepare Scikit-learn metadata for deployment\n",
      "INFO     2020-09-14 18:25:04.096 - Using transform operation with classes ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C27', 'C28', 'C29', 'C30', 'C31', 'C32', 'C33', 'C34', 'C35', 'C36', 'C37', 'C38', 'C39', 'C40', 'C41', 'C42', 'C43', 'C44', 'C45', 'C46', 'C47', 'C48', 'C49', 'C50', 'C51', 'C52', 'C53', 'C54', 'C55', 'C56', 'C57', 'C58', 'C59', 'C60', 'C61', 'C62', 'C63', 'C64', 'C65', 'C66', 'C67', 'C68', 'C69', 'C70', 'C71', 'C72', 'C73', 'C74', 'C75', 'C76', 'C77', 'C78', 'C79', 'C80', 'C81', 'C82', 'C83', 'C84', 'C85', 'C86', 'C87', 'C88', 'C89', 'C90', 'C91', 'C92', 'C93', 'C94', 'C95', 'C96', 'C97', 'C98', 'C99']\n",
      "INFO     2020-09-14 18:25:04.110 - Adding Schema String to model metadata...\n",
      "INFO     2020-09-14 18:25:04.132 - Starting 'creating model deployment table'...\n",
      "INFO     2020-09-14 18:25:04.175 - Executing\n",
      "CREATE TABLE ben.pca (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '66d3c2144716',\n",
      "                col1 FLOAT, col2 FLOAT, col3 FLOAT,MOMENT_KEY INT,\"C0\" DOUBLE,\"C1\" DOUBLE,\"C2\" DOUBLE,\"C3\" DOUBLE,\"C4\" DOUBLE,\"C5\" DOUBLE,\"C6\" DOUBLE,\"C7\" DOUBLE,\"C8\" DOUBLE,\"C9\" DOUBLE,\"C10\" DOUBLE,\"C11\" DOUBLE,\"C12\" DOUBLE,\"C13\" DOUBLE,\"C14\" DOUBLE,\"C15\" DOUBLE,\"C16\" DOUBLE,\"C17\" DOUBLE,\"C18\" DOUBLE,\"C19\" DOUBLE,\"C20\" DOUBLE,\"C21\" DOUBLE,\"C22\" DOUBLE,\"C23\" DOUBLE,\"C24\" DOUBLE,\"C25\" DOUBLE,\"C26\" DOUBLE,\"C27\" DOUBLE,\"C28\" DOUBLE,\"C29\" DOUBLE,\"C30\" DOUBLE,\"C31\" DOUBLE,\"C32\" DOUBLE,\"C33\" DOUBLE,\"C34\" DOUBLE,\"C35\" DOUBLE,\"C36\" DOUBLE,\"C37\" DOUBLE,\"C38\" DOUBLE,\"C39\" DOUBLE,\"C40\" DOUBLE,\"C41\" DOUBLE,\"C42\" DOUBLE,\"C43\" DOUBLE,\"C44\" DOUBLE,\"C45\" DOUBLE,\"C46\" DOUBLE,\"C47\" DOUBLE,\"C48\" DOUBLE,\"C49\" DOUBLE,\"C50\" DOUBLE,\"C51\" DOUBLE,\"C52\" DOUBLE,\"C53\" DOUBLE,\"C54\" DOUBLE,\"C55\" DOUBLE,\"C56\" DOUBLE,\"C57\" DOUBLE,\"C58\" DOUBLE,\"C59\" DOUBLE,\"C60\" DOUBLE,\"C61\" DOUBLE,\"C62\" DOUBLE,\"C63\" DOUBLE,\"C64\" DOUBLE,\"C65\" DOUBLE,\"C66\" DOUBLE,\"C67\" DOUBLE,\"C68\" DOUBLE,\"C69\" DOUBLE,\"C70\" DOUBLE,\"C71\" DOUBLE,\"C72\" DOUBLE,\"C73\" DOUBLE,\"C74\" DOUBLE,\"C75\" DOUBLE,\"C76\" DOUBLE,\"C77\" DOUBLE,\"C78\" DOUBLE,\"C79\" DOUBLE,\"C80\" DOUBLE,\"C81\" DOUBLE,\"C82\" DOUBLE,\"C83\" DOUBLE,\"C84\" DOUBLE,\"C85\" DOUBLE,\"C86\" DOUBLE,\"C87\" DOUBLE,\"C88\" DOUBLE,\"C89\" DOUBLE,\"C90\" DOUBLE,\"C91\" DOUBLE,\"C92\" DOUBLE,\"C93\" DOUBLE,\"C94\" DOUBLE,\"C95\" DOUBLE,\"C96\" DOUBLE,\"C97\" DOUBLE,\"C98\" DOUBLE,\"C99\" DOUBLE,PRIMARY KEY(MOMENT_KEY))                col1 FLOAT, col2 FLOAT, col3 FLOAT,MOMENT_KEY INT,\"C0\" DOUBLE,\"C1\" DOUBLE,\"C2\" DOUBLE,\"C3\" DOUBLE,\"C4\" DOUBLE,\"C5\" DOUBLE,\"C6\" DOUBLE,\"C7\" DOUBLE,\"C8\" DOUBLE,\"C9\" DOUBLE,\"C10\" DOUBLE,\"C11\" DOUBLE,\"C12\" DOUBLE,\"C13\" DOUBLE,\"C14\" DOUBLE,\"C15\" DOUBLE,\"C16\" DOUBLE,\"C17\" DOUBLE,\"C18\" DOUBLE,\"C19\" DOUBLE,\"C20\" DOUBLE,\"C21\" DOUBLE,\"C22\" DOUBLE,\"C23\" DOUBLE,\"C24\" DOUBLE,\"C25\" DOUBLE,\"C26\" DOUBLE,\"C27\" DOUBLE,\"C28\" DOUBLE,\"C29\" DOUBLE,\"C30\" DOUBLE,\"C31\" DOUBLE,\"C32\" DOUBLE,\"C33\" DOUBLE,\"C34\" DOUBLE,\"C35\" DOUBLE,\"C36\" DOUBLE,\"C37\" DOUBLE,\"C38\" DOUBLE,\"C39\" DOUBLE,\"C40\" DOUBLE,\"C41\" DOUBLE,\"C42\" DOUBLE,\"C43\" DOUBLE,\"C44\" DOUBLE,\"C45\" DOUBLE,\"C46\" DOUBLE,\"C47\" DOUBLE,\"C48\" DOUBLE,\"C49\" DOUBLE,\"C50\" DOUBLE,\"C51\" DOUBLE,\"C52\" DOUBLE,\"C53\" DOUBLE,\"C54\" DOUBLE,\"C55\" DOUBLE,\"C56\" DOUBLE,\"C57\" DOUBLE,\"C58\" DOUBLE,\"C59\" DOUBLE,\"C60\" DOUBLE,\"C61\" DOUBLE,\"C62\" DOUBLE,\"C63\" DOUBLE,\"C64\" DOUBLE,\"C65\" DOUBLE,\"C66\" DOUBLE,\"C67\" DOUBLE,\"C68\" DOUBLE,\"C69\" DOUBLE,\"C70\" DOUBLE,\"C71\" DOUBLE,\"C72\" DOUBLE,\"C73\" DOUBLE,\"C74\" DOUBLE,\"C75\" DOUBLE,\"C76\" DOUBLE,\"C77\" DOUBLE,\"C78\" DOUBLE,\"C79\" DOUBLE,\"C80\" DOUBLE,\"C81\" DOUBLE,\"C82\" DOUBLE,\"C83\" DOUBLE,\"C84\" DOUBLE,\"C85\" DOUBLE,\"C86\" DOUBLE,\"C87\" DOUBLE,\"C88\" DOUBLE,\"C89\" DOUBLE,\"C90\" DOUBLE,\"C91\" DOUBLE,\"C92\" DOUBLE,\"C93\" DOUBLE,\"C94\" DOUBLE,\"C95\" DOUBLE,\"C96\" DOUBLE,\"C97\" DOUBLE,\"C98\" DOUBLE,\"C99\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-09-14 18:25:05.642 - Done with 'creating model deployment table' [in 1510.1876258850098 ms]\n",
      "INFO     2020-09-14 18:25:05.655 - Starting 'creating trigger'...\n",
      "INFO     2020-09-14 18:25:05.667 - Creating VTI Prediction Trigger...\n",
      "INFO     2020-09-14 18:25:05.679 - Managing Sklearn prediction args\n",
      "INFO     2020-09-14 18:25:05.692 - Executing\n",
      "CREATE TRIGGER ben.runModel_pca_66d3c2144716 \n",
      "                        AFTER INSERT ON ben.pca REFERENCING NEW AS NEWROW FOR EACH ROW\n",
      "                        UPDATE ben.pca SET (\"C0\",\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\",\"C12\",\"C13\",\"C14\",\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\",\"C22\",\"C23\",\"C24\",\"C25\",\"C26\",\"C27\",\"C28\",\"C29\",\"C30\",\"C31\",\"C32\",\"C33\",\"C34\",\"C35\",\"C36\",\"C37\",\"C38\",\"C39\",\"C40\",\"C41\",\"C42\",\"C43\",\"C44\",\"C45\",\"C46\",\"C47\",\"C48\",\"C49\",\"C50\",\"C51\",\"C52\",\"C53\",\"C54\",\"C55\",\"C56\",\"C57\",\"C58\",\"C59\",\"C60\",\"C61\",\"C62\",\"C63\",\"C64\",\"C65\",\"C66\",\"C67\",\"C68\",\"C69\",\"C70\",\"C71\",\"C72\",\"C73\",\"C74\",\"C75\",\"C76\",\"C77\",\"C78\",\"C79\",\"C80\",\"C81\",\"C82\",\"C83\",\"C84\",\"C85\",\"C86\",\"C87\",\"C88\",\"C89\",\"C90\",\"C91\",\"C92\",\"C93\",\"C94\",\"C95\",\"C96\",\"C97\",\"C98\",\"C99\") = (SELECT b.\"C0\",b.\"C1\",b.\"C2\",b.\"C3\",b.\"C4\",b.\"C5\",b.\"C6\",b.\"C7\",b.\"C8\",b.\"C9\",b.\"C10\",b.\"C11\",b.\"C12\",b.\"C13\",b.\"C14\",b.\"C15\",b.\"C16\",b.\"C17\",b.\"C18\",b.\"C19\",b.\"C20\",b.\"C21\",b.\"C22\",b.\"C23\",b.\"C24\",b.\"C25\",b.\"C26\",b.\"C27\",b.\"C28\",b.\"C29\",b.\"C30\",b.\"C31\",b.\"C32\",b.\"C33\",b.\"C34\",b.\"C35\",b.\"C36\",b.\"C37\",b.\"C38\",b.\"C39\",b.\"C40\",b.\"C41\",b.\"C42\",b.\"C43\",b.\"C44\",b.\"C45\",b.\"C46\",b.\"C47\",b.\"C48\",b.\"C49\",b.\"C50\",b.\"C51\",b.\"C52\",b.\"C53\",b.\"C54\",b.\"C55\",b.\"C56\",b.\"C57\",b.\"C58\",b.\"C59\",b.\"C60\",b.\"C61\",b.\"C62\",b.\"C63\",b.\"C64\",b.\"C65\",b.\"C66\",b.\"C67\",b.\"C68\",b.\"C69\",b.\"C70\",b.\"C71\",b.\"C72\",b.\"C73\",b.\"C74\",b.\"C75\",b.\"C76\",b.\"C77\",b.\"C78\",b.\"C79\",b.\"C80\",b.\"C81\",b.\"C82\",b.\"C83\",b.\"C84\",b.\"C85\",b.\"C86\",b.\"C87\",b.\"C88\",b.\"C89\",b.\"C90\",b.\"C91\",b.\"C92\",b.\"C93\",b.\"C94\",b.\"C95\",b.\"C96\",b.\"C97\",b.\"C98\",b.\"C99\" FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', '66d3c2144716', TRIM(CAST(CAST(NEWROW.COL1 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.COL2 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.COL3 as DECIMAL(38,10)) as CHAR(41))), \n",
      "        'col1 FLOAT, col2 FLOAT, col3 FLOAT', 'transform', 'None') as b (\"C0\" DOUBLE,\"C1\" DOUBLE,\"C2\" DOUBLE,\"C3\" DOUBLE,\"C4\" DOUBLE,\"C5\" DOUBLE,\"C6\" DOUBLE,\"C7\" DOUBLE,\"C8\" DOUBLE,\"C9\" DOUBLE,\"C10\" DOUBLE,\"C11\" DOUBLE,\"C12\" DOUBLE,\"C13\" DOUBLE,\"C14\" DOUBLE,\"C15\" DOUBLE,\"C16\" DOUBLE,\"C17\" DOUBLE,\"C18\" DOUBLE,\"C19\" DOUBLE,\"C20\" DOUBLE,\"C21\" DOUBLE,\"C22\" DOUBLE,\"C23\" DOUBLE,\"C24\" DOUBLE,\"C25\" DOUBLE,\"C26\" DOUBLE,\"C27\" DOUBLE,\"C28\" DOUBLE,\"C29\" DOUBLE,\"C30\" DOUBLE,\"C31\" DOUBLE,\"C32\" DOUBLE,\"C33\" DOUBLE,\"C34\" DOUBLE,\"C35\" DOUBLE,\"C36\" DOUBLE,\"C37\" DOUBLE,\"C38\" DOUBLE,\"C39\" DOUBLE,\"C40\" DOUBLE,\"C41\" DOUBLE,\"C42\" DOUBLE,\"C43\" DOUBLE,\"C44\" DOUBLE,\"C45\" DOUBLE,\"C46\" DOUBLE,\"C47\" DOUBLE,\"C48\" DOUBLE,\"C49\" DOUBLE,\"C50\" DOUBLE,\"C51\" DOUBLE,\"C52\" DOUBLE,\"C53\" DOUBLE,\"C54\" DOUBLE,\"C55\" DOUBLE,\"C56\" DOUBLE,\"C57\" DOUBLE,\"C58\" DOUBLE,\"C59\" DOUBLE,\"C60\" DOUBLE,\"C61\" DOUBLE,\"C62\" DOUBLE,\"C63\" DOUBLE,\"C64\" DOUBLE,\"C65\" DOUBLE,\"C66\" DOUBLE,\"C67\" DOUBLE,\"C68\" DOUBLE,\"C69\" DOUBLE,\"C70\" DOUBLE,\"C71\" DOUBLE,\"C72\" DOUBLE,\"C73\" DOUBLE,\"C74\" DOUBLE,\"C75\" DOUBLE,\"C76\" DOUBLE,\"C77\" DOUBLE,\"C78\" DOUBLE,\"C79\" DOUBLE,\"C80\" DOUBLE,\"C81\" DOUBLE,\"C82\" DOUBLE,\"C83\" DOUBLE,\"C84\" DOUBLE,\"C85\" DOUBLE,\"C86\" DOUBLE,\"C87\" DOUBLE,\"C88\" DOUBLE,\"C89\" DOUBLE,\"C90\" DOUBLE,\"C91\" DOUBLE,\"C92\" DOUBLE,\"C93\" DOUBLE,\"C94\" DOUBLE,\"C95\" DOUBLE,\"C96\" DOUBLE,\"C97\" DOUBLE,\"C98\" DOUBLE,\"C99\" DOUBLE) WHERE 1=1) WHERE MOMENT_KEY = NEWROW.MOMENT_KEY        'col1 FLOAT, col2 FLOAT, col3 FLOAT', 'transform', 'None') as b (\"C0\" DOUBLE,\"C1\" DOUBLE,\"C2\" DOUBLE,\"C3\" DOUBLE,\"C4\" DOUBLE,\"C5\" DOUBLE,\"C6\" DOUBLE,\"C7\" DOUBLE,\"C8\" DOUBLE,\"C9\" DOUBLE,\"C10\" DOUBLE,\"C11\" DOUBLE,\"C12\" DOUBLE,\"C13\" DOUBLE,\"C14\" DOUBLE,\"C15\" DOUBLE,\"C16\" DOUBLE,\"C17\" DOUBLE,\"C18\" DOUBLE,\"C19\" DOUBLE,\"C20\" DOUBLE,\"C21\" DOUBLE,\"C22\" DOUBLE,\"C23\" DOUBLE,\"C24\" DOUBLE,\"C25\" DOUBLE,\"C26\" DOUBLE,\"C27\" DOUBLE,\"C28\" DOUBLE,\"C29\" DOUBLE,\"C30\" DOUBLE,\"C31\" DOUBLE,\"C32\" DOUBLE,\"C33\" DOUBLE,\"C34\" DOUBLE,\"C35\" DOUBLE,\"C36\" DOUBLE,\"C37\" DOUBLE,\"C38\" DOUBLE,\"C39\" DOUBLE,\"C40\" DOUBLE,\"C41\" DOUBLE,\"C42\" DOUBLE,\"C43\" DOUBLE,\"C44\" DOUBLE,\"C45\" DOUBLE,\"C46\" DOUBLE,\"C47\" DOUBLE,\"C48\" DOUBLE,\"C49\" DOUBLE,\"C50\" DOUBLE,\"C51\" DOUBLE,\"C52\" DOUBLE,\"C53\" DOUBLE,\"C54\" DOUBLE,\"C55\" DOUBLE,\"C56\" DOUBLE,\"C57\" DOUBLE,\"C58\" DOUBLE,\"C59\" DOUBLE,\"C60\" DOUBLE,\"C61\" DOUBLE,\"C62\" DOUBLE,\"C63\" DOUBLE,\"C64\" DOUBLE,\"C65\" DOUBLE,\"C66\" DOUBLE,\"C67\" DOUBLE,\"C68\" DOUBLE,\"C69\" DOUBLE,\"C70\" DOUBLE,\"C71\" DOUBLE,\"C72\" DOUBLE,\"C73\" DOUBLE,\"C74\" DOUBLE,\"C75\" DOUBLE,\"C76\" DOUBLE,\"C77\" DOUBLE,\"C78\" DOUBLE,\"C79\" DOUBLE,\"C80\" DOUBLE,\"C81\" DOUBLE,\"C82\" DOUBLE,\"C83\" DOUBLE,\"C84\" DOUBLE,\"C85\" DOUBLE,\"C86\" DOUBLE,\"C87\" DOUBLE,\"C88\" DOUBLE,\"C89\" DOUBLE,\"C90\" DOUBLE,\"C91\" DOUBLE,\"C92\" DOUBLE,\"C93\" DOUBLE,\"C94\" DOUBLE,\"C95\" DOUBLE,\"C96\" DOUBLE,\"C97\" DOUBLE,\"C98\" DOUBLE,\"C99\" DOUBLE) WHERE 1=1) WHERE MOMENT_KEY = NEWROW.MOMENT_KEY\n",
      "INFO     2020-09-14 18:25:06.510 - Done with 'creating trigger' [in 855.7021617889404 ms]\n",
      "INFO     2020-09-14 18:25:06.523 - Starting 'add model to metadata table'...\n",
      "INFO     2020-09-14 18:25:06.535 - Adding Model to Metadata table\n",
      "INFO     2020-09-14 18:25:06.618 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-09-14 18:25:06.666 - Done executing.\n",
      "INFO     2020-09-14 18:25:06.679 - Done with 'add model to metadata table' [in 155.9734344482422 ms]\n",
      "INFO     2020-09-14 18:25:06.692 - Flushing\n",
      "WARNING  2020-09-14 18:25:06.705 - Committing Transaction to Database\n",
      "INFO     2020-09-14 18:25:06.739 - Committed.\n",
      "INFO     2020-09-14 18:25:06.751 - Cleaning up deployment\n",
      "INFO     2020-09-14 18:25:06.793 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-09-14 18:25:06.818 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from random import random\n",
    "\n",
    "\n",
    "kpca = KernelPCA(kernel=\"rbf\", gamma=10, n_components=100)\n",
    "d = []\n",
    "for i in range(500):\n",
    "    d.append([random()*i for _ in range(3)])\n",
    "    \n",
    "df = pd.DataFrame(data=d, columns=['col1', 'col2', 'col3'])\n",
    "\n",
    "kpca.get_params()\n",
    "kpca.fit(df[['col1','col2', 'col3']])\n",
    "kpca.transform([[1,2,3]])\n",
    "\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='pca')\n",
    "mlflow.log_model(kpca, 'kpca')\n",
    "splice.execute(f'drop table if exists {schema}.pca')\n",
    "jid = mlflow.deploy_db(schema, 'pca', mlflow.current_run_id(), create_model_table=True, df=df[['col1', 'col2', 'col3']], primary_key=[('MOMENT_KEY', 'INT')],  verbose=True, library_specific={'predict_call':'transform'})\n",
    "mlflow.watch_job(jid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a5ada3-e51c-4186-a7f0-329299493a85",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e91864-9e12-4f16-b52f-0e308b1b2b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6de9f7-6f0e-4b4e-8781-8fae6e4e98ac",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26586e6-abea-4ae0-9ddc-d78f4eafb34b",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840f5190-cec6-4f8a-a034-89f419521bed",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "insert into pca (col1,col2,col3,moment_key) values(1,-2,3,4);\n",
    "insert into pca (col1,col2,col3,moment_key) values(-2,-3,33,5);\n",
    "insert into pca (col1,col2,col3,moment_key) values(3,4,-23,6);\n",
    "insert into pca (col1,col2,col3,moment_key) values(66,234,-2,1);\n",
    "\n",
    "select * from pca;\n",
    "select col1, col2, col3, C0,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,C15,C16,C17,C18,C19,C20,C21,C22,C23,C24,C25,C26,C27,C28,C29,C30,C31,C32,C33,C34,C35,C36,C37,C38,C39,C40,C41,C42,C43,C44,C45,C46,C47,C48,C49,C50,C51,C52,C53,C54,C55,C56,C57,C58,C59,C60,C61,C62,C63,C64,C65,C66,C67,C68,C69,C70,C71,C72,C73,C74,C75,C76,C77,C78,C79,C80,C81,C82,C83,C84,C85,C86,C87,C88,C89,C90,C91,C92,C93,C94,C95,C96,C97,C98,C99 \n",
    "into ${data_and_preds} from pca;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something is wrong. Checking rounding errors\n",
      "All values match to at least 15 decimal places\n",
      "Something is wrong. Checking rounding errors\n",
      "All values match to at least 15 decimal places\n",
      "Something is wrong. Checking rounding errors\n",
      "All values match to at least 15 decimal places\n",
      "Something is wrong. Checking rounding errors\n",
      "All values match to at least 15 decimal places\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    pcs = row[[f'C{i}' for i in range(100)]].values\n",
    "    c1, c2, c3 = row['COL1'],row['COL2'],row['COL3']\n",
    "    raw_pcs = kpca.transform([[float(c1),float(c2), float(c3)]])[0]\n",
    "    if not (raw_pcs == pcs).all(): \n",
    "        print(f'Something is wrong. Checking rounding errors')\n",
    "        comp=0\n",
    "        for i,j in zip(raw_pcs, pcs):\n",
    "            for rnd in range(15,8,-1):\n",
    "#                 print(f'checking round at {rnd}')\n",
    "                if round(i,rnd)!=round(j,rnd):\n",
    "                    raise Exception(f'Values are incorrect. Database returned {j} but model returned {i} for component C{comp}')\n",
    "                break\n",
    "\n",
    "        print(f'All values match to at least {rnd} decimal places')\n",
    "    \n",
    "print('test passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving artifact of size: 5.877 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated Parameter 'verbose'. Use mlflow.watch_job(<job id>) or mlflow.fetch_logs(<job id>) to get verbose output. Ignoring...\n",
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "---Job Logs---\n",
      "INFO     2020-09-14 18:34:06.820 - A service worker has found your request\n",
      "INFO     2020-09-14 18:34:06.840 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-09-14 18:34:06.866 - Handler is available\n",
      "INFO     2020-09-14 18:34:06.880 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-09-14 18:34:06.956 - Retrieved MLFlow RunINFO     2020-09-14 18:34:06.956 - Retrieved MLFlow Run\n",
      "INFO     2020-09-14 18:34:06.969 - Updating MLFlow Run for the UI\n",
      "INFO     2020-09-14 18:34:07.003 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-09-14 18:34:07.015 - Extracting Model from DB with Name: pipeline\n",
      "INFO     2020-09-14 18:34:07.039 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-09-14 18:34:07.059 - Decompressing Model Artifact\n",
      "INFO     2020-09-14 18:34:07.073 - Creating raw model representation from MLModel\n",
      "INFO     2020-09-14 18:34:07.087 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-09-14 18:34:07.103 - Registering Raw Model Representation...\n",
      "INFO     2020-09-14 18:34:07.115 - Done.\n",
      "INFO     2020-09-14 18:34:07.127 - Adding Model Schema and DF...\n",
      "INFO     2020-09-14 18:34:07.168 - Creating Alternative Scikit Representations\n",
      "INFO     2020-09-14 18:34:07.182 - Registering Serialized Representation\n",
      "INFO     2020-09-14 18:34:07.218 - Updating Artifact with serialized representation\n",
      "INFO     2020-09-14 18:34:07.232 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-09-14 18:34:07.245 - Prepare Scikit-learn metadata for deployment\n",
      "INFO     2020-09-14 18:34:07.259 - Adding Schema String to model metadata...\n",
      "INFO     2020-09-14 18:34:07.277 - Starting 'creating model deployment table'...\n",
      "INFO     2020-09-14 18:34:07.319 - Executing\n",
      "CREATE TABLE ben.skpipe (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT 'c56497d9e6d6',\n",
      "                C0 FLOAT, C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT, C7 FLOAT, C8 FLOAT, C9 FLOAT, C10 FLOAT, C11 FLOAT, C12 FLOAT, C13 FLOAT, C14 FLOAT, C15 FLOAT, C16 FLOAT, C17 FLOAT, C18 FLOAT, C19 FLOAT,MOMENT_KEY INT,PREDICTION INT,PRIMARY KEY(MOMENT_KEY))                C0 FLOAT, C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT, C7 FLOAT, C8 FLOAT, C9 FLOAT, C10 FLOAT, C11 FLOAT, C12 FLOAT, C13 FLOAT, C14 FLOAT, C15 FLOAT, C16 FLOAT, C17 FLOAT, C18 FLOAT, C19 FLOAT,MOMENT_KEY INT,PREDICTION INT,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-09-14 18:34:08.178 - Done with 'creating model deployment table' [in 901.3748168945312 ms]\n",
      "INFO     2020-09-14 18:34:08.191 - Starting 'creating trigger'...\n",
      "INFO     2020-09-14 18:34:08.204 - Creating Prediction Trigger...\n",
      "INFO     2020-09-14 18:34:08.218 - Executing\n",
      "CREATE TRIGGER ben.runModel_skpipe_c56497d9e6d6\n",
      "                           BEFORE INSERT ON ben.skpipe REFERENCING NEW AS NEWROW \n",
      "                           FOR EACH ROW SET NEWROW.PREDICTION=MLMANAGER.PREDICT_CLUSTER('c56497d9e6d6',TRIM(CAST(CAST(NEWROW.C0 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C1 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C2 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C3 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C4 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C5 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C6 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C7 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C8 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C9 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C10 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C11 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C12 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C13 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C14 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C15 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C16 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C17 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C18 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C19 as DECIMAL(38,10)) as CHAR(41))),\n",
      "'C0 FLOAT, C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT, C7 FLOAT, C8 FLOAT, C9 FLOAT, C10 FLOAT, C11 FLOAT, C12 FLOAT, C13 FLOAT, C14 FLOAT, C15 FLOAT, C16 FLOAT, C17 FLOAT, C18 FLOAT, C19 FLOAT')\n",
      "INFO     2020-09-14 18:34:08.444 - Done with 'creating trigger' [in 252.49004364013672 ms]\n",
      "INFO     2020-09-14 18:34:08.460 - Starting 'add model to metadata table'...\n",
      "INFO     2020-09-14 18:34:08.473 - Adding Model to Metadata table\n",
      "INFO     2020-09-14 18:34:08.562 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-09-14 18:34:08.618 - Done executing.\n",
      "INFO     2020-09-14 18:34:08.632 - Done with 'add model to metadata table' [in 172.58095741271973 ms]\n",
      "INFO     2020-09-14 18:34:08.645 - Flushing\n",
      "WARNING  2020-09-14 18:34:08.657 - Committing Transaction to Database\n",
      "INFO     2020-09-14 18:34:08.693 - Committed.\n",
      "INFO     2020-09-14 18:34:08.706 - Cleaning up deployment\n",
      "INFO     2020-09-14 18:34:08.748 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-09-14 18:34:08.773 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# generate some data to play with\n",
    "X, y = make_classification(\n",
    "    n_informative=5, n_redundant=0, random_state=42)\n",
    "# ANOVA SVM-C\n",
    "anova_filter = SelectKBest(f_regression, k=5)\n",
    "clf = svm.SVC(kernel='linear', probability=True)\n",
    "anova_svm = Pipeline([('anova', anova_filter), ('svc', clf)])\n",
    "anova_svm.set_params(anova__k=10, svc__C=.1).fit(X, y)\n",
    "prediction = anova_svm.predict(X)\n",
    "anova_svm.score(X, y)\n",
    "# getting the selected features chosen by anova_filter\n",
    "anova_svm['anova'].get_support()\n",
    "# Another way to get selected features chosen by anova_filter\n",
    "anova_svm.named_steps.anova.get_support()\n",
    "# Indexing can also be used to extract a sub-pipeline.\n",
    "sub_pipeline = anova_svm[:1]\n",
    "sub_pipeline\n",
    "coef = anova_svm[-1].coef_\n",
    "anova_svm['svc'] is anova_svm[-1]\n",
    "coef.shape\n",
    "\n",
    "df = pd.DataFrame(X, columns=[f'C{i}' for i in range(20)])\n",
    "df['label'] = pd.DataFrame(y)\n",
    "\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='pipeline')\n",
    "mlflow.log_model(anova_svm, 'pipeline')\n",
    "splice.execute(f'drop table if exists {schema}.skpipe')\n",
    "jid = mlflow.deploy_db(schema, 'skpipe', mlflow.current_run_id(), primary_key=[('MOMENT_KEY', 'INT')], create_model_table=True, df=df.drop('label', axis=1), verbose=True)\n",
    "mlflow.watch_job(jid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b4735b-7115-4cc7-98f2-8fdedd92099d",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7daf6b70-6d2b-419f-891d-e36090adbef1",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19739286-8dc3-41ae-a178-784e5c3998eb",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "insert into skpipe (c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,c11,c12,c13,c14,c15,c16,c17,c18,c19,moment_key) values(3.611,6.133,9.065,9.347,4.649,11.534,1.436,3.625,0.617,5.556,1.191,11.871,6.27,13.615,4.942,16.17,1.858,13.121,9.192,16.729,9);\n",
    "insert into skpipe (c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,c11,c12,c13,c14,c15,c16,c17,c18,c19,moment_key) values(1.1520228167464979,2.1605391309255357,2.1567734709026443,2.574915424636612,1.286824753247393,0.5889507491535976,1.5086880856146783,2.269695379745943,2.6089968335162177,0.14727247523071063,1.8485328196592175,2.097532276755521,0.27822480992530085,2.666733308369378,2.143893385597627,1.3465081988790233,0.11041583917168307,0.9246752875764862,2.500911791131701,1.1195218819285857,5);\n",
    "select * from skpipe;\n",
    "select c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,c11,c12,c13,c14,c15,c16,c17,c18,c19, prediction into ${data_and_preds} from skpipe;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,c11,c12,c13,c14,c15,c16,c17,c18,c19,p = row\n",
    "    raw_p = anova_svm.predict([[float(c0),float(c1),float(c2),float(c3),float(c4),float(c5),float(c6),float(c7),float(c8),float(c9),float(c10),float(c11),float(c12),float(c13),float(c14),float(c15),float(c16),float(c17),float(c18),float(c19)]])\n",
    "    assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Proba Exmaple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving artifact of size: 1.696 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated Parameter 'verbose'. Use mlflow.watch_job(<job id>) or mlflow.fetch_logs(<job id>) to get verbose output. Ignoring...\n",
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "---Job Logs---\n",
      "INFO     2020-09-14 18:37:33.783 - A service worker has found your request\n",
      "INFO     2020-09-14 18:37:33.803 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-09-14 18:37:33.826 - Handler is available\n",
      "INFO     2020-09-14 18:37:33.839 - Retrieving Run from MLFlow Tracking Server...INFO     2020-09-14 18:37:33.839 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-09-14 18:37:33.914 - Retrieved MLFlow Run\n",
      "INFO     2020-09-14 18:37:33.925 - Updating MLFlow Run for the UI\n",
      "INFO     2020-09-14 18:37:33.955 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-09-14 18:37:33.967 - Extracting Model from DB with Name: rf\n",
      "INFO     2020-09-14 18:37:33.988 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-09-14 18:37:34.006 - Decompressing Model Artifact\n",
      "INFO     2020-09-14 18:37:34.019 - Creating raw model representation from MLModel\n",
      "INFO     2020-09-14 18:37:34.035 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-09-14 18:37:34.052 - Registering Raw Model Representation...\n",
      "INFO     2020-09-14 18:37:34.064 - Done.\n",
      "INFO     2020-09-14 18:37:34.077 - Adding Model Schema and DF...\n",
      "INFO     2020-09-14 18:37:34.112 - Creating Alternative Scikit Representations\n",
      "INFO     2020-09-14 18:37:34.124 - Registering Serialized Representation\n",
      "INFO     2020-09-14 18:37:34.162 - Updating Artifact with serialized representation\n",
      "INFO     2020-09-14 18:37:34.175 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-09-14 18:37:34.188 - Prepare Scikit-learn metadata for deployment\n",
      "INFO     2020-09-14 18:37:34.201 - Using model provided classes: ['C1', 'C4']\n",
      "INFO     2020-09-14 18:37:34.213 - Adding Schema String to model metadata...\n",
      "INFO     2020-09-14 18:37:34.231 - Starting 'creating model deployment table'...\n",
      "INFO     2020-09-14 18:37:34.269 - Executing\n",
      "CREATE TABLE ben.predict_proba (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '6bd8e2b47300',\n",
      "                col1 BIGINT, col2 BIGINT,MOMENT_KEY INT,\"prediction\" DOUBLE,\"C1\" DOUBLE,\"C4\" DOUBLE,PRIMARY KEY(MOMENT_KEY))                col1 BIGINT, col2 BIGINT,MOMENT_KEY INT,\"prediction\" DOUBLE,\"C1\" DOUBLE,\"C4\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-09-14 18:37:35.083 - Done with 'creating model deployment table' [in 852.5340557098389 ms]\n",
      "INFO     2020-09-14 18:37:35.096 - Starting 'creating trigger'...\n",
      "INFO     2020-09-14 18:37:35.107 - Creating VTI Prediction Trigger...\n",
      "INFO     2020-09-14 18:37:35.119 - Managing Sklearn prediction args\n",
      "INFO     2020-09-14 18:37:35.131 - Executing\n",
      "CREATE TRIGGER ben.runModel_predict_proba_6bd8e2b47300 \n",
      "                        AFTER INSERT ON ben.predict_proba REFERENCING NEW AS NEWROW FOR EACH ROW\n",
      "                        UPDATE ben.predict_proba SET (\"prediction\",\"C1\",\"C4\") = (SELECT b.\"prediction\",b.\"C1\",b.\"C4\" FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', '6bd8e2b47300', TRIM(CAST(NEWROW.COL1 as CHAR(41)))||','||TRIM(CAST(NEWROW.COL2 as CHAR(41))), \n",
      "        'col1 BIGINT, col2 BIGINT', 'predict_proba', 'None') as b (\"prediction\" INT,\"C1\" DOUBLE,\"C4\" DOUBLE) WHERE 1=1) WHERE MOMENT_KEY = NEWROW.MOMENT_KEY\n",
      "INFO     2020-09-14 18:37:35.420 - Done with 'creating trigger' [in 323.866605758667 ms]\n",
      "INFO     2020-09-14 18:37:35.434 - Starting 'add model to metadata table'...\n",
      "INFO     2020-09-14 18:37:35.448 - Adding Model to Metadata table\n",
      "INFO     2020-09-14 18:37:35.527 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-09-14 18:37:35.575 - Done executing.\n",
      "INFO     2020-09-14 18:37:35.587 - Done with 'add model to metadata table' [in 152.88019180297852 ms]\n",
      "INFO     2020-09-14 18:37:35.598 - Flushing\n",
      "WARNING  2020-09-14 18:37:35.610 - Committing Transaction to Database\n",
      "INFO     2020-09-14 18:37:35.645 - Committed.\n",
      "INFO     2020-09-14 18:37:35.657 - Cleaning up deployment\n",
      "INFO     2020-09-14 18:37:35.700 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-09-14 18:37:35.723 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "d = {'col1': [1, 2], 'col2': [3, 4], 'y': [4, 1]}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(df[['col1','col2']],df['y'])\n",
    "clf.predict_proba([[0,1]])\n",
    "\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='predict_proba')\n",
    "mlflow.log_model(clf, 'rf')\n",
    "splice.execute(f'drop table if exists {schema}.predict_proba')\n",
    "jid = mlflow.deploy_db(schema, 'predict_proba', mlflow.current_run_id(), create_model_table=True, df=df[['col1', 'col2']], primary_key=[('MOMENT_KEY', 'INT')],  verbose=True, library_specific={'predict_call':'predict_proba'})\n",
    "mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926a0208-3a18-4491-89de-de26f0a26b36",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926996f6-fc0c-4111-82d2-0d5018f19836",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd78eaec-3e85-4a9c-bdc3-0f3f06b2beff",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "insert into predict_proba (col1,col2,moment_key) values(3.611,6.133,9);\n",
    "insert into predict_proba (col1,col2,moment_key) values(1.1520228167464979,2.1605,5);\n",
    "select * from predict_proba;\n",
    "select col1,col2, \"prediction\", C1, C4 into ${data_and_preds} from predict_proba;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    col1,col2,p,c1,c4 = row\n",
    "    raw_c1,raw_c4 = clf.predict_proba([[float(col1),float(col2)]])[0]\n",
    "    raw_p = clf.predict([[float(col1),float(col2)]])[0]\n",
    "    assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "    assert raw_c1 == c1, f'Something is wrong. Model Table gives {c1} but raw model gives {raw_c1}'\n",
    "    assert raw_c4 == c4, f'Something is wrong. Model Table gives {c4} but raw model gives {raw_c4}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
