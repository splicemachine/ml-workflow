{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splicemachine.spark import PySpliceContext\n",
    "from splicemachine.mlflow_support.utilities import get_user\n",
    "from splicemachine.mlflow_support import *\n",
    "\n",
    "splice = PySpliceContext(spark)\n",
    "mlflow.set_experiment('sklearn model deployment')\n",
    "mlflow.register_splice_context(splice)\n",
    "schema = get_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from splicemachine.notebook import *\n",
    "get_mlflow_ui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Data\n",
    "d = {'col1': [1, 2], 'col2': [3, 4], 'y': [0.2, 5.3]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df\n",
    "# Model\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(df[['col1', 'col2']], df['y'])\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='regression')\n",
    "mlflow.log_model(reg, 'regression_model')\n",
    "splice.execute(f'drop table if exists {schema}.sk_regression')\n",
    "jid = mlflow.deploy_db(schema, 'sk_regression', mlflow.current_run_id(), primary_key=[('MOMENT_KEY', 'INT')], df=df[['col1', 'col2']],create_model_table=True, verbose=True)\n",
    "mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "insert into sk_regression (col1, col2, moment_key) values(1,5,4347861);\n",
    "insert into sk_regression (col1, col2, moment_key) values(2,7,4908084);\n",
    "select * from sk_regression;\n",
    "select col1, col2, prediction into ${data_and_preds} from sk_regression;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.load_model('8d8eaffcf42b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    c1, c2, p = row\n",
    "    raw_p = reg.predict([[float(c1),float(c2)]])[0]\n",
    "    assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "import pandas as pd\n",
    "# Data\n",
    "d = {'col1': [1, 2], 'col2': [3, 4], 'y': [0.2, 5.3]}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "# Model\n",
    "model = BayesianRidge(compute_score=True,normalize = True)\n",
    "model.fit(df[['col1', 'col2']], df['y'])\n",
    "x = model.predict([[1,2]], return_std=True)\n",
    "\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='bayesian with std')\n",
    "mlflow.log_model(model, 'bayesian_model')\n",
    "splice.execute(f'drop table if exists {schema}.sk_bayesian')\n",
    "jid = mlflow.deploy_db(schema, 'sk_bayesian', mlflow.current_run_id(), primary_key=[('MOMENT_KEY', 'INT')], df=df[['col1', 'col2']], create_model_table=True, verbose=True, library_specific={'predict_call':'predict', 'predict_args':'return_std'})\n",
    "mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.load_model('dd5f3f988a9c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%sql\n",
    "\n",
    "insert into sk_bayesian (col1, col2, moment_key) values(-4,-5,1);\n",
    "insert into sk_bayesian (col1, col2, moment_key) values(100,22,2);\n",
    "insert into sk_bayesian (col1, col2, moment_key) values(7,8,3);\n",
    "\n",
    "select * from sk_bayesian;\n",
    "select col1, col2, \"prediction\", \"std\" into ${data_and_preds} from sk_bayesian;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    c1, c2, p, std = row\n",
    "    raw_p, raw_std = model.predict([[float(c1),float(c2)]], return_std=True)\n",
    "    assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "    assert raw_std == std, f'Something is wrong. Model Table gives {std} but raw model gives {raw_std}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Bayesian model into existing table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists bayesian_table;\n",
    "create table bayesian_table(col1 int, col2 int, moment_key int primary key);\n",
    "insert into bayesian_table values(4,2,1);\n",
    "insert into bayesian_table values(9,8,7);\n",
    "select * from bayesian_table;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_id = mlflow.get_run_ids_by_name('bayesian with std')[0]\n",
    "jid = mlflow.deploy_db(schema, 'bayesian_table', run_id, verbose=True, model_cols=['COL1','COL2'], library_specific={'predict_call':'predict', 'predict_args':'return_std'}, create_model_table=False)\n",
    "mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.load_model('dd5f3f988a9c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 2 rows should have <b>NO</b> values for prediction and std (we inserted those rows before model deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%sql\n",
    "\n",
    "insert into bayesian_table (col1, col2, moment_key) values(4,5,20);\n",
    "insert into bayesian_table (col1, col2, moment_key) values(-4,-5,21);\n",
    "insert into bayesian_table (col1, col2, moment_key) values(7,8,22);\n",
    "\n",
    "select * from bayesian_table;\n",
    "select col1, col2, \"prediction\", \"std\" into ${data_and_preds} from bayesian_table;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    c1, c2, p, std = row\n",
    "    if index in (0, 1):\n",
    "        assert math.isnan(p), f\"Something is wrong. prediction should be NaN for the first 2 rows but has value {p}\"\n",
    "        assert math.isnan(std), f\"Something is wrong. std should be NaN for the first 2 rows but has value {std}\"\n",
    "    else:\n",
    "        raw_p, raw_std = model.predict([[float(c1),float(c2)]], return_std=True)\n",
    "        assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "        assert raw_std == std, f'Something is wrong. Model Table gives {std} but raw model gives {raw_std}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM Model\n",
    "## GMM with Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.gpr import GaussianProcessRegressor\n",
    "# Data\n",
    "d = {'col1': [1, 2], 'col2': [3, 4], 'y': [0.2, 5.3]}\n",
    "df = pd.DataFrame(data=d)\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "\n",
    "# Model\n",
    "g = GaussianProcessRegressor()\n",
    "g.fit(df[['col1','col2']],df['y'])\n",
    "# print(g.predict([[5,5]],return_std=True))\n",
    "# print(g.predict([[5,5]],return_cov=True))\n",
    "\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='gmm with std')\n",
    "mlflow.log_model(g, 'gmm_model')\n",
    "splice.execute(f'drop table if exists {schema}.sk_gmm')\n",
    "jid = mlflow.deploy_db(schema, 'sk_gmm', mlflow.current_run_id(), df=df[['col1', 'col2']], primary_key=[('MOMENT_KEY', 'INT')], create_model_table=True, verbose=True, library_specific={'predict_call':'predict', 'predict_args':'return_std'})\n",
    "mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.load_model('a4bed73efce0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%sql\n",
    "\n",
    "insert into sk_gmm (col1,col2,moment_key) values(4,5,1);\n",
    "insert into sk_gmm (col1,col2,moment_key) values(-4,-5,2);\n",
    "insert into sk_gmm (col1,col2,moment_key) values(7,8,3);\n",
    "\n",
    "select * from sk_gmm;\n",
    "select col1, col2, \"prediction\", \"std\" into ${data_and_preds} from sk_gmm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    c1, c2, p, std = row\n",
    "    raw_p, raw_std = g.predict([[float(c1),float(c2)]], return_std=True)\n",
    "    assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "    assert raw_std == std, f'Something is wrong. Model Table gives {std} but raw model gives {raw_std}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM with Covarience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.gpr import GaussianProcessRegressor\n",
    "# Data\n",
    "d = {'col1': [1, 2], 'col2': [3, 4], 'y': [0.2, 5.3]}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "\n",
    "# Model\n",
    "g = GaussianProcessRegressor()\n",
    "g.fit(df[['col1','col2']],df['y'])\n",
    "# print(g.predict([[5,5]],return_std=True))\n",
    "# print(g.predict([[5,5]],return_cov=True))\n",
    "\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='gmm with cov')\n",
    "mlflow.log_model(g, 'gmm')\n",
    "splice.execute(f'drop table if exists {schema}.sk_gmm_cov')\n",
    "jid = mlflow.deploy_db(schema, 'sk_gmm_cov', mlflow.current_run_id(), df=df[['col1', 'col2']], primary_key=[('MOMENT_KEY', 'INT')], create_model_table=True, verbose=True, library_specific={'predict_call':'predict', 'predict_args':'return_cov'})\n",
    "mlflow.watch_job(jid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.load_model('cfb906e60196')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%sql\n",
    "\n",
    "insert into sk_gmm_cov (col1,col2,moment_key) values(4,5,1);\n",
    "insert into sk_gmm_cov (col1,col2,moment_key) values(-4,-5,2);\n",
    "insert into sk_gmm_cov (col1,col2,moment_key) values(7,8,3);\n",
    "\n",
    "select * from sk_gmm_cov;\n",
    "select col1, col2, \"prediction\", \"cov\" into ${data_and_preds} from sk_gmm_cov;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    c1, c2, p, std = row\n",
    "    raw_p, raw_std = g.predict([[float(c1),float(c2)]], return_cov=True)\n",
    "    assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "    assert raw_std == std, f'Something is wrong. Model Table gives {std} but raw model gives {raw_std}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from random import random\n",
    "\n",
    "\n",
    "kpca = KernelPCA(kernel=\"rbf\", gamma=10, n_components=100)\n",
    "d = []\n",
    "for i in range(500):\n",
    "    d.append([random()*i for _ in range(3)])\n",
    "    \n",
    "df = pd.DataFrame(data=d, columns=['col1', 'col2', 'col3'])\n",
    "\n",
    "kpca.get_params()\n",
    "kpca.fit(df[['col1','col2', 'col3']])\n",
    "kpca.transform([[1,2,3]])\n",
    "\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='pca')\n",
    "mlflow.log_model(kpca, 'kpca')\n",
    "splice.execute(f'drop table if exists {schema}.pca')\n",
    "jid = mlflow.deploy_db(schema, 'pca', mlflow.current_run_id(), create_model_table=True, df=df[['col1', 'col2', 'col3']], primary_key=[('MOMENT_KEY', 'INT')],  verbose=True, library_specific={'predict_call':'transform'})\n",
    "mlflow.watch_job(jid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.load_model('7f685cfb26bb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "insert into pca (col1,col2,col3,moment_key) values(1,-2,3,4);\n",
    "insert into pca (col1,col2,col3,moment_key) values(-2,-3,33,5);\n",
    "insert into pca (col1,col2,col3,moment_key) values(3,4,-23,6);\n",
    "insert into pca (col1,col2,col3,moment_key) values(66,234,-2,1);\n",
    "\n",
    "select * from pca;\n",
    "select col1, col2, col3, C0,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,C15,C16,C17,C18,C19,C20,C21,C22,C23,C24,C25,C26,C27,C28,C29,C30,C31,C32,C33,C34,C35,C36,C37,C38,C39,C40,C41,C42,C43,C44,C45,C46,C47,C48,C49,C50,C51,C52,C53,C54,C55,C56,C57,C58,C59,C60,C61,C62,C63,C64,C65,C66,C67,C68,C69,C70,C71,C72,C73,C74,C75,C76,C77,C78,C79,C80,C81,C82,C83,C84,C85,C86,C87,C88,C89,C90,C91,C92,C93,C94,C95,C96,C97,C98,C99 \n",
    "into ${data_and_preds} from pca;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    pcs = row[[f'C{i}' for i in range(100)]].values\n",
    "    c1, c2, c3 = row['COL1'],row['COL2'],row['COL3']\n",
    "    raw_pcs = kpca.transform([[float(c1),float(c2), float(c3)]])[0]\n",
    "    if not (raw_pcs == pcs).all(): \n",
    "        print(f'Something is wrong. Checking rounding errors')\n",
    "        comp=0\n",
    "        for i,j in zip(raw_pcs, pcs):\n",
    "            for rnd in range(15,8,-1):\n",
    "#                 print(f'checking round at {rnd}')\n",
    "                if round(i,rnd)!=round(j,rnd):\n",
    "                    raise Exception(f'Values are incorrect. Database returned {j} but model returned {i} for component C{comp}')\n",
    "                break\n",
    "\n",
    "        print(f'All values match to at least {rnd} decimal places')\n",
    "    \n",
    "print('test passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# generate some data to play with\n",
    "X, y = make_classification(\n",
    "    n_informative=5, n_redundant=0, random_state=42)\n",
    "# ANOVA SVM-C\n",
    "anova_filter = SelectKBest(f_regression, k=5)\n",
    "clf = svm.SVC(kernel='linear', probability=True)\n",
    "anova_svm = Pipeline([('anova', anova_filter), ('svc', clf)])\n",
    "anova_svm.set_params(anova__k=10, svc__C=.1).fit(X, y)\n",
    "prediction = anova_svm.predict(X)\n",
    "anova_svm.score(X, y)\n",
    "# getting the selected features chosen by anova_filter\n",
    "anova_svm['anova'].get_support()\n",
    "# Another way to get selected features chosen by anova_filter\n",
    "anova_svm.named_steps.anova.get_support()\n",
    "# Indexing can also be used to extract a sub-pipeline.\n",
    "sub_pipeline = anova_svm[:1]\n",
    "sub_pipeline\n",
    "coef = anova_svm[-1].coef_\n",
    "anova_svm['svc'] is anova_svm[-1]\n",
    "coef.shape\n",
    "\n",
    "df = pd.DataFrame(X, columns=[f'C{i}' for i in range(20)])\n",
    "df['label'] = pd.DataFrame(y)\n",
    "\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='pipeline')\n",
    "mlflow.log_model(anova_svm, 'pipeline')\n",
    "splice.execute(f'drop table if exists {schema}.skpipe')\n",
    "jid = mlflow.deploy_db(schema, 'skpipe', mlflow.current_run_id(), primary_key=[('MOMENT_KEY', 'INT')], create_model_table=True, df=df.drop('label', axis=1), verbose=True)\n",
    "mlflow.watch_job(jid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.load_model('1733b7b8f83c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "insert into skpipe (c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,c11,c12,c13,c14,c15,c16,c17,c18,c19,moment_key) values(3.611,6.133,9.065,9.347,4.649,11.534,1.436,3.625,0.617,5.556,1.191,11.871,6.27,13.615,4.942,16.17,1.858,13.121,9.192,16.729,9);\n",
    "insert into skpipe (c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,c11,c12,c13,c14,c15,c16,c17,c18,c19,moment_key) values(1.1520228167464979,2.1605391309255357,2.1567734709026443,2.574915424636612,1.286824753247393,0.5889507491535976,1.5086880856146783,2.269695379745943,2.6089968335162177,0.14727247523071063,1.8485328196592175,2.097532276755521,0.27822480992530085,2.666733308369378,2.143893385597627,1.3465081988790233,0.11041583917168307,0.9246752875764862,2.500911791131701,1.1195218819285857,5);\n",
    "select * from skpipe;\n",
    "select c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,c11,c12,c13,c14,c15,c16,c17,c18,c19, prediction into ${data_and_preds} from skpipe;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,c11,c12,c13,c14,c15,c16,c17,c18,c19,p = row\n",
    "    raw_p = anova_svm.predict([[float(c0),float(c1),float(c2),float(c3),float(c4),float(c5),float(c6),float(c7),float(c8),float(c9),float(c10),float(c11),float(c12),float(c13),float(c14),float(c15),float(c16),float(c17),float(c18),float(c19)]])\n",
    "    assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Proba Exmaple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "d = {'col1': [1, 2], 'col2': [3, 4], 'y': [4, 1]}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(df[['col1','col2']],df['y'])\n",
    "clf.predict_proba([[0,1]])\n",
    "\n",
    "# Deploy\n",
    "while mlflow.active_run(): # In case nested runs\n",
    "    mlflow.end_run() \n",
    "mlflow.start_run(run_name='predict_proba')\n",
    "mlflow.log_model(clf, 'rf')\n",
    "splice.execute(f'drop table if exists {schema}.predict_proba')\n",
    "jid = mlflow.deploy_db(schema, 'predict_proba', mlflow.current_run_id(), create_model_table=True, df=df[['col1', 'col2']], primary_key=[('MOMENT_KEY', 'INT')],  verbose=True, library_specific={'predict_call':'predict_proba'})\n",
    "mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.load_model('46acad893a2e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "insert into predict_proba (col1,col2,moment_key) values(3.611,6.133,9);\n",
    "insert into predict_proba (col1,col2,moment_key) values(1.1520228167464979,2.1605,5);\n",
    "select * from predict_proba;\n",
    "select col1,col2, \"prediction\", C1, C4 into ${data_and_preds} from predict_proba;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = beakerx.get('data_and_preds')\n",
    "for index, row in data.iterrows():\n",
    "    col1,col2,p,c1,c4 = row\n",
    "    raw_c1,raw_c4 = clf.predict_proba([[float(col1),float(col2)]])[0]\n",
    "    raw_p = clf.predict([[float(col1),float(col2)]])[0]\n",
    "    assert raw_p == p, f'Something is wrong. Model Table gives {p} but raw model gives {raw_p}'\n",
    "    assert raw_c1 == c1, f'Something is wrong. Model Table gives {c1} but raw model gives {raw_c1}'\n",
    "    assert raw_c4 == c4, f'Something is wrong. Model Table gives {c4} but raw model gives {raw_c4}'\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
