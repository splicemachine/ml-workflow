{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from h2o.estimators import *\n",
    "from pysparkling import *\n",
    "import h2o\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "spark = SparkSession.builder.config('spark.dynamicAllocation.enabled','false').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create H2O Sparkling Water cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://10.128.98.41:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>10 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.0.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>8 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>sparkling-water-jovyan_spark-application-1606341750786</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.833 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>5</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://10.128.98.41:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>null</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------------------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         10 secs\n",
       "H2O_cluster_timezone:       UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.0.2\n",
       "H2O_cluster_version_age:    8 days\n",
       "H2O_cluster_name:           sparkling-water-jovyan_spark-application-1606341750786\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.833 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  5\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://10.128.98.41:54321\n",
       "H2O_connection_proxy:       null\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.8 final\n",
       "--------------------------  -------------------------------------------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.32.0.2-1-3.0\n",
      " * H2O name: jovyan\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,10.128.98.103,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://10.128.98.41:54321 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "conf = H2OConf().setInternalClusterMode()\n",
    "hc = H2OContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "from splicemachine.spark.context import PySpliceContext\n",
    "splice = PySpliceContext(spark)\n",
    "from splicemachine.mlflow_support import *\n",
    "from splicemachine.mlflow_support.utilities import get_user\n",
    "mlflow.register_splice_context(splice)\n",
    "mlflow.set_experiment('h2o deployment')\n",
    "schema = get_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "deploying gbm\n",
      "Saving artifact of size: 70.231 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 21:22:41.000 - A service worker has found your request\n",
      "INFO     2020-11-25 21:22:41.063 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 21:22:41.096 - Handler is available\n",
      "INFO     2020-11-25 21:22:41.117 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 21:22:41.183 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 21:22:41.205 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 21:22:41.273 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 21:22:41.296 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 21:22:41.329 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 21:22:41.355 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 21:22:41.379 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 21:22:41.398 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 21:22:41.838 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 21:22:41.862 - Done.\n",
      "INFO     2020-11-25 21:22:41.883 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 21:22:42.903 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 21:22:42.926 - Adding Serialized Representation\n",
      "INFO     2020-11-25 21:22:43.023 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 21:22:43.044 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 21:22:43.064 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 21:22:43.091 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 21:22:43.117 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 21:22:43.179 - Executing\n",
      "CREATE TABLE splice.h2o_gbm (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '046b88926704',\n",
      "                SIBSP TINYINT, SEX VARCHAR(5000), AGE FLOAT,MOMENT_KEY INTEGER,PREDICTION VARCHAR(5000),\"C0\" DOUBLE,\"C1\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 21:22:44.811 - Done with 'creating model deployment table' [in 1693.6120986938477 ms]\n",
      "INFO     2020-11-25 21:22:44.831 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 21:22:44.851 - Creating Prediction Trigger...\n",
      "INFO     2020-11-25 21:22:44.870 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_gbm_046b88926704\n",
      "                           BEFORE INSERT ON splice.h2o_gbm REFERENCING NEW AS NEWROW \n",
      "                           FOR EACH ROW SET NEWROW.PREDICTION=MLMANAGER.PREDICT_CLASSIFICATION('046b88926704',TRIM(CAST(NEWROW.SIBSP as CHAR(41)))||','||NEWROW.SEX||','||TRIM(CAST(CAST(NEWROW.AGE as DECIMAL(38,10)) as CHAR(41))),\n",
      "'sibsp TINYINT, sex VARCHAR(5000), age FLOAT')\n",
      "INFO     2020-11-25 21:22:45.138 - Done with 'creating trigger' [in 307.4493408203125 ms]\n",
      "INFO     2020-11-25 21:22:45.160 - Starting 'create parsing trigger'...\n",
      "INFO     2020-11-25 21:22:45.183 - Creating parsing trigger...\n",
      "INFO     2020-11-25 21:22:45.203 - Executing\n",
      "CREATE TRIGGER splice.PARSERESULT_h2o_gbm_046b88926704                                 BEFORE INSERT ON splice.h2o_gbm REFERENCING NEW AS NEWROW                                 FOR EACH ROW set NEWROW.\"C0\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,0),NEWROW.\"C1\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,1),NEWROW.PREDICTION=   CASE   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=0 then 'C0'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=1 then 'C1'   END;\n",
      "INFO     2020-11-25 21:22:45.561 - Done with 'create parsing trigger' [in 400.8767604827881 ms]\n",
      "INFO     2020-11-25 21:22:45.582 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 21:22:45.602 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 21:22:45.712 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 21:22:45.851 - Done executing.\n",
      "INFO     2020-11-25 21:22:45.874 - Done with 'add model to metadata table' [in 291.89443588256836 ms]\n",
      "INFO     2020-11-25 21:22:45.900 - Flushing\n",
      "WARNING  2020-11-25 21:22:45.921 - Committing Transaction to Database\n",
      "INFO     2020-11-25 21:22:45.976 - Committed.\n",
      "INFO     2020-11-25 21:22:46.009 - Cleaning up deployment\n",
      "INFO     2020-11-25 21:22:46.058 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 21:22:46.110 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "\n",
    "\n",
    "# Import the titanic dataset into H2O:\n",
    "titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "\n",
    "# Set the predictors and response; set the response as a factor:\n",
    "titanic[\"survived\"] = titanic[\"survived\"].asfactor()\n",
    "predictors = ['sibsp', 'sex', 'age']\n",
    "response = \"survived\"\n",
    "\n",
    "# Split the dataset into a train and valid set:\n",
    "train, valid = titanic.split_frame(ratios=[.8], seed=1234)\n",
    "\n",
    "\n",
    "model = H2OGradientBoostingEstimator(ntrees         =50,\n",
    "                                        max_depth      =6,\n",
    "                                        learn_rate     =0.1, \n",
    "                                        nfolds         =2)\n",
    "\n",
    "model.train(x               =predictors,\n",
    "               y               =response,\n",
    "               training_frame  =train,\n",
    "               validation_frame=valid\n",
    "               )\n",
    "\n",
    "\n",
    "print('deploying gbm')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_gbm')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_gbm',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sql started successfully\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd282f03-1932-4c6c-abc8-ea475d086cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deb5ce3-dac4-499d-9803-bd442b8d1758",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff06e92-a159-4a36-982d-ecef3bb3f6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_gbm (moment_key,sibsp,sex,age) values(0, 5,'female',2.496);\n",
    "insert into h2o_gbm (moment_key,sibsp,sex,age) values(1, 1,'male',-7.048);\n",
    "select * from h2o_gbm;\n",
    "select sibsp, sex, age, prediction, c0, c1 into ${data_and_preds} from h2o_gbm;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['SIBSP','SEX','AGE']])\n",
    "db_preds = data[['PREDICTION','C0','C1']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p, db_c0, db_c1 = db_pred[1]\n",
    "    raw_p, raw_c0, raw_c1 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    raw_p = f'C{int(raw_p)}'\n",
    "    \n",
    "    assert db_p == raw_p, f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    assert round(db_c0,14) == round(raw_c0,14), f'Something is wrong. Model Table gives {db_c0} but raw model gives {raw_c0}'\n",
    "    assert round(db_c1,14) == round(raw_c1,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "deploying multinomial\n",
      "Saving artifact of size: 110.721 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 21:23:00.995 - A service worker has found your request\n",
      "INFO     2020-11-25 21:23:01.039 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 21:23:01.074 - Handler is available\n",
      "INFO     2020-11-25 21:23:01.099 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 21:23:01.165 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 21:23:01.188 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 21:23:01.242 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 21:23:01.266 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 21:23:01.300 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 21:23:01.332 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 21:23:01.359 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 21:23:01.385 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 21:23:01.468 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 21:23:01.496 - Done.\n",
      "INFO     2020-11-25 21:23:01.520 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 21:23:01.652 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 21:23:01.679 - Adding Serialized Representation\n",
      "INFO     2020-11-25 21:23:01.831 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 21:23:01.858 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 21:23:01.881 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 21:23:01.909 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 21:23:01.940 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 21:23:01.987 - Executing\n",
      "CREATE TABLE splice.h2o_multinomial (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '6114efe044ba',\n",
      "                DISPLACEMENT FLOAT, POWER SMALLINT, WEIGHT SMALLINT, ACCELERATION FLOAT, YEAR_MAKE TINYINT,MOMENT_KEY INTEGER,PREDICTION VARCHAR(5000),\"C3\" DOUBLE,\"C4\" DOUBLE,\"C5\" DOUBLE,\"C6\" DOUBLE,\"C8\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 21:23:02.837 - Done with 'creating model deployment table' [in 897.4802494049072 ms]\n",
      "INFO     2020-11-25 21:23:02.863 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 21:23:02.887 - Creating Prediction Trigger...\n",
      "INFO     2020-11-25 21:23:02.912 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_multinomial_6114efe044ba\n",
      "                           BEFORE INSERT ON splice.h2o_multinomial REFERENCING NEW AS NEWROW \n",
      "                           FOR EACH ROW SET NEWROW.PREDICTION=MLMANAGER.PREDICT_CLASSIFICATION('6114efe044ba',TRIM(CAST(CAST(NEWROW.DISPLACEMENT as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(NEWROW.POWER as CHAR(41)))||','||TRIM(CAST(NEWROW.WEIGHT as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.ACCELERATION as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(NEWROW.YEAR_MAKE as CHAR(41))),\n",
      "'displacement FLOAT, power SMALLINT, weight SMALLINT, acceleration FLOAT, year_make TINYINT')\n",
      "INFO     2020-11-25 21:23:03.102 - Done with 'creating trigger' [in 239.61234092712402 ms]\n",
      "INFO     2020-11-25 21:23:03.128 - Starting 'create parsing trigger'...\n",
      "INFO     2020-11-25 21:23:03.156 - Creating parsing trigger...\n",
      "INFO     2020-11-25 21:23:03.179 - Executing\n",
      "CREATE TRIGGER splice.PARSERESULT_h2o_multinomial_6114efe044ba                                 BEFORE INSERT ON splice.h2o_multinomial REFERENCING NEW AS NEWROW                                 FOR EACH ROW set NEWROW.\"C3\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,0),NEWROW.\"C4\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,1),NEWROW.\"C5\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,2),NEWROW.\"C6\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,3),NEWROW.\"C8\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,4),NEWROW.PREDICTION=   CASE   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=0 then 'C3'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=1 then 'C4'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=2 then 'C5'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=3 then 'C6'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=4 then 'C8'   END;\n",
      "INFO     2020-11-25 21:23:03.563 - Done with 'create parsing trigger' [in 434.75866317749023 ms]\n",
      "INFO     2020-11-25 21:23:03.591 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 21:23:03.617 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 21:23:03.725 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 21:23:03.793 - Done executing.\n",
      "INFO     2020-11-25 21:23:03.817 - Done with 'add model to metadata table' [in 226.04608535766602 ms]\n",
      "INFO     2020-11-25 21:23:03.839 - Flushing\n",
      "WARNING  2020-11-25 21:23:03.861 - Committing Transaction to Database\n",
      "INFO     2020-11-25 21:23:03.913 - Committed.\n",
      "INFO     2020-11-25 21:23:03.938 - Cleaning up deployment\n",
      "INFO     2020-11-25 21:23:03.980 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 21:23:04.026 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars[\"cylinders\"] = cars[\"cylinders\"].asfactor()\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response_col = \"cylinders\"\n",
    "distribution = \"multinomial\"\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "\n",
    "train.rename(columns={'year':'year_make'})\n",
    "\n",
    "model = H2OGradientBoostingEstimator(nfolds=3,\n",
    "                                   distribution=distribution)\n",
    "model.train(x=predictors,\n",
    "          y=response_col,\n",
    "          training_frame=train,\n",
    "          validation_frame=valid)\n",
    "\n",
    "\n",
    "\n",
    "print('deploying multinomial')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_multinomial')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_multinomial',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9dca7b-28d5-4b36-b793-fe7861f87994",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c648fed-ea76-4931-af0d-74fca466c0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6627ba9-4700-4cf9-90fc-51409be409a2",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_multinomial (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_multinomial (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_multinomial;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make,prediction, c3,c4,c5,c6,c8 into ${data_and_preds} from h2o_multinomial;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION','C3','C4','C5','C6','C8']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p, db_c0, db_c1, db_c2, db_c3, db_c4 = db_pred[1]\n",
    "    raw_p, raw_c0, raw_c1, raw_c2, raw_c3, raw_c4 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    raw_p = f'C{int(raw_p)}'\n",
    "    \n",
    "    assert db_p == raw_p, f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    assert round(db_c0,14) == round(raw_c0,14), f'Something is wrong. Model Table gives {db_c0} but raw model gives {raw_c0}'\n",
    "    assert round(db_c1,14) == round(raw_c1,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c2,14) == round(raw_c2,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c3,14) == round(raw_c3,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c4,14) == round(raw_c4,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reached maximum number of iterations 50!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploying ordinal\n",
      "Saving artifact of size: 7.966 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 21:23:14.985 - A service worker has found your request\n",
      "INFO     2020-11-25 21:23:15.025 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 21:23:15.059 - Handler is available\n",
      "INFO     2020-11-25 21:23:15.081 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 21:23:15.146 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 21:23:15.168 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 21:23:15.215 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 21:23:15.236 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 21:23:15.268 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 21:23:15.295 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 21:23:15.318 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 21:23:15.339 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 21:23:15.477 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 21:23:15.501 - Done.\n",
      "INFO     2020-11-25 21:23:15.523 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 21:23:15.612 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 21:23:15.636 - Adding Serialized Representation\n",
      "INFO     2020-11-25 21:23:15.702 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 21:23:15.727 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 21:23:15.750 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 21:23:15.781 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 21:23:15.812 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 21:23:15.859 - Executing\n",
      "CREATE TABLE splice.h2o_ordinal (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT 'f7caa7d3838d',\n",
      "                DISPLACEMENT FLOAT, POWER SMALLINT, WEIGHT SMALLINT, ACCELERATION FLOAT, YEAR_MAKE TINYINT,MOMENT_KEY INTEGER,PREDICTION VARCHAR(5000),\"C3\" DOUBLE,\"C4\" DOUBLE,\"C5\" DOUBLE,\"C6\" DOUBLE,\"C8\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 21:23:16.697 - Done with 'creating model deployment table' [in 884.6268653869629 ms]\n",
      "INFO     2020-11-25 21:23:16.720 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 21:23:16.742 - Creating Prediction Trigger...\n",
      "INFO     2020-11-25 21:23:16.764 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_ordinal_f7caa7d3838d\n",
      "                           BEFORE INSERT ON splice.h2o_ordinal REFERENCING NEW AS NEWROW \n",
      "                           FOR EACH ROW SET NEWROW.PREDICTION=MLMANAGER.PREDICT_CLASSIFICATION('f7caa7d3838d',TRIM(CAST(CAST(NEWROW.DISPLACEMENT as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(NEWROW.POWER as CHAR(41)))||','||TRIM(CAST(NEWROW.WEIGHT as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.ACCELERATION as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(NEWROW.YEAR_MAKE as CHAR(41))),\n",
      "'displacement FLOAT, power SMALLINT, weight SMALLINT, acceleration FLOAT, year_make TINYINT')\n",
      "INFO     2020-11-25 21:23:16.940 - Done with 'creating trigger' [in 219.88487243652344 ms]\n",
      "INFO     2020-11-25 21:23:16.964 - Starting 'create parsing trigger'...\n",
      "INFO     2020-11-25 21:23:16.987 - Creating parsing trigger...\n",
      "INFO     2020-11-25 21:23:17.010 - Executing\n",
      "CREATE TRIGGER splice.PARSERESULT_h2o_ordinal_f7caa7d3838d                                 BEFORE INSERT ON splice.h2o_ordinal REFERENCING NEW AS NEWROW                                 FOR EACH ROW set NEWROW.\"C3\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,0),NEWROW.\"C4\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,1),NEWROW.\"C5\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,2),NEWROW.\"C6\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,3),NEWROW.\"C8\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,4),NEWROW.PREDICTION=   CASE   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=0 then 'C3'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=1 then 'C4'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=2 then 'C5'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=3 then 'C6'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=4 then 'C8'   END;\n",
      "INFO     2020-11-25 21:23:17.359 - Done with 'create parsing trigger' [in 394.75226402282715 ms]\n",
      "INFO     2020-11-25 21:23:17.384 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 21:23:17.409 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 21:23:17.520 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 21:23:17.593 - Done executing.\n",
      "INFO     2020-11-25 21:23:17.618 - Done with 'add model to metadata table' [in 234.67278480529785 ms]\n",
      "INFO     2020-11-25 21:23:17.642 - Flushing\n",
      "WARNING  2020-11-25 21:23:17.666 - Committing Transaction to Database\n",
      "INFO     2020-11-25 21:23:17.718 - Committed.\n",
      "INFO     2020-11-25 21:23:17.744 - Cleaning up deployment\n",
      "INFO     2020-11-25 21:23:17.789 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 21:23:17.835 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars[\"cylinders\"] = cars[\"cylinders\"].asfactor()\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response = \"cylinders\"\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "model = H2OGeneralizedLinearEstimator(seed=1234,\n",
    "                                         family='ordinal')\n",
    "model.train(x=predictors,\n",
    "               y=response,\n",
    "               training_frame=train,\n",
    "               validation_frame=valid)\n",
    "\n",
    "\n",
    "print('deploying ordinal')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_ordinal')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_ordinal',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103445e8-ac6e-4768-9291-7cd1490a88c8",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fb3a02-7d73-4932-9449-f386dba3d22a",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f108a5b-5e68-43ca-8adf-de383ca15a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_ordinal (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_ordinal (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_ordinal;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make,prediction, c3,c4,c5,c6,c8 into ${data_and_preds} from h2o_ordinal;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION','C3','C4','C5','C6','C8']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p, db_c0, db_c1, db_c2, db_c3, db_c4 = db_pred[1]\n",
    "    raw_p, raw_c0, raw_c1, raw_c2, raw_c3, raw_c4 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    raw_p = f'C{int(raw_p)}'\n",
    "    \n",
    "    assert db_p == raw_p, f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    assert round(db_c0,14) == round(raw_c0,14), f'Something is wrong. Model Table gives {db_c0} but raw model gives {raw_c0}'\n",
    "    assert round(db_c1,14) == round(raw_c1,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c2,14) == round(raw_c2,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c3,14) == round(raw_c3,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c4,14) == round(raw_c4,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploying regression\n",
      "Table exists. Dropping table\n",
      "Saving artifact of size: 37.898 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 21:25:22.501 - A service worker has found your request\n",
      "INFO     2020-11-25 21:25:22.543 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 21:25:22.576 - Handler is available\n",
      "INFO     2020-11-25 21:25:22.600 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 21:25:22.702 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 21:25:22.724 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 21:25:22.769 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 21:25:22.787 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 21:25:22.815 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 21:25:22.841 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 21:25:22.863 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 21:25:22.883 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 21:25:22.950 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 21:25:22.971 - Done.\n",
      "INFO     2020-11-25 21:25:22.992 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 21:25:23.085 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 21:25:23.108 - Adding Serialized Representation\n",
      "INFO     2020-11-25 21:25:23.215 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 21:25:23.237 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 21:25:23.256 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 21:25:23.277 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 21:25:23.304 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 21:25:23.352 - Executing\n",
      "CREATE TABLE splice.h2o_regression (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT 'a46398b64f99',\n",
      "                DISPLACEMENT FLOAT, POWER SMALLINT, WEIGHT SMALLINT, ACCELERATION FLOAT, YEAR_MAKE TINYINT,MOMENT_KEY INTEGER,PREDICTION DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 21:25:24.173 - Done with 'creating model deployment table' [in 869.7855472564697 ms]\n",
      "INFO     2020-11-25 21:25:24.195 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 21:25:24.215 - Creating Prediction Trigger...\n",
      "INFO     2020-11-25 21:25:24.238 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_regression_a46398b64f99\n",
      "                           BEFORE INSERT ON splice.h2o_regression REFERENCING NEW AS NEWROW \n",
      "                           FOR EACH ROW SET NEWROW.PREDICTION=MLMANAGER.PREDICT_REGRESSION('a46398b64f99',TRIM(CAST(CAST(NEWROW.DISPLACEMENT as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(NEWROW.POWER as CHAR(41)))||','||TRIM(CAST(NEWROW.WEIGHT as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.ACCELERATION as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(NEWROW.YEAR_MAKE as CHAR(41))),\n",
      "'displacement FLOAT, power SMALLINT, weight SMALLINT, acceleration FLOAT, year_make TINYINT')\n",
      "INFO     2020-11-25 21:25:24.386 - Done with 'creating trigger' [in 191.60938262939453 ms]\n",
      "INFO     2020-11-25 21:25:24.409 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 21:25:24.431 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 21:25:24.522 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 21:25:24.581 - Done executing.\n",
      "INFO     2020-11-25 21:25:24.604 - Done with 'add model to metadata table' [in 194.46492195129395 ms]\n",
      "INFO     2020-11-25 21:25:24.624 - Flushing\n",
      "WARNING  2020-11-25 21:25:24.645 - Committing Transaction to Database\n",
      "INFO     2020-11-25 21:25:24.685 - Committed.\n",
      "INFO     2020-11-25 21:25:24.707 - Cleaning up deployment\n",
      "INFO     2020-11-25 21:25:24.749 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 21:25:24.792 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response_col = \"economy\"\n",
    "distribution = \"gaussian\"\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "model = H2OGradientBoostingEstimator(nfolds=3,\n",
    "                                   distribution=distribution,\n",
    "                                   fold_assignment=\"Random\")\n",
    "model.train(x=predictors,\n",
    "          y=response_col,\n",
    "          training_frame=train,\n",
    "          validation_frame=valid)\n",
    "model.plot(timestep=\"AUTO\", metric=\"AUTO\",)\n",
    "\n",
    "\n",
    "print('deploying regression')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_regression')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_regression',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667c2c22-cacd-4791-815f-fe3b0b02498f",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b574cf70-4e82-4c62-831d-66acc354ce97",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d435d7-6022-414f-9597-1c434976e16b",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_regression (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_regression (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_regression;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make,prediction into ${data_and_preds} from h2o_regression;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p = db_pred[1]['PREDICTION']\n",
    "    raw_p = raw_pred[1]['predict']\n",
    "    \n",
    "    l = min(16, len(str(db_p)), len(str(raw_p))) -2 # -2 because of the decimal point and final value\n",
    "    assert round(db_p,l) == round(raw_p,l), f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HGLM Model example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "deploying hglm\n",
      "Saving artifact of size: 5.801 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 21:27:45.551 - A service worker has found your request\n",
      "INFO     2020-11-25 21:27:45.592 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 21:27:45.626 - Handler is available\n",
      "INFO     2020-11-25 21:27:45.647 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 21:27:45.710 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 21:27:45.733 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 21:27:45.782 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 21:27:45.804 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 21:27:45.834 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 21:27:45.861 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 21:27:45.883 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 21:27:45.904 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 21:27:45.985 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 21:27:46.009 - Done.\n",
      "INFO     2020-11-25 21:27:46.031 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 21:27:46.115 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 21:27:46.136 - Adding Serialized Representation\n",
      "INFO     2020-11-25 21:27:46.193 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 21:27:46.215 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 21:27:46.234 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 21:27:46.256 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 21:27:46.281 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 21:27:46.326 - Executing\n",
      "CREATE TABLE splice.h2o_hglm (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '1314d88d14f4',\n",
      "                DISPLACEMENT SMALLINT, POWER SMALLINT, WEIGHT SMALLINT, ACCELERATION FLOAT, YEAR_MAKE TINYINT,MOMENT_KEY INTEGER,PREDICTION DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 21:27:47.148 - Done with 'creating model deployment table' [in 867.3121929168701 ms]\n",
      "INFO     2020-11-25 21:27:47.173 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 21:27:47.195 - Creating Prediction Trigger...\n",
      "INFO     2020-11-25 21:27:47.216 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_hglm_1314d88d14f4\n",
      "                           BEFORE INSERT ON splice.h2o_hglm REFERENCING NEW AS NEWROW \n",
      "                           FOR EACH ROW SET NEWROW.PREDICTION=MLMANAGER.PREDICT_REGRESSION('1314d88d14f4',TRIM(CAST(NEWROW.DISPLACEMENT as CHAR(41)))||','||TRIM(CAST(NEWROW.POWER as CHAR(41)))||','||TRIM(CAST(NEWROW.WEIGHT as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.ACCELERATION as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(NEWROW.YEAR_MAKE as CHAR(41))),\n",
      "'displacement SMALLINT, power SMALLINT, weight SMALLINT, acceleration FLOAT, year_make TINYINT')\n",
      "INFO     2020-11-25 21:27:47.375 - Done with 'creating trigger' [in 202.27980613708496 ms]\n",
      "INFO     2020-11-25 21:27:47.397 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 21:27:47.419 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 21:27:47.512 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 21:27:47.573 - Done executing.\n",
      "INFO     2020-11-25 21:27:47.595 - Done with 'add model to metadata table' [in 197.74746894836426 ms]\n",
      "INFO     2020-11-25 21:27:47.617 - Flushing\n",
      "WARNING  2020-11-25 21:27:47.638 - Committing Transaction to Database\n",
      "INFO     2020-11-25 21:27:47.679 - Committed.\n",
      "INFO     2020-11-25 21:27:47.700 - Cleaning up deployment\n",
      "INFO     2020-11-25 21:27:47.741 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 21:27:47.780 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response = \"economy\"\n",
    "distribution = \"gaussian\"\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "model = H2OGeneralizedLinearEstimator(alpha=.25)\n",
    "model.train(x=predictors,\n",
    "                 y=response,\n",
    "                 training_frame=train,\n",
    "                 validation_frame=valid)\n",
    "\n",
    "\n",
    "print('deploying hglm')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_hglm')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_hglm',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549442a2-4d9b-4732-b16a-896817a63025",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8152f725-2301-4abc-b9c6-d656379812f3",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b216ab8-6233-48b0-a3f3-2edac793d300",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_hglm (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_hglm (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_hglm;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make,prediction into ${data_and_preds} from h2o_hglm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p = db_pred[1]['PREDICTION']\n",
    "    raw_p = raw_pred[1]['predict']\n",
    "    \n",
    "    l = min(16, len(str(db_p)), len(str(raw_p))) -2\n",
    "    assert round(db_p,l) == round(raw_p,l), f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Build word2vec model\n",
      "word2vec Model Build progress: |██████████████████████████████████████████| 100%\n",
      "Sanity check - find synonyms for the word 'teacher'\n",
      "deploying w2v\n",
      "Saving artifact of size: 103.279 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 21:28:20.546 - A service worker has found your request\n",
      "INFO     2020-11-25 21:28:20.583 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 21:28:20.620 - Handler is available\n",
      "INFO     2020-11-25 21:28:20.640 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 21:28:20.700 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 21:28:20.720 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 21:28:20.763 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 21:28:20.781 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 21:28:20.809 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 21:28:20.835 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 21:28:20.857 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 21:28:20.877 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 21:28:20.949 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 21:28:20.972 - Done.\n",
      "INFO     2020-11-25 21:28:20.991 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 21:28:21.082 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 21:28:21.102 - Adding Serialized Representation\n",
      "INFO     2020-11-25 21:28:21.223 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 21:28:21.243 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 21:28:21.262 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 21:28:21.295 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 21:28:21.319 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 21:28:21.361 - Executing\n",
      "CREATE TABLE splice.h2o_w2v (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT 'ad284a2071ee',\n",
      "                WORD VARCHAR(5000),MOMENT_KEY INTEGER,\"word_C0\" DOUBLE,\"word_C1\" DOUBLE,\"word_C2\" DOUBLE,\"word_C3\" DOUBLE,\"word_C4\" DOUBLE,\"word_C5\" DOUBLE,\"word_C6\" DOUBLE,\"word_C7\" DOUBLE,\"word_C8\" DOUBLE,\"word_C9\" DOUBLE,\"word_C10\" DOUBLE,\"word_C11\" DOUBLE,\"word_C12\" DOUBLE,\"word_C13\" DOUBLE,\"word_C14\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 21:28:22.186 - Done with 'creating model deployment table' [in 867.0451641082764 ms]\n",
      "INFO     2020-11-25 21:28:22.206 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 21:28:22.224 - Creating VTI Prediction Trigger...\n",
      "INFO     2020-11-25 21:28:22.243 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_w2v_ad284a2071ee \n",
      "                        AFTER INSERT ON splice.h2o_w2v REFERENCING NEW AS NEWROW FOR EACH ROW\n",
      "                        UPDATE splice.h2o_w2v SET (\"word_C0\",\"word_C1\",\"word_C2\",\"word_C3\",\"word_C4\",\"word_C5\",\"word_C6\",\"word_C7\",\"word_C8\",\"word_C9\",\"word_C10\",\"word_C11\",\"word_C12\",\"word_C13\",\"word_C14\") = (SELECT b.\"word_C0\",b.\"word_C1\",b.\"word_C2\",b.\"word_C3\",b.\"word_C4\",b.\"word_C5\",b.\"word_C6\",b.\"word_C7\",b.\"word_C8\",b.\"word_C9\",b.\"word_C10\",b.\"word_C11\",b.\"word_C12\",b.\"word_C13\",b.\"word_C14\" FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', 'ad284a2071ee', NEWROW.WORD, \n",
      "        'word VARCHAR(5000)') as b (\"word_C0\" DOUBLE,\"word_C1\" DOUBLE,\"word_C2\" DOUBLE,\"word_C3\" DOUBLE,\"word_C4\" DOUBLE,\"word_C5\" DOUBLE,\"word_C6\" DOUBLE,\"word_C7\" DOUBLE,\"word_C8\" DOUBLE,\"word_C9\" DOUBLE,\"word_C10\" DOUBLE,\"word_C11\" DOUBLE,\"word_C12\" DOUBLE,\"word_C13\" DOUBLE,\"word_C14\" DOUBLE) WHERE 1=1) WHERE MOMENT_KEY = NEWROW.MOMENT_KEY\n",
      "INFO     2020-11-25 21:28:22.574 - Done with 'creating trigger' [in 367.89846420288086 ms]\n",
      "INFO     2020-11-25 21:28:22.594 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 21:28:22.614 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 21:28:22.699 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 21:28:22.752 - Done executing.\n",
      "INFO     2020-11-25 21:28:22.773 - Done with 'add model to metadata table' [in 178.64155769348145 ms]\n",
      "INFO     2020-11-25 21:28:22.792 - Flushing\n",
      "WARNING  2020-11-25 21:28:22.810 - Committing Transaction to Database\n",
      "INFO     2020-11-25 21:28:22.849 - Committed.\n",
      "INFO     2020-11-25 21:28:22.870 - Cleaning up deployment\n",
      "INFO     2020-11-25 21:28:22.910 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 21:28:22.948 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.word2vec import H2OWord2vecEstimator\n",
    "job_titles_path = \"https://raw.githubusercontent.com/h2oai/sparkling-water/rel-1.6/examples/smalldata/craigslistJobTitles.csv\"\n",
    "job_titles = h2o.import_file(job_titles_path, destination_frame = \"jobtitles\",\n",
    "                             col_names = [\"category\", \"jobtitle\"], col_types = [\"enum\", \"string\"], header = 1)\n",
    "STOP_WORDS = [\"ax\",\"i\",\"you\",\"edu\",\"s\",\"t\",\"m\",\"subject\",\"can\",\"lines\",\"re\",\"what\",\n",
    "               \"there\",\"all\",\"we\",\"one\",\"the\",\"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\n",
    "               \"but\",\"is\",\"in\",\"a\",\"not\",\"with\",\"as\",\"was\",\"if\",\"they\",\"are\",\"this\",\"and\",\"it\",\"have\",\n",
    "               \"from\",\"at\",\"my\",\"be\",\"by\",\"not\",\"that\",\"to\",\"from\",\"com\",\"org\",\"like\",\"likes\",\"so\"]\n",
    "\n",
    "def tokenize(sentences, stop_word = STOP_WORDS):\n",
    "    tokenized = sentences.tokenize(\"\\\\W+\")\n",
    "    tokenized_lower = tokenized.tolower()\n",
    "    tokenized_filtered = tokenized_lower[(tokenized_lower.nchar() >= 2) | (tokenized_lower.isna()),:]\n",
    "    tokenized_words = tokenized_filtered[tokenized_filtered.grep(\"[0-9]\",invert=True,output_logical=True),:]\n",
    "    tokenized_words = tokenized_words[(tokenized_words.isna()) | (~ tokenized_words.isin(STOP_WORDS)),:]\n",
    "    return tokenized_words\n",
    "\n",
    "\n",
    "words = tokenize(job_titles[\"jobtitle\"])\n",
    "words.columns = ['word']\n",
    "\n",
    "print(\"Build word2vec model\")\n",
    "model = H2OWord2vecEstimator(sent_sample_rate = 0.0, epochs = 10, vec_size=15)\n",
    "model.train(training_frame=words)\n",
    "\n",
    "\n",
    "print(\"Sanity check - find synonyms for the word 'teacher'\")\n",
    "model.find_synonyms(\"teacher\", count = 5)\n",
    "\n",
    "print('deploying w2v')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_w2v')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_w2v',mlflow.current_run_id(), df=hc.asSparkFrame(words), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c6591f-83b2-4f86-b7de-e524ed30f69b",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f6e8df-7d9f-47c0-a079-0666beff6b48",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfe1214-5413-40cf-bbaf-d8080c723200",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f421c8-6cad-47cc-84c9-afd60a56d5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "insert into h2o_w2v (word, moment_key) values('teacher', 1);\n",
    "insert into h2o_w2v (word, moment_key) values('teachers', 2);\n",
    "insert into h2o_w2v (word, moment_key) values('elementary', 3);\n",
    "\n",
    "select * from h2o_w2v;\n",
    "select * into ${data_and_preds} from h2o_w2v;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['WORD']])\n",
    "db_preds = data[['word_C0','word_C1','word_C2','word_C3','word_C4','word_C5','word_C6','word_C7','word_C8','word_C9','word_C10','word_C11','word_C12','word_C13','word_C14']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.transform(features,aggregate_method=None).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "#     db_p, db_c0, db_c1, db_c2, db_c3, db_c4 = db_pred[1]\n",
    "#     raw_p, raw_c0, raw_c1, raw_c2, raw_c3, raw_c4 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,14) == round(raw,14), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  reconstr_C1.SE</th><th style=\"text-align: right;\">  reconstr_C2.SE</th><th style=\"text-align: right;\">  reconstr_C3.SE</th><th style=\"text-align: right;\">  reconstr_C4.SE</th><th style=\"text-align: right;\">  reconstr_C5.SE</th><th style=\"text-align: right;\">  reconstr_C6.SE</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">     0.0968696  </td><td style=\"text-align: right;\">      0.00186831</td><td style=\"text-align: right;\">      0.0236483 </td><td style=\"text-align: right;\">      0.316328  </td><td style=\"text-align: right;\">     0.0154392  </td><td style=\"text-align: right;\">      0.072383  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0.0900991  </td><td style=\"text-align: right;\">      0.144147  </td><td style=\"text-align: right;\">      0.0244125 </td><td style=\"text-align: right;\">      0.163053  </td><td style=\"text-align: right;\">     0.113798   </td><td style=\"text-align: right;\">      0.0200023 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0.00655416 </td><td style=\"text-align: right;\">      0.22751   </td><td style=\"text-align: right;\">      0.169456  </td><td style=\"text-align: right;\">      0.00301388</td><td style=\"text-align: right;\">     0.12906    </td><td style=\"text-align: right;\">      0.0128973 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0.0041591  </td><td style=\"text-align: right;\">      5.21e-07  </td><td style=\"text-align: right;\">      0.0187153 </td><td style=\"text-align: right;\">      0.00118691</td><td style=\"text-align: right;\">     0.0201489  </td><td style=\"text-align: right;\">      0.0358883 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0.00434698 </td><td style=\"text-align: right;\">      0.0863694 </td><td style=\"text-align: right;\">      0.132245  </td><td style=\"text-align: right;\">      0.0833289 </td><td style=\"text-align: right;\">     0.0622806  </td><td style=\"text-align: right;\">      0.127037  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0.0231179  </td><td style=\"text-align: right;\">      0.235324  </td><td style=\"text-align: right;\">      0.218086  </td><td style=\"text-align: right;\">      0.00134694</td><td style=\"text-align: right;\">     0.187245   </td><td style=\"text-align: right;\">      0.0499606 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0.0227876  </td><td style=\"text-align: right;\">      0.067962  </td><td style=\"text-align: right;\">      0.0901349 </td><td style=\"text-align: right;\">      0.129349  </td><td style=\"text-align: right;\">     0.00521986 </td><td style=\"text-align: right;\">      0.00191159</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0.00639448 </td><td style=\"text-align: right;\">      0.126894  </td><td style=\"text-align: right;\">      4.2368e-05</td><td style=\"text-align: right;\">      0.00666487</td><td style=\"text-align: right;\">     0.000802673</td><td style=\"text-align: right;\">      0.170669  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0.0154813  </td><td style=\"text-align: right;\">      0.0236197 </td><td style=\"text-align: right;\">      0.0515209 </td><td style=\"text-align: right;\">      0.0939627 </td><td style=\"text-align: right;\">     0.00230567 </td><td style=\"text-align: right;\">      0.00104477</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0.000706211</td><td style=\"text-align: right;\">      0.109755  </td><td style=\"text-align: right;\">      0.169829  </td><td style=\"text-align: right;\">      0.0557486 </td><td style=\"text-align: right;\">     0.0671676  </td><td style=\"text-align: right;\">      0.120217  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n",
      "deploying autoencoder\n",
      "Saving artifact of size: 7.679 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 21:28:38.848 - A service worker has found your request\n",
      "INFO     2020-11-25 21:28:38.880 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 21:28:38.914 - Handler is available\n",
      "INFO     2020-11-25 21:28:38.934 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 21:28:39.007 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 21:28:39.025 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 21:28:39.066 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 21:28:39.083 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 21:28:39.108 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 21:28:39.130 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 21:28:39.149 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 21:28:39.167 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 21:28:39.281 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 21:28:39.300 - Done.\n",
      "INFO     2020-11-25 21:28:39.318 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 21:28:39.397 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 21:28:39.416 - Adding Serialized Representation\n",
      "INFO     2020-11-25 21:28:39.509 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 21:28:39.528 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 21:28:39.548 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 21:28:39.571 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 21:28:39.596 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 21:28:39.640 - Executing\n",
      "CREATE TABLE splice.h2o_ae (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT 'ca984568f598',\n",
      "                C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT,MOMENT_KEY INTEGER,\"C1_reconstr\" DOUBLE,\"C2_reconstr\" DOUBLE,\"C3_reconstr\" DOUBLE,\"C4_reconstr\" DOUBLE,\"C5_reconstr\" DOUBLE,\"C6_reconstr\" DOUBLE,\"MSE_reconstr\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 21:28:40.457 - Done with 'creating model deployment table' [in 860.5484962463379 ms]\n",
      "INFO     2020-11-25 21:28:40.477 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 21:28:40.497 - Creating VTI Prediction Trigger...\n",
      "INFO     2020-11-25 21:28:40.515 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_ae_ca984568f598 \n",
      "                        AFTER INSERT ON splice.h2o_ae REFERENCING NEW AS NEWROW FOR EACH ROW\n",
      "                        UPDATE splice.h2o_ae SET (\"C1_reconstr\",\"C2_reconstr\",\"C3_reconstr\",\"C4_reconstr\",\"C5_reconstr\",\"C6_reconstr\",\"MSE_reconstr\") = (SELECT b.\"C1_reconstr\",b.\"C2_reconstr\",b.\"C3_reconstr\",b.\"C4_reconstr\",b.\"C5_reconstr\",b.\"C6_reconstr\",b.\"MSE_reconstr\" FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', 'ca984568f598', TRIM(CAST(CAST(NEWROW.C1 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C2 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C3 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C4 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C5 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C6 as DECIMAL(38,10)) as CHAR(41))), \n",
      "        'C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT') as b (\"C1_reconstr\" DOUBLE,\"C2_reconstr\" DOUBLE,\"C3_reconstr\" DOUBLE,\"C4_reconstr\" DOUBLE,\"C5_reconstr\" DOUBLE,\"C6_reconstr\" DOUBLE,\"MSE_reconstr\" DOUBLE) WHERE 1=1) WHERE MOMENT_KEY = NEWROW.MOMENT_KEY\n",
      "INFO     2020-11-25 21:28:40.835 - Done with 'creating trigger' [in 357.6703071594238 ms]\n",
      "INFO     2020-11-25 21:28:40.856 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 21:28:40.998 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 21:28:41.084 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 21:28:41.137 - Done executing.\n",
      "INFO     2020-11-25 21:28:41.157 - Done with 'add model to metadata table' [in 301.4874458312988 ms]\n",
      "INFO     2020-11-25 21:28:41.176 - Flushing\n",
      "WARNING  2020-11-25 21:28:41.196 - Committing Transaction to Database\n",
      "INFO     2020-11-25 21:28:41.233 - Committed.\n",
      "INFO     2020-11-25 21:28:41.253 - Cleaning up deployment\n",
      "INFO     2020-11-25 21:28:41.293 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 21:28:41.331 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
    "# train = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/bigdata/laptop/mnist/train.csv.gz\")\n",
    "# test = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/bigdata/laptop/mnist/test.csv.gz\")\n",
    "\n",
    "import random\n",
    "train = []\n",
    "test = []\n",
    "for i in range(60000):\n",
    "    train.append([random.random()*4 for i in range(6)])\n",
    "    test.append([random.random()*4 for i in range(6)])\n",
    "\n",
    "train = h2o.H2OFrame(train)\n",
    "test = h2o.H2OFrame(test)\n",
    "predictors = [f'C{i}' for i in range(1,7)]\n",
    "\n",
    "\n",
    "model = H2OAutoEncoderEstimator(activation=\"Tanh\",\n",
    "                                   hidden=[2],\n",
    "                                   l1=1e-5,\n",
    "                                   ignore_const_cols=False,\n",
    "                                   epochs=1)\n",
    "model.train(x=predictors,training_frame=train)\n",
    "test_rec_error = model.anomaly(test)\n",
    "test_rec_error\n",
    "test_rec_error_features = model.anomaly(test, per_feature=True)\n",
    "print(test_rec_error_features)\n",
    "model.predict(test)\n",
    "\n",
    "print('deploying autoencoder')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_ae')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_ae',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7a1e6d-d097-4df4-828a-791896d9d33b",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6ced4b-bbbf-4e4f-8e5a-49de6b855050",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121f0b01-6055-4b05-942c-ec16bdc96584",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7087713a-3d7b-42c1-bfef-abc08e18f1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_ae (moment_key,c1,c2,c3,c4,c5,c6) values(1,0, 0, 0, 0, 0, 0);\n",
    "insert into h2o_ae (moment_key,c1,c2,c3,c4,c5,c6) values(2,1, 1, 1, 1, 1, 1);\n",
    "insert into h2o_ae (moment_key,c1,c2,c3,c4,c5,c6) values(3,0.25, 0.99, 0.623, 0.21, 0.52, 0.66);\n",
    "\n",
    "select * from h2o_ae;\n",
    "select * into ${data_and_preds} from h2o_ae;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['C1','C2','C3','C4','C5','C6']])\n",
    "db_preds = data[['C1_reconstr','C2_reconstr','C3_reconstr','C4_reconstr','C5_reconstr','C6_reconstr']]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "# Check the MSE score\n",
    "raw_mses = model.anomaly(features).as_data_frame(use_pandas=True)\n",
    "db_mses = data[['MSE_reconstr']]\n",
    "for db_mse, raw_mse in zip(db_mses.iterrows(), raw_mses.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "    \n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "kmeans Model Build progress: |████████████████████████████████████████████| 100%\n",
      "deploying clustering\n",
      "Saving artifact of size: 6.557 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 21:28:55.181 - A service worker has found your request\n",
      "INFO     2020-11-25 21:28:55.215 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 21:28:55.244 - Handler is available\n",
      "INFO     2020-11-25 21:28:55.264 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 21:28:55.329 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 21:28:55.349 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 21:28:55.396 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 21:28:55.417 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 21:28:55.444 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 21:28:55.470 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 21:28:55.491 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 21:28:55.511 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 21:28:55.611 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 21:28:55.633 - Done.\n",
      "INFO     2020-11-25 21:28:55.652 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 21:28:55.720 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 21:28:55.741 - Adding Serialized Representation\n",
      "INFO     2020-11-25 21:28:55.797 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 21:28:55.818 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 21:28:55.838 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 21:28:55.858 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 21:28:55.883 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 21:28:55.930 - Executing\n",
      "CREATE TABLE splice.h2o_cluster (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT 'ce35a49c5441',\n",
      "                C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT,MOMENT_KEY INTEGER,PREDICTION INT,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 21:28:56.744 - Done with 'creating model deployment table' [in 860.4588508605957 ms]\n",
      "INFO     2020-11-25 21:28:56.765 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 21:28:56.785 - Creating Prediction Trigger...\n",
      "INFO     2020-11-25 21:28:56.806 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_cluster_ce35a49c5441\n",
      "                           BEFORE INSERT ON splice.h2o_cluster REFERENCING NEW AS NEWROW \n",
      "                           FOR EACH ROW SET NEWROW.PREDICTION=MLMANAGER.PREDICT_CLUSTER('ce35a49c5441',TRIM(CAST(CAST(NEWROW.C1 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C2 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C3 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C4 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C5 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C6 as DECIMAL(38,10)) as CHAR(41))),\n",
      "'C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT')\n",
      "INFO     2020-11-25 21:28:56.954 - Done with 'creating trigger' [in 189.13817405700684 ms]\n",
      "INFO     2020-11-25 21:28:56.976 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 21:28:56.996 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 21:28:57.090 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 21:28:57.141 - Done executing.\n",
      "INFO     2020-11-25 21:28:57.161 - Done with 'add model to metadata table' [in 184.92817878723145 ms]\n",
      "INFO     2020-11-25 21:28:57.179 - Flushing\n",
      "WARNING  2020-11-25 21:28:57.197 - Committing Transaction to Database\n",
      "INFO     2020-11-25 21:28:57.234 - Committed.\n",
      "INFO     2020-11-25 21:28:57.254 - Cleaning up deployment\n",
      "INFO     2020-11-25 21:28:57.294 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 21:28:57.331 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.kmeans import H2OKMeansEstimator\n",
    "import random\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "for i in range(60000):\n",
    "    train.append([random.random()*4 for i in range(6)])\n",
    "    test.append([random.random()*4 for i in range(6)])\n",
    "\n",
    "train = h2o.H2OFrame(train)\n",
    "test = h2o.H2OFrame(test)\n",
    "predictors = [f'C{i}' for i in range(1,7)]\n",
    "\n",
    "\n",
    "model = H2OKMeansEstimator(k=3, nfolds=3)\n",
    "model.train(x=list(range(4)), training_frame=train)\n",
    "\n",
    "\n",
    "print('deploying clustering')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_cluster')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_cluster',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.download_artifact('model','/tmp/downloaded_model.zip','ce35a49c5441')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/downloaded_model.zip\n",
      "replace MLmodel? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip /tmp/downloaded_model.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/downloaded_model/model.h2o/KMeans_model_python_1606338895375_628\r\n"
     ]
    }
   ],
   "source": [
    "!ls /tmp/downloaded_model/model.h2o/KMeans_model_python_1606338895375_628"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/tmp/downloaded_model/model.h2o'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-7e70f3720c10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/downloaded_model/model.h2o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mupload_model\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m   1457\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mH2OEstimator\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \"\"\"\n\u001b[0;32m-> 1459\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /3/PostFile.bin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m     \u001b[0mframe_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"destination_frame\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /99/Models.upload.bin/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"dir\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mframe_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_data_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_file_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GET\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"DELETE\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_prepare_file_payload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabsfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File %s does not exist\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabsfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabsfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/tmp/downloaded_model/model.h2o'"
     ]
    }
   ],
   "source": [
    "h2o.upload_model('/tmp/downloaded_model/model.h2o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>29 mins 29 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.0.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>8 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>sparkling-water-jovyan_spark-application-1606338834225</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.718 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>5</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------------------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         29 mins 29 secs\n",
       "H2O_cluster_timezone:       UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.0.2\n",
       "H2O_cluster_version_age:    8 days\n",
       "H2O_cluster_name:           sparkling-water-jovyan_spark-application-1606338834225\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.718 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  5\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.8 final\n",
       "--------------------------  -------------------------------------------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "H2OResponseError",
     "evalue": "Server error water.exceptions.H2OIllegalArgumentException:\n  Error: Illegal argument: dir of function: importModel: water.api.FSIOException: FS IO Failure: \n accessed path : file:/tmp/downloaded_model/model.h2o/KMeans_model_python_1606338895375_628 msg: File not found\n  Request: POST /99/Models.bin/\n    data: {'dir': '/tmp/downloaded_model/model.h2o/KMeans_model_python_1606338895375_628'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-aeda2b6a8296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/downloaded_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_uri, suppress_warnings)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_code_to_system_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDATA\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlocal_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMAIN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pyfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mlflow/h2o.py\u001b[0m in \u001b[0;36m_load_pyfunc\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLocal\u001b[0m \u001b[0mfilesystem\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMLflow\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mh2o\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mflavor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_H2OModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mlflow/h2o.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(path, init)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \"\"\"\n\u001b[1;32m   1487\u001b[0m     \u001b[0massert_is_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1488\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /99/Models.bin/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"dir\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1489\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0msave_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_end_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(response, save_to)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;31m# Client errors (400 = \"Bad Request\", 404 = \"Not Found\", 412 = \"Precondition Failed\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m412\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH2OErrorV3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2OModelBuilderErrorV3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# Server errors (notably 500 = \"Server Error\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OResponseError\u001b[0m: Server error water.exceptions.H2OIllegalArgumentException:\n  Error: Illegal argument: dir of function: importModel: water.api.FSIOException: FS IO Failure: \n accessed path : file:/tmp/downloaded_model/model.h2o/KMeans_model_python_1606338895375_628 msg: File not found\n  Request: POST /99/Models.bin/\n    data: {'dir': '/tmp/downloaded_model/model.h2o/KMeans_model_python_1606338895375_628'}\n"
     ]
    }
   ],
   "source": [
    "x = mlflow.pyfunc.load_model('/tmp/downloaded_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "H2OResponseError",
     "evalue": "Server error water.exceptions.H2OIllegalArgumentException:\n  Error: Illegal argument: dir of function: importModel: water.api.FSIOException: FS IO Failure: \n accessed path : file:/tmp/downloaded_model/model.h2o/KMeans_model_python_1606338895375_628 msg: File not found\n  Request: POST /99/Models.bin/\n    data: {'dir': '/tmp/downloaded_model/model.h2o/KMeans_model_python_1606338895375_628'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-d184da54c5fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file:///tmp/downloaded_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mlflow/h2o.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_uri)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;31m# `data` key; in this case, we assume the model artifact path to be `model.h2o`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mh2o_model_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflavor_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.h2o\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh2o_model_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mlflow/h2o.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(path, init)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \"\"\"\n\u001b[1;32m   1487\u001b[0m     \u001b[0massert_is_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1488\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /99/Models.bin/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"dir\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1489\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0msave_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_end_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(response, save_to)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;31m# Client errors (400 = \"Bad Request\", 404 = \"Not Found\", 412 = \"Precondition Failed\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m412\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH2OErrorV3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2OModelBuilderErrorV3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# Server errors (notably 500 = \"Server Error\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OResponseError\u001b[0m: Server error water.exceptions.H2OIllegalArgumentException:\n  Error: Illegal argument: dir of function: importModel: water.api.FSIOException: FS IO Failure: \n accessed path : file:/tmp/downloaded_model/model.h2o/KMeans_model_python_1606338895375_628 msg: File not found\n  Request: POST /99/Models.bin/\n    data: {'dir': '/tmp/downloaded_model/model.h2o/KMeans_model_python_1606338895375_628'}\n"
     ]
    }
   ],
   "source": [
    "mlflow.h2o.load_model('file:///tmp/downloaded_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f62b76-3bc0-436a-97ae-ef1dcc250eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbb859f-7a93-48a9-9094-a33b14b41c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a453c9e3-81ff-4750-9668-8cddd5d249a3",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f274f17-5e93-426d-b5bc-19c5dd3cfd92",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_cluster (moment_key,c1,c2,c3,c4,c5,c6) values(1,0, 0, 0, 0, 0, 0);\n",
    "insert into h2o_cluster (moment_key,c1,c2,c3,c4,c5,c6) values(2,0.258682,2.03961,3.13087,2.71747,2.46077,0.24339);\n",
    "insert into h2o_cluster (moment_key,c1,c2,c3,c4,c5,c6) values(3,0.25, 0.99, 0.623, 0.21, 0.52, 0.66);\n",
    "\n",
    "select * from h2o_cluster;\n",
    "select * into ${data_and_preds} from h2o_cluster;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['C1','C2','C3','C4','C5','C6']])\n",
    "db_preds = data[['PREDICTION']]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "    \n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_train: PCA Power method failed to converge within TOLERANCE.  Increase max_iterations or reduce TOLERANCE to mitigate this problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploying pca\n",
      "Saving artifact of size: 52.228 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 21:55:35.328 - A service worker has found your request\n",
      "INFO     2020-11-25 21:55:35.370 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 21:55:35.404 - Handler is available\n",
      "INFO     2020-11-25 21:55:35.426 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 21:55:35.494 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 21:55:35.513 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 21:55:35.561 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 21:55:35.580 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 21:55:35.610 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 21:55:35.636 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 21:55:35.658 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 21:55:35.678 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 21:55:35.864 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 21:55:35.888 - Done.\n",
      "INFO     2020-11-25 21:55:35.911 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 21:55:36.049 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 21:55:36.074 - Adding Serialized Representation\n",
      "INFO     2020-11-25 21:55:36.141 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 21:55:36.163 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 21:55:36.185 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 21:55:36.204 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 21:55:36.229 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 21:55:36.271 - Executing\n",
      "CREATE TABLE splice.h2o_pca (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '335d51e2a6e4',\n",
      "                C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT,MOMENT_KEY INTEGER,\"PC0\" DOUBLE,\"PC1\" DOUBLE,\"PC2\" DOUBLE,\"PC3\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 21:55:37.112 - Done with 'creating model deployment table' [in 883.2697868347168 ms]\n",
      "INFO     2020-11-25 21:55:37.133 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 21:55:37.152 - Creating VTI Prediction Trigger...\n",
      "INFO     2020-11-25 21:55:37.173 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_pca_335d51e2a6e4 \n",
      "                        AFTER INSERT ON splice.h2o_pca REFERENCING NEW AS NEWROW FOR EACH ROW\n",
      "                        UPDATE splice.h2o_pca SET (\"PC0\",\"PC1\",\"PC2\",\"PC3\") = (SELECT b.\"PC0\",b.\"PC1\",b.\"PC2\",b.\"PC3\" FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', '335d51e2a6e4', TRIM(CAST(CAST(NEWROW.C1 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C2 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C3 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C4 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C5 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C6 as DECIMAL(38,10)) as CHAR(41))), \n",
      "        'C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT') as b (\"PC0\" DOUBLE,\"PC1\" DOUBLE,\"PC2\" DOUBLE,\"PC3\" DOUBLE) WHERE 1=1) WHERE MOMENT_KEY = NEWROW.MOMENT_KEY\n",
      "INFO     2020-11-25 21:55:37.489 - Done with 'creating trigger' [in 356.123685836792 ms]\n",
      "INFO     2020-11-25 21:55:37.511 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 21:55:37.531 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 21:55:37.619 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 21:55:37.676 - Done executing.\n",
      "INFO     2020-11-25 21:55:37.696 - Done with 'add model to metadata table' [in 184.69953536987305 ms]\n",
      "INFO     2020-11-25 21:55:37.716 - Flushing\n",
      "WARNING  2020-11-25 21:55:37.735 - Committing Transaction to Database\n",
      "INFO     2020-11-25 21:55:37.774 - Committed.\n",
      "INFO     2020-11-25 21:55:37.795 - Cleaning up deployment\n",
      "INFO     2020-11-25 21:55:37.839 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 21:55:37.878 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "from h2o.estimators import H2OPrincipalComponentAnalysisEstimator\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "for i in range(60000):\n",
    "    train.append([random.random()*4 for i in range(6)])\n",
    "    test.append([random.random()*4 for i in range(6)])\n",
    "\n",
    "train = h2o.H2OFrame(train)\n",
    "test = h2o.H2OFrame(test)\n",
    "predictors = [f'C{i}' for i in range(1,7)]\n",
    "\n",
    "model = H2OPrincipalComponentAnalysisEstimator(k = 4, transform = \"STANDARDIZE\", pca_method=\"Power\",\n",
    "                   use_all_factor_levels=True, impute_missing=True)\n",
    "model.train(x=train.names, training_frame=train)\n",
    "\n",
    "\n",
    "print('deploying pca')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_pca')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_pca',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b81b008-6992-4af2-a05d-57d854bd60e3",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca65650-0250-40f9-98c5-8647ebb002dc",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16dc2b8c-764b-491b-81da-78d701abc117",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1a5f08-434c-4c79-987f-f147bb92153b",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_pca (moment_key,c1,c2,c3,c4,c5,c6) values(1,0, 0, 0, 0, 0, 0);\n",
    "insert into h2o_pca (moment_key,c1,c2,c3,c4,c5,c6) values(2,0.258682,2.03961,3.13087,2.71747,2.46077,0.24339);\n",
    "insert into h2o_pca (moment_key,c1,c2,c3,c4,c5,c6) values(3,0.25, 0.99, 0.623, 0.21, 0.52, 0.66);\n",
    "\n",
    "select * from h2o_pca;\n",
    "select * into ${data_and_preds} from h2o_pca;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['C1','C2','C3','C4','C5','C6']])\n",
    "db_preds = data[['PC0','PC1','PC2','PC3']]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "    \n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping tolerance is ignored for _stopping_rounds=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploying isoforect\n",
      "Saving artifact of size: 89.908 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 21:55:44.972 - A service worker has found your request\n",
      "INFO     2020-11-25 21:55:45.004 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 21:55:45.034 - Handler is available\n",
      "INFO     2020-11-25 21:55:45.052 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 21:55:45.110 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 21:55:45.127 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 21:55:45.168 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 21:55:45.185 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 21:55:45.212 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 21:55:45.237 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 21:55:45.260 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 21:55:45.278 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 21:55:45.352 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 21:55:45.372 - Done.\n",
      "INFO     2020-11-25 21:55:45.393 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 21:55:45.484 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 21:55:45.504 - Adding Serialized Representation\n",
      "INFO     2020-11-25 21:55:45.632 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 21:55:45.652 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 21:55:45.670 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 21:55:45.690 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 21:55:45.713 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 21:55:45.754 - Executing\n",
      "CREATE TABLE splice.h2o_iso (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '1fd617461caa',\n",
      "                DISPLACEMENT FLOAT, POWER SMALLINT, WEIGHT SMALLINT, ACCELERATION FLOAT, YEAR_MAKE TINYINT,MOMENT_KEY INTEGER,\"score\" DOUBLE,\"normalizedScore\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 21:55:46.559 - Done with 'creating model deployment table' [in 846.0068702697754 ms]\n",
      "INFO     2020-11-25 21:55:46.578 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 21:55:46.598 - Creating VTI Prediction Trigger...\n",
      "INFO     2020-11-25 21:55:46.617 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_iso_1fd617461caa \n",
      "                        AFTER INSERT ON splice.h2o_iso REFERENCING NEW AS NEWROW FOR EACH ROW\n",
      "                        UPDATE splice.h2o_iso SET (\"score\",\"normalizedScore\") = (SELECT b.\"score\",b.\"normalizedScore\" FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', '1fd617461caa', TRIM(CAST(CAST(NEWROW.DISPLACEMENT as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(NEWROW.POWER as CHAR(41)))||','||TRIM(CAST(NEWROW.WEIGHT as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.ACCELERATION as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(NEWROW.YEAR_MAKE as CHAR(41))), \n",
      "        'displacement FLOAT, power SMALLINT, weight SMALLINT, acceleration FLOAT, year_make TINYINT') as b (\"score\" DOUBLE,\"normalizedScore\" DOUBLE) WHERE 1=1) WHERE MOMENT_KEY = NEWROW.MOMENT_KEY\n",
      "INFO     2020-11-25 21:55:46.862 - Done with 'creating trigger' [in 283.50090980529785 ms]\n",
      "INFO     2020-11-25 21:55:46.881 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 21:55:46.899 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 21:55:46.975 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 21:55:47.025 - Done executing.\n",
      "INFO     2020-11-25 21:55:47.044 - Done with 'add model to metadata table' [in 162.93001174926758 ms]\n",
      "INFO     2020-11-25 21:55:47.062 - Flushing\n",
      "WARNING  2020-11-25 21:55:47.079 - Committing Transaction to Database\n",
      "INFO     2020-11-25 21:55:47.117 - Committed.\n",
      "INFO     2020-11-25 21:55:47.136 - Cleaning up deployment\n",
      "INFO     2020-11-25 21:55:47.174 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 21:55:47.207 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "model = H2OIsolationForestEstimator(seed=1234,score_each_iteration=True,score_tree_interval=5)\n",
    "model.train(x=predictors,\n",
    "              training_frame=cars)\n",
    "model.model_performance()\n",
    "\n",
    "\n",
    "print('deploying isoforect')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_iso')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_iso',mlflow.current_run_id(), df=hc.asSparkFrame(cars).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c11278d-2ded-409a-9251-44f156ab3ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3a2da7-ed9e-4c8b-9db7-5d6a905e7e70",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1333ca9e-431a-43e2-92a7-3f39c1d05257",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_iso (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_iso (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_iso;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make, \"normalizedScore\",\"score\" into ${data_and_preds} from h2o_iso;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['normalizedScore','score']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploying neural network\n",
      "Saving artifact of size: 483.271 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 21:55:57.366 - A service worker has found your request\n",
      "INFO     2020-11-25 21:55:57.402 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 21:55:57.431 - Handler is available\n",
      "INFO     2020-11-25 21:55:57.448 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 21:55:57.510 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 21:55:57.527 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 21:55:57.565 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 21:55:57.583 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 21:55:57.609 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 21:55:57.640 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 21:55:57.665 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 21:55:57.684 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 21:55:57.756 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 21:55:57.777 - Done.\n",
      "INFO     2020-11-25 21:55:57.795 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 21:55:57.987 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 21:55:58.008 - Adding Serialized Representation\n",
      "INFO     2020-11-25 21:55:58.138 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 21:55:58.157 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 21:55:58.174 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 21:55:58.196 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 21:55:58.219 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 21:55:58.258 - Executing\n",
      "CREATE TABLE splice.h2o_nn (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '26f113df4988',\n",
      "                DISPLACEMENT FLOAT, POWER SMALLINT, WEIGHT SMALLINT, ACCELERATION FLOAT, YEAR_MAKE TINYINT,MOMENT_KEY INTEGER,PREDICTION VARCHAR(5000),\"C3\" DOUBLE,\"C4\" DOUBLE,\"C5\" DOUBLE,\"C6\" DOUBLE,\"C8\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 21:55:59.065 - Done with 'creating model deployment table' [in 846.107006072998 ms]\n",
      "INFO     2020-11-25 21:55:59.085 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 21:55:59.103 - Creating Prediction Trigger...\n",
      "INFO     2020-11-25 21:55:59.121 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_nn_26f113df4988\n",
      "                           BEFORE INSERT ON splice.h2o_nn REFERENCING NEW AS NEWROW \n",
      "                           FOR EACH ROW SET NEWROW.PREDICTION=MLMANAGER.PREDICT_CLASSIFICATION('26f113df4988',TRIM(CAST(CAST(NEWROW.DISPLACEMENT as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(NEWROW.POWER as CHAR(41)))||','||TRIM(CAST(NEWROW.WEIGHT as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.ACCELERATION as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(NEWROW.YEAR_MAKE as CHAR(41))),\n",
      "'displacement FLOAT, power SMALLINT, weight SMALLINT, acceleration FLOAT, year_make TINYINT')\n",
      "INFO     2020-11-25 21:55:59.257 - Done with 'creating trigger' [in 172.5597381591797 ms]\n",
      "INFO     2020-11-25 21:55:59.276 - Starting 'create parsing trigger'...\n",
      "INFO     2020-11-25 21:55:59.295 - Creating parsing trigger...\n",
      "INFO     2020-11-25 21:55:59.318 - Executing\n",
      "CREATE TRIGGER splice.PARSERESULT_h2o_nn_26f113df4988                                 BEFORE INSERT ON splice.h2o_nn REFERENCING NEW AS NEWROW                                 FOR EACH ROW set NEWROW.\"C3\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,0),NEWROW.\"C4\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,1),NEWROW.\"C5\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,2),NEWROW.\"C6\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,3),NEWROW.\"C8\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,4),NEWROW.PREDICTION=   CASE   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=0 then 'C3'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=1 then 'C4'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=2 then 'C5'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=3 then 'C6'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=4 then 'C8'   END;\n",
      "INFO     2020-11-25 21:55:59.590 - Done with 'create parsing trigger' [in 313.43889236450195 ms]\n",
      "INFO     2020-11-25 21:55:59.610 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 21:55:59.628 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 21:55:59.711 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 21:55:59.761 - Done executing.\n",
      "INFO     2020-11-25 21:55:59.780 - Done with 'add model to metadata table' [in 170.11594772338867 ms]\n",
      "INFO     2020-11-25 21:55:59.798 - Flushing\n",
      "WARNING  2020-11-25 21:55:59.816 - Committing Transaction to Database\n",
      "INFO     2020-11-25 21:55:59.863 - Committed.\n",
      "INFO     2020-11-25 21:55:59.880 - Cleaning up deployment\n",
      "INFO     2020-11-25 21:55:59.920 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 21:55:59.956 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "cars[\"cylinders\"] = cars[\"cylinders\"].asfactor()\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response_col = \"cylinders\"\n",
    "\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "\n",
    "\n",
    "\n",
    "model = H2ODeepLearningEstimator(variable_importances=True,loss =\"Automatic\")\n",
    "\n",
    "model.train(x                =predictors,\n",
    "              y                =response_col,\n",
    "               training_frame  =train,\n",
    "              validation_frame=valid)\n",
    "\n",
    "\n",
    "\n",
    "print('deploying neural network')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_nn')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_nn',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae50cd0-8d16-4097-af9c-de71a4501794",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cee036-1f3f-4549-a01b-042d1afdaf99",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64f31b8-3602-4d67-918d-17db1e516a23",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_nn (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_nn (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_nn;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make,prediction, c3,c4,c5,c6,c8 into ${data_and_preds} from h2o_nn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION','C3','C4','C5','C6','C8']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        if isinstance(db,str):\n",
    "            raw = f'C{int(raw)}'\n",
    "            assert db==raw, f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "        else:\n",
    "            assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "    \n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "xgboost Model Build progress: |███████████████████████████████████████████| 100%\n",
      "xgboost prediction progress: |████████████████████████████████████████████| 100%\n",
      "deploying xgb\n",
      "Table exists. Dropping table\n",
      "Saving artifact of size: 55.564 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 22:03:32.544 - A service worker has found your request\n",
      "INFO     2020-11-25 22:03:32.578 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 22:03:32.608 - Handler is available\n",
      "INFO     2020-11-25 22:03:32.631 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 22:03:32.694 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 22:03:32.712 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 22:03:32.753 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 22:03:32.772 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 22:03:32.798 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 22:03:32.823 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 22:03:32.843 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 22:03:32.863 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 22:03:32.950 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 22:03:32.971 - Done.\n",
      "INFO     2020-11-25 22:03:32.990 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 22:03:33.081 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 22:03:33.103 - Adding Serialized Representation\n",
      "INFO     2020-11-25 22:03:33.227 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 22:03:33.247 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 22:03:33.267 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 22:03:33.291 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 22:03:33.315 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 22:03:33.360 - Executing\n",
      "CREATE TABLE splice.h2o_xgb (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '3b8a8c8b113a',\n",
      "                SIBSP TINYINT, SEX VARCHAR(5000), AGE FLOAT,MOMENT_KEY INTEGER,PREDICTION VARCHAR(5000),\"C0\" DOUBLE,\"C1\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 22:03:34.175 - Done with 'creating model deployment table' [in 859.2014312744141 ms]\n",
      "INFO     2020-11-25 22:03:34.196 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 22:03:34.215 - Creating Prediction Trigger...\n",
      "INFO     2020-11-25 22:03:34.233 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_xgb_3b8a8c8b113a\n",
      "                           BEFORE INSERT ON splice.h2o_xgb REFERENCING NEW AS NEWROW \n",
      "                           FOR EACH ROW SET NEWROW.PREDICTION=MLMANAGER.PREDICT_CLASSIFICATION('3b8a8c8b113a',TRIM(CAST(NEWROW.SIBSP as CHAR(41)))||','||NEWROW.SEX||','||TRIM(CAST(CAST(NEWROW.AGE as DECIMAL(38,10)) as CHAR(41))),\n",
      "'sibsp TINYINT, sex VARCHAR(5000), age FLOAT')\n",
      "INFO     2020-11-25 22:03:34.361 - Done with 'creating trigger' [in 165.3614044189453 ms]\n",
      "INFO     2020-11-25 22:03:34.381 - Starting 'create parsing trigger'...\n",
      "INFO     2020-11-25 22:03:34.400 - Creating parsing trigger...\n",
      "INFO     2020-11-25 22:03:34.419 - Executing\n",
      "CREATE TRIGGER splice.PARSERESULT_h2o_xgb_3b8a8c8b113a                                 BEFORE INSERT ON splice.h2o_xgb REFERENCING NEW AS NEWROW                                 FOR EACH ROW set NEWROW.\"C0\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,0),NEWROW.\"C1\"=MLMANAGER.PARSEPROBS(NEWROW.prediction,1),NEWROW.PREDICTION=   CASE   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=0 then 'C0'   WHEN MLMANAGER.GETPREDICTION(NEWROW.prediction)=1 then 'C1'   END;\n",
      "INFO     2020-11-25 22:03:34.652 - Done with 'create parsing trigger' [in 270.95842361450195 ms]\n",
      "INFO     2020-11-25 22:03:34.671 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 22:03:34.690 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 22:03:34.771 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 22:03:34.821 - Done executing.\n",
      "INFO     2020-11-25 22:03:34.842 - Done with 'add model to metadata table' [in 170.6845760345459 ms]\n",
      "INFO     2020-11-25 22:03:34.861 - Flushing\n",
      "WARNING  2020-11-25 22:03:34.879 - Committing Transaction to Database\n",
      "INFO     2020-11-25 22:03:34.925 - Committed.\n",
      "INFO     2020-11-25 22:03:34.944 - Cleaning up deployment\n",
      "INFO     2020-11-25 22:03:34.983 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 22:03:35.020 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.estimators import H2OXGBoostEstimator\n",
    "\n",
    "# Import the titanic dataset into H2O:\n",
    "titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "\n",
    "# Set the predictors and response; set the response as a factor:\n",
    "titanic[\"survived\"] = titanic[\"survived\"].asfactor()\n",
    "predictors = ['sibsp', 'sex', 'age']\n",
    "response = \"survived\"\n",
    "\n",
    "# Split the dataset into a train and valid set:\n",
    "train, valid = titanic.split_frame(ratios=[.8], seed=1234)\n",
    "\n",
    "# Build and train the model:\n",
    "model = H2OXGBoostEstimator(booster='dart',\n",
    "                                  normalize_type=\"tree\",\n",
    "                                  seed=1234)\n",
    "model.train(x=predictors,\n",
    "                  y=response,\n",
    "                  training_frame=train,\n",
    "                  validation_frame=valid)\n",
    "\n",
    "# Eval performance:\n",
    "perf = model.model_performance()\n",
    "\n",
    "# Generate predictions on a test set (if necessary):\n",
    "pred = model.predict(valid)\n",
    "\n",
    "print('deploying xgb')\n",
    "splice.dropTableIfExists('splice.h2o_xgb')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db('splice','h2o_xgb',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sql started successfully\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ed0911-8534-4f71-88f0-8e8499356594",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94a2b6e-9187-4f54-84be-a0df9a7973da",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9ed0bf-90ef-450f-8f36-79e8e47f5b77",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "insert into splice.h2o_xgb (moment_key,sibsp,sex,age) values(0, 5,'female',2.496);\n",
    "insert into splice.h2o_xgb (moment_key,sibsp,sex,age) values(1, 1,'male',-7.048);\n",
    "select * from h2o_xgb;\n",
    "select sibsp, sex, age, prediction, c0, c1 into ${data_and_preds} from splice.h2o_xgb;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "xgboost prediction progress: |████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['SIBSP','SEX','AGE']])\n",
    "db_preds = data[['PREDICTION','C0','C1']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p, db_c0, db_c1 = db_pred[1]\n",
    "    raw_p, raw_c0, raw_c1 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    raw_p = f'C{int(raw_p)}'\n",
    "    \n",
    "    assert db_p == raw_p, f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    assert round(db_c0,14) == round(raw_c0,14), f'Something is wrong. Model Table gives {db_c0} but raw model gives {raw_c0}'\n",
    "    assert round(db_c1,14) == round(raw_c1,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================================== Below is Broken =====================================\n",
    "\n",
    "## GLRM (not broken but can't test), TargetEncoder (broken on deploy)\n",
    "\n",
    "### GLRM explanation https://0xdata.atlassian.net/browse/PUBDEV-7761"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploying glrm\n",
      "Saving artifact of size: 2790.735 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 21:56:21.612 - A service worker has found your request\n",
      "INFO     2020-11-25 21:56:21.643 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 21:56:21.671 - Handler is available\n",
      "INFO     2020-11-25 21:56:21.689 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 21:56:21.752 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 21:56:21.769 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 21:56:21.812 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 21:56:21.833 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 21:56:21.870 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 21:56:21.968 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 21:56:22.009 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 21:56:22.030 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 21:56:22.139 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 21:56:22.160 - Done.\n",
      "INFO     2020-11-25 21:56:22.178 - Adding Model Schema and DF...\n",
      "INFO     2020-11-25 21:56:22.256 - Adding Library Specific Representations...\n",
      "INFO     2020-11-25 21:56:22.275 - Adding Serialized Representation\n",
      "INFO     2020-11-25 21:56:22.373 - Updating Artifact with serialized representation\n",
      "INFO     2020-11-25 21:56:22.394 - Preparing Model Metadata for Deployment...\n",
      "INFO     2020-11-25 21:56:22.412 - Preparing H2O Model metadata for deployment\n",
      "INFO     2020-11-25 21:56:22.431 - Adding Schema String to model metadata...\n",
      "INFO     2020-11-25 21:56:22.455 - Starting 'creating model deployment table'...\n",
      "INFO     2020-11-25 21:56:22.496 - Executing\n",
      "CREATE TABLE splice.h2o_glrm (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '7ad85978c270',\n",
      "                C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT,MOMENT_KEY INTEGER,\"PC0\" DOUBLE,\"PC1\" DOUBLE,\"PC2\" DOUBLE,\"PC3\" DOUBLE,\"PC4\" DOUBLE,\"PC5\" DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2020-11-25 21:56:23.302 - Done with 'creating model deployment table' [in 847.5520610809326 ms]\n",
      "INFO     2020-11-25 21:56:23.321 - Starting 'creating trigger'...\n",
      "INFO     2020-11-25 21:56:23.340 - Creating VTI Prediction Trigger...\n",
      "INFO     2020-11-25 21:56:23.358 - Executing\n",
      "CREATE TRIGGER splice.runModel_h2o_glrm_7ad85978c270 \n",
      "                        AFTER INSERT ON splice.h2o_glrm REFERENCING NEW AS NEWROW FOR EACH ROW\n",
      "                        UPDATE splice.h2o_glrm SET (\"PC0\",\"PC1\",\"PC2\",\"PC3\",\"PC4\",\"PC5\") = (SELECT b.\"PC0\",b.\"PC1\",b.\"PC2\",b.\"PC3\",b.\"PC4\",b.\"PC5\" FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', '7ad85978c270', TRIM(CAST(CAST(NEWROW.C1 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C2 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C3 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C4 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C5 as DECIMAL(38,10)) as CHAR(41)))||','||TRIM(CAST(CAST(NEWROW.C6 as DECIMAL(38,10)) as CHAR(41))), \n",
      "        'C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT') as b (\"PC0\" DOUBLE,\"PC1\" DOUBLE,\"PC2\" DOUBLE,\"PC3\" DOUBLE,\"PC4\" DOUBLE,\"PC5\" DOUBLE) WHERE 1=1) WHERE MOMENT_KEY = NEWROW.MOMENT_KEY\n",
      "INFO     2020-11-25 21:56:23.639 - Done with 'creating trigger' [in 317.94238090515137 ms]\n",
      "INFO     2020-11-25 21:56:23.660 - Starting 'add model to metadata table'...\n",
      "INFO     2020-11-25 21:56:23.678 - Adding Model to Metadata table\n",
      "INFO     2020-11-25 21:56:23.761 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2020-11-25 21:56:23.809 - Done executing.\n",
      "INFO     2020-11-25 21:56:23.829 - Done with 'add model to metadata table' [in 169.70252990722656 ms]\n",
      "INFO     2020-11-25 21:56:23.849 - Flushing\n",
      "WARNING  2020-11-25 21:56:23.866 - Committing Transaction to Database\n",
      "INFO     2020-11-25 21:56:23.903 - Committed.\n",
      "INFO     2020-11-25 21:56:23.922 - Cleaning up deployment\n",
      "INFO     2020-11-25 21:56:23.961 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2020-11-25 21:56:23.998 - TASK_COMPLETED"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "test = []\n",
    "for i in range(60000):\n",
    "    train.append([random.random()*4 for i in range(6)])\n",
    "\n",
    "train = h2o.H2OFrame(train)\n",
    "predictors = [f'C{i}' for i in range(1,7)]\n",
    "\n",
    "model = H2OGeneralizedLowRankEstimator(k=6,seed=1234, impute_original=True,transform='Normalize')\n",
    "model.train(x=predictors, training_frame=train)\n",
    "\n",
    "print('deploying glrm')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_glrm')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_glrm',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  reconstr_C1</th><th style=\"text-align: right;\">  reconstr_C2</th><th style=\"text-align: right;\">  reconstr_C3</th><th style=\"text-align: right;\">  reconstr_C4</th><th style=\"text-align: right;\">  reconstr_C5</th><th style=\"text-align: right;\">  reconstr_C6</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">    -0.499772</td><td style=\"text-align: right;\">    -0.501924</td><td style=\"text-align: right;\">    -0.500133</td><td style=\"text-align: right;\">     -0.49943</td><td style=\"text-align: right;\">    -0.499896</td><td style=\"text-align: right;\">    -0.499611</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.reconstruct(h2o.H2OFrame([[0,0,0,0,0,0]]))\n",
    "# dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d023d705-4b29-4252-b027-19b5fa4ac651",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0bfc45-0727-4933-b08b-90aaf37706ad",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eb56ae-2ed4-4eda-85a9-99af0c0b9df5",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb5c9de-24ec-4b05-9f01-1dca5af326df",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602992b1-21b5-423f-846e-a1d6a969b2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "truncate table h2o_glrm;\n",
    "insert into h2o_glrm (moment_key,c1,c2,c3,c4,c5,c6) values(1,0, 0, 0, 0, 0, 0);\n",
    "insert into h2o_glrm (moment_key,c1,c2,c3,c4,c5,c6) values(2,0.258682,2.03961,3.13087,2.71747,2.46077,0.24339);\n",
    "insert into h2o_glrm (moment_key,c1,c2,c3,c4,c5,c6) values(3,0.25, 0.99, 0.623, 0.21, 0.52, 0.66);\n",
    "\n",
    "select * from h2o_glrm;\n",
    "select * into ${data_and_preds} from h2o_glrm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "## GLRM Can act as both autoencoders in that they reconstruct data, and also perform PCA. In the database, we always do PCA (maybe something to change later)\n",
    "## For reconstruction, you call predict. I don't know how to get components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Something is wrong. Model Table gives 0.001523829447429341 but raw model gives -3.414778858782197",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-053221790888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Check reconstruction values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Something is wrong. Model Table gives {db} but raw model gives {raw}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test passed!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Something is wrong. Model Table gives 0.001523829447429341 but raw model gives -3.414778858782197"
     ]
    }
   ],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['C1','C2','C3','C4','C5','C6']])\n",
    "db_preds = data[['PC0','PC1','PC2','PC3','PC4','PC5']]\n",
    "\n",
    "# GLRM Can act as both autoencoders in that they reconstruct data, and also perform PCA. In the database, we always do PCA (maybe something to change later)\n",
    "# To get the PCA, you call proj_archetypes, for reconstruction, you call predict\n",
    "raw_preds = model.proj_archetypes(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLRM is weird because it can act as either Dim Reduction or an Autoencoder... Which should we pick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DimReduction\n"
     ]
    }
   ],
   "source": [
    "pca_path = model.download_mojo('/tmp/gbm.zip')\n",
    "\n",
    "\n",
    "from py4j.java_gateway import java_import\n",
    "java_import(splice.jvm, 'hex.genmodel.easy.EasyPredictModelWrapper')\n",
    "java_import(splice.jvm, 'hex.genmodel.MojoModel')\n",
    "java_import(splice.jvm, 'java.io.ByteArrayOutputStream')\n",
    "java_import(splice.jvm, 'java.io.ObjectOutputStream') \n",
    "java_import(splice.jvm, 'hex.genmodel.easy.RowData')\n",
    "java_import(splice.jvm, 'hex.genmodel.easy.prediction.DimReductionModelPrediction')\n",
    "\n",
    "\n",
    "java_mojo_c = splice.jvm.EasyPredictModelWrapper.Config().setModel(splice.jvm.MojoModel.load(pca_path))\n",
    "java_mojo = splice.jvm.EasyPredictModelWrapper(java_mojo_c)\n",
    "\n",
    "\n",
    "\n",
    "m = splice.jvm.MojoModel.load(pca_path)\n",
    "\n",
    "# java_mojo.predictDimReduction(train)\n",
    "\n",
    "\n",
    "print(java_mojo.getModelCategory().toString())\n",
    "\n",
    "\n",
    "row = splice.jvm.RowData()\n",
    "row.put(\"C1\", \"0\")\n",
    "row.put(\"C2\", \"0\")\n",
    "row.put(\"C3\", \"0\")\n",
    "row.put(\"C4\", \"0\")\n",
    "row.put(\"C5\", \"0\")\n",
    "row.put(\"C6\", \"0\")\n",
    "\n",
    "d = splice.jvm.DimReductionModelPrediction\n",
    "\n",
    "# pred = m.predictDimReduction(row)\n",
    "\n",
    "# list(java_mojo.predictDimReduction(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_8084357634934378958() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "        <a href=\"javascript:code_toggle_8084357634934378958()\"><button style='color:black'>Toggle show/hide next cell</button></a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splicemachine.notebook import hide_toggle\n",
    "hide_toggle(toggle_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java started successfully\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad classpath, file not found\n",
      "Bad classpath, file not found\n"
     ]
    },
    {
     "ename": "package hex.genmodel.easy does not exist",
     "evalue": "package hex.genmodel.easy does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mpackage hex.genmodel.easy does not exist\u001b[0;0m",
      "\u001b[1;31m import hex.genmodel.easy.RowData\u001b[0;0m",
      "\u001b[1;31m        ^                        ^ \u001b[0;0m",
      "\u001b[1;31m\u001b[0;0m",
      "\u001b[1;31mpackage hex.genmodel.easy does not exist\u001b[0;0m",
      "\u001b[1;31m import hex.genmodel.easy.EasyPredictModelWrapper\u001b[0;0m",
      "\u001b[1;31m        ^                                        ^ \u001b[0;0m",
      "\u001b[1;31m\u001b[0;0m",
      "\u001b[1;31mpackage hex.genmodel.easy.prediction does not exist\u001b[0;0m",
      "\u001b[1;31m import hex.genmodel.easy.predi\u001b[0;0m",
      "\u001b[1;31m ^                              \u001b[0;0m",
      "\u001b[1;31m\u001b[0;0m",
      "\u001b[1;31mpackage hex.genmodel does not exist\u001b[0;0m",
      "\u001b[1;31m import hex.genmodel.MojoModel\u001b[0;0m",
      "\u001b[1;31m        ^                     ^ \u001b[0;0m",
      "\u001b[1;31m\u001b[0;0m",
      "\u001b[1;31mpackage hex.genmodel does not exist\u001b[0;0m",
      "\u001b[1;31m import hex.genmodel.InMemoryMojoReaderBackend\u001b[0;0m",
      "\u001b[1;31m        ^                                     ^ \u001b[0;0m",
      "\u001b[1;31m\u001b[0;0m",
      "\u001b[1;31mpackage com.splicemachine.db.jdbc does not exist\u001b[0;0m",
      "\u001b[1;31m import com.splicemachine.db.jd\u001b[0;0m",
      "\u001b[1;31m ^                              \u001b[0;0m",
      "\u001b[1;31m\u001b[0;0m",
      "\u001b[1;31mpackage com.splicemachine.db.jdbc does not exist\u001b[0;0m",
      "\u001b[1;31m Driver d = new com.splicemachine.db.jdbc.ClientDriver()\u001b[0;0m",
      "\u001b[1;31m                ^                                     ^   \u001b[0;0m",
      "\u001b[1;31m\u001b[0;0m",
      "\u001b[1;31mcannot find symbol\u001b[0;0m",
      "\u001b[1;31m  symbol:   class EasyPredictModelWrapper\u001b[0;0m",
      "\u001b[0;31m  location: class com.twosigma.beaker.javash.bkr5029108f.BeakerWrapperClass1261714175Id7bd47d7494884501a9574af2ce4917ec\u001b[0;0m",
      "\u001b[0;31m EasyPredictModelWrapper model = null\u001b[0;0m",
      "\u001b[0;31m ^                      ^              \u001b[0;0m",
      "\u001b[0;31m\u001b[0;0m",
      "\u001b[0;31mcannot find symbol\u001b[0;0m",
      "\u001b[0;31m  symbol:   class EasyPredictModelWrapper\u001b[0;0m",
      "\u001b[0;31m  location: class com.twosigma.beaker.javash.bkr5029108f.BeakerWrapperClass1261714175Id7bd47d7494884501a9574af2ce4917ec\u001b[0;0m",
      "\u001b[0;31m model = (EasyPredictModelWrapper) (ois.readObject())\u001b[0;0m",
      "\u001b[0;31m          ^                      ^                     \u001b[0;0m",
      "\u001b[0;31m\u001b[0;0m",
      "\u001b[0;31mcannot find symbol\u001b[0;0m",
      "\u001b[0;31m  symbol:   class RowData\u001b[0;0m",
      "\u001b[0;31m  location: class com.twosigma.beaker.javash.bkr5029108f.BeakerWrapperClass1261714175Id7bd47d7494884501a9574af2ce4917ec\u001b[0;0m",
      "\u001b[0;31m RowData row = new RowData()\u001b[0;0m",
      "\u001b[0;31m ^      ^                     \u001b[0;0m",
      "\u001b[0;31m\u001b[0;0m",
      "\u001b[0;31mcannot find symbol\u001b[0;0m",
      "\u001b[0;31m  symbol:   class RowData\u001b[0;0m",
      "\u001b[0;31m  location: class com.twosigma.beaker.javash.bkr5029108f.BeakerWrapperClass1261714175Id7bd47d7494884501a9574af2ce4917ec\u001b[0;0m",
      "\u001b[0;31m RowData row = new RowData()\u001b[0;0m",
      "\u001b[0;31m                   ^      ^   \u001b[0;0m",
      "\u001b[0;31m\u001b[0;0m",
      "\u001b[0;31mcannot find symbol\u001b[0;0m",
      "\u001b[0;31m  symbol:   class AbstractPrediction\u001b[0;0m",
      "\u001b[0;31m  location: class com.twosigma.beaker.javash.bkr5029108f.BeakerWrapperClass1261714175Id7bd47d7494884501a9574af2ce4917ec\u001b[0;0m",
      "\u001b[0;31m AbstractPrediction p\u001b[0;0m",
      "\u001b[0;31m ^                 ^   \u001b[0;0m",
      "\u001b[0;31m\u001b[0;0m",
      "\u001b[0;31mcannot find symbol\u001b[0;0m",
      "\u001b[0;31m  symbol:   class DimReductionModelPrediction\u001b[0;0m",
      "\u001b[0;31m  location: class com.twosigma.beaker.javash.bkr5029108f.BeakerWrapperClass1261714175Id7bd47d7494884501a9574af2ce4917ec\u001b[0;0m",
      "\u001b[0;31m final double[] dim = ((DimReductionModelPrediction) p).dimensions\u001b[0;0m",
      "\u001b[0;31m                        ^                          ^                \u001b[0;0m"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "%classpath add jar db-client-3.0.0.1950.jar\n",
    "%classpath add jar /home/jovyan/nn_model.jar\n",
    "import java.sql.*; \n",
    "import java.util.*; \n",
    "import hex.genmodel.easy.RowData;\n",
    "import hex.genmodel.easy.EasyPredictModelWrapper;\n",
    "import hex.genmodel.easy.prediction.*;\n",
    "import java.io.*;\n",
    "import hex.genmodel.MojoModel;\n",
    "import hex.genmodel.InMemoryMojoReaderBackend;\n",
    "import java.sql.Driver;  \n",
    "import com.splicemachine.db.jdbc.*;\n",
    "\n",
    "\n",
    "Driver d = new com.splicemachine.db.jdbc.ClientDriver();  \n",
    "DriverManager.registerDriver(d);\n",
    "Connection conn = DriverManager.getConnection(\"jdbc:splice://jdbc-test-aks-dev1.dev.splicemachine-dev.io:1527/splicedb;ssl=basic\",\"splice\",\"admin\");\n",
    "PreparedStatement pstmt = conn.prepareStatement(\"select \\\"binary\\\" from mlmanager.artifacts where RUN_UUID=? and NAME=?\");\n",
    "        pstmt.setString(1, \"6ba390856894\");\n",
    "        pstmt.setString(2,\"h2omojo\");\n",
    "        ResultSet rs = pstmt.executeQuery();\n",
    "        EasyPredictModelWrapper model = null;\n",
    "        if(rs.next()) {\n",
    "            Blob blobModel = rs.getBlob(1);\n",
    "            InputStream bis = blobModel.getBinaryStream();\n",
    "            ObjectInputStream ois = new ObjectInputStream(bis);\n",
    "            model = (EasyPredictModelWrapper) (ois.readObject());\n",
    "            ois.close();\n",
    "        }\n",
    "\n",
    "        \n",
    "\n",
    "RowData row = new RowData();\n",
    "\n",
    "row.put(\"SDSS_J\", \"000009.26+151754.5\");\n",
    "row.put(\"R.A.\", \"9.08519705868309\");\n",
    "row.put(\"Dec.\", \"4.932083187033184\");\n",
    "row.put(\"z\", \"7.139249327431729\");\n",
    "row.put(\"u_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_u\", \"7.139249327431729\");\n",
    "row.put(\"g_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_g\", \"7.139249327431729\");\n",
    "row.put(\"r_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_r\", \"7.139249327431729\");\n",
    "row.put(\"i_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_i\", \"7.139249327431729\");\n",
    "row.put(\"z_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_z\", \"7.139249327431729\");\n",
    "row.put(\"Radio\", \"7.139249327431729\");\n",
    "row.put(\"X-ray\", \"7.139249327431729\");\n",
    "row.put(\"J_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_J\", \"7.139249327431729\");\n",
    "row.put(\"H_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_H\", \"7.139249327431729\");\n",
    "row.put(\"K_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_K\", \"7.139249327431729\");\n",
    "row.put(\"M_i\", \"7.139249327431729\");\n",
    "\n",
    "\n",
    "AbstractPrediction p;\n",
    "p = model.predictDimReduction(row);\n",
    "\n",
    "final StringBuilder builder = new StringBuilder();\n",
    "//for(int i = 0; i < classProbs.length; i++){\n",
    "//    builder.append(i).append(\"=\").append(classProbs[i]).append(\";\");\n",
    "//}\n",
    "//return builder.substring(0, builder.length() - 1);\n",
    "//return c;\n",
    "\n",
    "final double[] dim = ((DimReductionModelPrediction) p).dimensions;\n",
    "//AutoEncoderModelPrediction\n",
    "\n",
    "\n",
    "//for(int i = 0; i < dim.length; i++){\n",
    "//    builder.append(\"PC\" + i).append(\"=\").append(Double.toString(dim[i])).append(\";\");\n",
    "//}\n",
    "\n",
    "return dim;\n",
    "//return builder.substring(0, builder.length() - 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TargetEncoder (BROKEN on Deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "``k`` is deprecated, please use ``inflection_point`` instead.\n",
      "``f`` is deprecated, please use ``smoothing`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targetencoder Model Build progress: |█████████████████████████████████████| 100%\n",
      "deploying target encoder\n",
      "Saving artifact of size: 8.535 KB to Splice Machine DB\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2020-11-25 22:05:42.296 - A service worker has found your request\n",
      "INFO     2020-11-25 22:05:42.334 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2020-11-25 22:05:42.369 - Handler is available\n",
      "INFO     2020-11-25 22:05:42.393 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2020-11-25 22:05:42.464 - Retrieved MLFlow Run\n",
      "INFO     2020-11-25 22:05:42.484 - Updating MLFlow Run for the UI\n",
      "INFO     2020-11-25 22:05:42.536 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2020-11-25 22:05:42.557 - Extracting Model from DB with Name: model\n",
      "INFO     2020-11-25 22:05:42.589 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2020-11-25 22:05:42.614 - Decompressing Model Artifact\n",
      "INFO     2020-11-25 22:05:42.636 - Creating raw model representation from MLModel\n",
      "INFO     2020-11-25 22:05:42.657 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2020-11-25 22:05:42.746 - Registering Raw Model Representation...\n",
      "INFO     2020-11-25 22:05:42.768 - Done.\n",
      "INFO     2020-11-25 22:05:42.786 - Adding Model Schema and DF...\n",
      "ERROR    2020-11-25 22:05:42.875 - Running Exception Callback because of encountered: 'HTTP 500 Server Error:\n",
      "'<html>\\n<head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\"/>\\n<title>Error 500 Server Error</title>\\n</head>\\n<body><h2>HTTP ERROR 500</h2>\\n<p>Problem accessing /3/Models/TargetEncoder_model_python_1606341758081_104/mojo. Reason:\\n<pre>    Server Error</pre></p><h3>Caused by:</h3><pre>java.lang.NullPointerException\\n\\tat ai.h2o.targetencoding.TargetEncoderMojoWriter.writeTargetEncodingMap(TargetEncoderMojoWriter.java:86)\\n\\tat ai.h2o.targetencoding.TargetEncoderMojoWriter.writeModelData(TargetEncoderMojoWriter.java:39)\\n\\tat hex.genmodel.AbstractMojoWriter.writeTo(AbstractMojoWriter.java:149)\\n\\tat hex.genmodel.AbstractMojoWriter.writeTo(AbstractMojoWriter.java:143)\\n\\tat hex.ModelMojoWriter.writeTo(ModelMojoWriter.java:78)\\n\\tat water.api.NanoStreamResponse.writeTo(NanoStreamResponse.java:17)\\n\\tat water.api.RequestServer.doGeneric(RequestServer.java:319)\\n\\tat water.api.RequestServer.doGet(RequestServer.java:225)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat ai.h2o.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat ai.h2o.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:535)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1317)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat ai.h2o.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1219)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat water.webserver.jetty9.Jetty9ServerAdapter$LoginHandler.handle(Jetty9ServerAdapter.java:130)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat ai.h2o.org.eclipse.jetty.server.Server.handle(Server.java:531)\\n\\tat ai.h2o.org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:352)\\n\\tat ai.h2o.org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat ai.h2o.org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:281)\\n\\tat ai.h2o.org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:102)\\n\\tat ai.h2o.org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:762)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:680)\\n\\tat java.lang.Thread.run(Thread.java:745)\\n</pre>\\n\\n</body>\\n</html>\\n''\n",
      "INFO     2020-11-25 22:05:42.896 - Cleaning up deployment\n",
      "ERROR    2020-11-25 22:05:42.941 - Task Failed\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/threading.py\", line 885, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "    │    └ <function Thread._bootstrap_inner at 0x7f52829766a8>\n",
      "    └ <Worker(Thread-16, started 139989640361728)>\n",
      "  File \"/usr/local/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "    │    └ <function Worker.run at 0x7f51e14bf488>\n",
      "    └ <Worker(Thread-16, started 139989640361728)>\n",
      "  File \"/usr/local/lib/python3.7/site-packages/workerpool/workers.py\", line 36, in run\n",
      "    job.run()\n",
      "    │   └ <function Runner.run at 0x7f51e14d1158>\n",
      "    └ <main.Runner object at 0x7f517c64b080>\n",
      "\n",
      "  File \"/opt/bobby/main.py\", line 124, in run\n",
      "    KnownHandlers.get_class(self.handler_name)(self.task_id).handle()\n",
      "    │             │         │    │             │    └ 31\n",
      "    │             │         │    │             └ <main.Runner object at 0x7f517c64b080>\n",
      "    │             │         │    └ 'DEPLOY_DATABASE'\n",
      "    │             │         └ <main.Runner object at 0x7f517c64b080>\n",
      "    │             └ <staticmethod object at 0x7f5252206438>\n",
      "    └ <class 'shared.services.handlers.KnownHandlers'>\n",
      "\n",
      "> File \"/opt/bobby/handlers/base_handler.py\", line 85, in handle\n",
      "    self._handle()\n",
      "    │    └ <function BaseDeploymentHandler._handle at 0x7f52521b9d90>\n",
      "    └ <handlers.run_handlers.database_deployment_handler.DatabaseDeploymentHandler object at 0x7f517c64b588>\n",
      "\n",
      "  File \"/opt/bobby/handlers/run_handlers/base_deployment_handler.py\", line 163, in _handle\n",
      "    raise e\n",
      "\n",
      "  File \"/opt/bobby/handlers/run_handlers/base_deployment_handler.py\", line 158, in _handle\n",
      "    self.execute()\n",
      "    │    └ <function DatabaseDeploymentHandler.execute at 0x7f51e180a158>\n",
      "    └ <handlers.run_handlers.database_deployment_handler.DatabaseDeploymentHandler object at 0x7f517c64b588>\n",
      "\n",
      "  File \"/opt/bobby/handlers/run_handlers/database_deployment_handler.py\", line 221, in execute\n",
      "    execute_step()\n",
      "    └ <bound method DatabaseDeploymentHandler._retrieve_alternate_model_representations of <handlers.run_handlers.database_deployme...\n",
      "\n",
      "  File \"/opt/bobby/handlers/run_handlers/database_deployment_handler.py\", line 159, in _retrieve_alternate_model_representations\n",
      "    self.creator.create_alternate_representations()\n",
      "    │    │       └ <function DatabaseRepresentationCreator.create_alternate_representations at 0x7f524fd29268>\n",
      "    │    └ <handlers.run_handlers.db_deploy_utils.db_representation_creator.DatabaseRepresentationCreator object at 0x7f51e00e90b8>\n",
      "    └ <handlers.run_handlers.database_deployment_handler.DatabaseDeploymentHandler object at 0x7f517c64b588>\n",
      "\n",
      "  File \"/opt/bobby/handlers/run_handlers/db_deploy_utils/db_representation_creator.py\", line 78, in create_alternate_representations\n",
      "    self.representation_generator()\n",
      "    │    └ <bound method DatabaseRepresentationCreator._create_alternate_h2o of <handlers.run_handlers.db_deploy_utils.db_representation...\n",
      "    └ <handlers.run_handlers.db_deploy_utils.db_representation_creator.DatabaseRepresentationCreator object at 0x7f51e00e90b8>\n",
      "\n",
      "  File \"/opt/bobby/handlers/run_handlers/db_deploy_utils/db_representation_creator.py\", line 109, in _create_alternate_h2o\n",
      "    download_mojo(f'/{tmpdir}/h2o_model.zip')\n",
      "\n",
      "  File \"/usr/local/lib/python3.7/site-packages/h2o/model/model_base.py\", line 966, in download_mojo\n",
      "    return h2o.api(\"GET /3/Models/%s/mojo\" % self.model_id, save_to=path)\n",
      "           │   │                             │    │                 └ '//tmp/tmpv3z9scrk/h2o_model.zip'\n",
      "           │   │                             │    └ <property object at 0x7f51e16ad4a8>\n",
      "           │   │                             └ \n",
      "           │   └ <function api at 0x7f51e14f76a8>\n",
      "           └ <module 'h2o' from '/usr/local/lib/python3.7/site-packages/h2o/__init__.py'>\n",
      "  File \"/usr/local/lib/python3.7/site-packages/h2o/h2o.py\", line 107, in api\n",
      "    return h2oconn.request(endpoint, data=data, json=json, filename=filename, save_to=save_to)\n",
      "           │       │       │              │          │              │                 └ '//tmp/tmpv3z9scrk/h2o_model.zip'\n",
      "           │       │       │              │          │              └ None\n",
      "           │       │       │              │          └ None\n",
      "           │       │       │              └ None\n",
      "           │       │       └ 'GET /3/Models/TargetEncoder_model_python_1606341758081_104/mojo'\n",
      "           │       └ <function H2OConnection.request at 0x7f51e164d620>\n",
      "           └ <H2OConnection to http://splicedb-bobby-0.splicedb-bobby.test.svc.cluster.local:54323, no session>\n",
      "  File \"/usr/local/lib/python3.7/site-packages/h2o/backend/connection.py\", line 478, in request\n",
      "    return self._process_response(resp, save_to)\n",
      "           │    │                 │     └ '//tmp/tmpv3z9scrk/h2o_model.zip'\n",
      "           │    │                 └ <Response [500]>\n",
      "           │    └ <staticmethod object at 0x7f51e1701320>\n",
      "           └ <H2OConnection to http://splicedb-bobby-0.splicedb-bobby.test.svc.cluster.local:54323, no session>\n",
      "  File \"/usr/local/lib/python3.7/site-packages/h2o/backend/connection.py\", line 829, in _process_response\n",
      "    raise H2OServerError(\"HTTP %d %s:\\n%r\" % (status_code, response.reason, data))\n",
      "          │                                   │            │        │       └ '<html>\\n<head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\"/>\\n<title>Error 500 Server Error</title>\\n...\n",
      "          │                                   │            │        └ 'Server Error'\n",
      "          │                                   │            └ <Response [500]>\n",
      "          │                                   └ 500\n",
      "          └ <class 'h2o.exceptions.H2OServerError'>\n",
      "\n",
      "h2o.exceptions.H2OServerError: HTTP 500 Server Error:\n",
      "'<html>\\n<head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\"/>\\n<title>Error 500 Server Error</title>\\n</head>\\n<body><h2>HTTP ERROR 500</h2>\\n<p>Problem accessing /3/Models/TargetEncoder_model_python_1606341758081_104/mojo. Reason:\\n<pre>    Server Error</pre></p><h3>Caused by:</h3><pre>java.lang.NullPointerException\\n\\tat ai.h2o.targetencoding.TargetEncoderMojoWriter.writeTargetEncodingMap(TargetEncoderMojoWriter.java:86)\\n\\tat ai.h2o.targetencoding.TargetEncoderMojoWriter.writeModelData(TargetEncoderMojoWriter.java:39)\\n\\tat hex.genmodel.AbstractMojoWriter.writeTo(AbstractMojoWriter.java:149)\\n\\tat hex.genmodel.AbstractMojoWriter.writeTo(AbstractMojoWriter.java:143)\\n\\tat hex.ModelMojoWriter.writeTo(ModelMojoWriter.java:78)\\n\\tat water.api.NanoStreamResponse.writeTo(NanoStreamResponse.java:17)\\n\\tat water.api.RequestServer.doGeneric(RequestServer.java:319)\\n\\tat water.api.RequestServer.doGet(RequestServer.java:225)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat ai.h2o.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat ai.h2o.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:535)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1317)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat ai.h2o.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1219)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat water.webserver.jetty9.Jetty9ServerAdapter$LoginHandler.handle(Jetty9ServerAdapter.java:130)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat ai.h2o.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat ai.h2o.org.eclipse.jetty.server.Server.handle(Server.java:531)\\n\\tat ai.h2o.org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:352)\\n\\tat ai.h2o.org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat ai.h2o.org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:281)\\n\\tat ai.h2o.org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:102)\\n\\tat ai.h2o.org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:762)\\n\\tat ai.h2o.org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:680)\\n\\tat java.lang.Thread.run(Thread.java:745)\\n</pre>\\n\\n</body>\\n</html>\\n'\n",
      "INFO     2020-11-25 22:05:43.003 - TASK_COMPLETED\n"
     ]
    }
   ],
   "source": [
    "titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "titanic.rename(columns={'home.dest':'home_dest'})\n",
    "predictors = [\"home_dest\", \"cabin\", \"embarked\"]\n",
    "response = \"survived\"\n",
    "titanic[\"survived\"] = titanic[\"survived\"].asfactor()\n",
    "fold_col = \"kfold_column\"\n",
    "titanic[fold_col] = titanic.kfold_column(n_folds=5, seed=1234)\n",
    "model = H2OTargetEncoderEstimator(k=35,\n",
    "                                       f=25,\n",
    "                                       blending=True)\n",
    "model.train(x=predictors,\n",
    "                 y=response,\n",
    "                 training_frame=titanic)\n",
    "\n",
    "\n",
    "print('deploying target encoder')\n",
    "splice.dropTableIfExists('splice.te')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db('splice','te',mlflow.current_run_id(), df=hc.asSparkFrame(titanic).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_nn (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_nn (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_nn;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make,prediction, c3,c4,c5,c6,c8 into ${data_and_preds} from h2o_nn;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "438.542px",
    "left": "10px",
    "top": "150px",
    "width": "194.219px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
