{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go through the cells until you see STOP in markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from h2o.estimators import *\n",
    "from pysparkling import *\n",
    "import h2o\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "spark = SparkSession.builder.config('spark.dynamicAllocation.enabled','false').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create H2O Sparkling Water cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://10.129.34.72:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>14 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>4 months and 3 days !!!</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>sparkling-water-jovyan_spark-application-1622826988926</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.667 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://10.129.34.72:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>null</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.7 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------------------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         14 secs\n",
       "H2O_cluster_timezone:       UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.0.4\n",
       "H2O_cluster_version_age:    4 months and 3 days !!!\n",
       "H2O_cluster_name:           sparkling-water-jovyan_spark-application-1622826988926\n",
       "H2O_cluster_total_nodes:    2\n",
       "H2O_cluster_free_memory:    7.667 Gb\n",
       "H2O_cluster_total_cores:    32\n",
       "H2O_cluster_allowed_cores:  10\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://10.129.34.72:54321\n",
       "H2O_connection_proxy:       null\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.7 final\n",
       "--------------------------  -------------------------------------------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.32.0.4-1-3.0\n",
      " * H2O name: jovyan\n",
      " * cluster size: 2\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,10.129.34.38,54321)\n",
      "  (1,10.129.35.38,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://10.129.34.72:54321 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "conf = H2OConf().setInternalClusterMode()\n",
    "hc = H2OContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'h2o deployment' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "from splicemachine.spark.context import PySpliceContext\n",
    "splice = PySpliceContext(spark)\n",
    "from splicemachine.mlflow_support import *\n",
    "from splicemachine.mlflow_support.utilities import get_user\n",
    "mlflow.register_splice_context(splice)\n",
    "mlflow.set_experiment('h2o deployment')\n",
    "schema = get_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "deploying gbm\n",
      "Uploading file... Done.\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2021-06-04 17:17:21.788 - A service worker has found your request\n",
      "INFO     2021-06-04 17:17:21.925 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2021-06-04 17:17:22.064 - Handler is available\n",
      "INFO     2021-06-04 17:17:22.088 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2021-06-04 17:17:22.196 - Retrieved MLFlow Run\n",
      "INFO     2021-06-04 17:17:22.227 - Updating MLFlow Run for the UI\n",
      "INFO     2021-06-04 17:17:22.350 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2021-06-04 17:17:22.384 - Extracting Model from DB with Name: model\n",
      "INFO     2021-06-04 17:17:22.429 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2021-06-04 17:17:22.475 - Decompressing Model Artifact\n",
      "INFO     2021-06-04 17:17:22.506 - Creating raw model representation from MLModel\n",
      "INFO     2021-06-04 17:17:22.540 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2021-06-04 17:17:23.035 - Registering Raw Model Representation...\n",
      "INFO     2021-06-04 17:17:23.065 - Done.\n",
      "INFO     2021-06-04 17:17:23.097 - Adding Model Schema and DF...\n",
      "INFO     2021-06-04 17:17:24.057 - Adding Library Specific Representations...\n",
      "INFO     2021-06-04 17:17:24.091 - Adding Serialized Representation\n",
      "INFO     2021-06-04 17:17:24.276 - Updating Artifact with serialized representation\n",
      "INFO     2021-06-04 17:17:24.319 - Preparing Model Metadata for Deployment...\n",
      "INFO     2021-06-04 17:17:24.359 - Preparing H2O Model metadata for deployment\n",
      "INFO     2021-06-04 17:17:24.407 - Using sanitized labels ['C0', 'C1'] as labels for predictions\n",
      "INFO     2021-06-04 17:17:24.521 - Adding Schema String to model metadata...\n",
      "INFO     2021-06-04 17:17:24.564 - Starting 'creating model deployment table'...\n",
      "INFO     2021-06-04 17:17:24.692 - Executing\n",
      "CREATE TABLE SPLICE.H2O_GBM (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT 'e0f498837a09',\n",
      "                SIBSP TINYINT, SEX VARCHAR(20000), AGE FLOAT,MOMENT_KEY INTEGER,PREDICTION VARCHAR(5000),C0 DOUBLE,C1 DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2021-06-04 17:17:26.203 - Done with 'creating model deployment table' [in 1639.4824981689453 ms]\n",
      "INFO     2021-06-04 17:17:26.237 - Starting 'creating trigger'...\n",
      "INFO     2021-06-04 17:17:26.274 - Creating VTI Prediction Trigger...\n",
      "INFO     2021-06-04 17:17:26.515 - Executing\n",
      "CREATE TRIGGER SPLICE.runModel_H2O_GBM_e0f498837a09 \n",
      "                        AFTER INSERT ON SPLICE.H2O_GBM REFERENCING NEW TABLE AS NT FOR EACH STATEMENT\n",
      "                        UPDATE SPLICE.H2O_GBM --splice-properties useSpark=False \n",
      "SET (PREDICTION,C0,C1) = (SELECT b.PREDICTION,b.C0,b.C1 FROM new \"com.splicemachine.mlrunner.MLRunner\"('classification', 'e0f498837a09',\n",
      "        new \"com.splicemachine.derby.catalog.TriggerNewTransitionRows\"(),'SPLICE', \n",
      "        'H2O_GBM', 'NULL', 'NULL', \n",
      "        cast(-1 as float), 'sibsp,sex,age', 'C0,C1', 10000)\n",
      "         as b (cur_user VARCHAR(50),eval_time TIMESTAMP,run_id VARCHAR(50),sibsp SMALLINT,sex VARCHAR(20000),age FLOAT,moment_key INTEGER,prediction VARCHAR(5000),c0 FLOAT,c1 FLOAT) --splice-properties useSpark=False, joinStrategy = sortmerge \n",
      "WHERE SPLICE.H2O_GBM.MOMENT_KEY = b.MOMENT_KEY)\n",
      "INFO     2021-06-04 17:17:27.316 - Done with 'creating trigger' [in 1079.3230533599854 ms]\n",
      "INFO     2021-06-04 17:17:27.346 - Starting 'add model to metadata table'...\n",
      "INFO     2021-06-04 17:17:27.383 - Adding Model to Metadata table\n",
      "INFO     2021-06-04 17:17:27.543 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2021-06-04 17:17:27.728 - Done executing.\n",
      "INFO     2021-06-04 17:17:27.761 - Done with 'add model to metadata table' [in 415.35043716430664 ms]\n",
      "INFO     2021-06-04 17:17:27.791 - Starting 'Managing Feature Store metadata'...\n",
      "INFO     2021-06-04 17:17:27.819 - Checking if run was created with Feature Store training set\n",
      "INFO     2021-06-04 17:17:27.880 - Done with 'Managing Feature Store metadata' [in 89.6916389465332 ms]\n",
      "INFO     2021-06-04 17:17:27.909 - Flushing\n",
      "INFO     2021-06-04 17:17:27.937 - Committing Transaction to Database\n",
      "INFO     2021-06-04 17:17:28.003 - Committed.\n",
      "INFO     2021-06-04 17:17:28.034 - Cleaning up deployment\n",
      "INFO     2021-06-04 17:17:28.140 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2021-06-04 17:17:28.185 - TASK_COMPLETEDUploading file... Done.\n",
      "Saved artifact as e0f498837a09_run_log.ipynb in mlflow\n",
      "Uploading file... Done.\n",
      "Saved artifact as e0f498837a09_run_log.html in mlflow\n",
      "Loading model\n",
      "Downloading file model\n",
      "Done. Unpacking artifact\n",
      "Running model\n",
      "Getting results\n",
      "Comparing DB results to model results\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "\n",
    "\n",
    "# Import the titanic dataset into H2O:\n",
    "titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "\n",
    "# Set the predictors and response; set the response as a factor:\n",
    "titanic[\"survived\"] = titanic[\"survived\"].asfactor()\n",
    "predictors = ['sibsp', 'sex', 'age']\n",
    "response = \"survived\"\n",
    "\n",
    "# Split the dataset into a train and valid set:\n",
    "train, valid = titanic.split_frame(ratios=[.8], seed=1234)\n",
    "\n",
    "\n",
    "model = H2OGradientBoostingEstimator(ntrees         =50,\n",
    "                                        max_depth      =6,\n",
    "                                        learn_rate     =0.1, \n",
    "                                        nfolds         =2)\n",
    "\n",
    "model.train(x               =predictors,\n",
    "               y               =response,\n",
    "               training_frame  =train,\n",
    "               validation_frame=valid\n",
    "               )\n",
    "\n",
    "\n",
    "print('deploying gbm')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_gbm')\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_gbm',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key={'MOMENT_KEY':'INTEGER'})\n",
    "    mlflow.watch_job(jid)\n",
    "\n",
    "print(f'Loading model {run.info.run_uuid}')\n",
    "mlflow.load_model(run.info.run_uuid)\n",
    "print('Running model')\n",
    "splice.execute(\"insert into h2o_gbm (moment_key,sibsp,sex,age) values(0, 5,'female',2.496)\")    \n",
    "splice.execute(\"insert into h2o_gbm (moment_key,sibsp,sex,age) values(1, 1,'male',-7.048)\")\n",
    "print('Getting results')\n",
    "data = splice.df('select sibsp, sex, age, prediction, c0, c1 from h2o_gbm').toPandas()\n",
    "print('Comparing DB results to model results')\n",
    "features = h2o.H2OFrame(data[['SIBSP','SEX','AGE']])\n",
    "db_preds = data[['PREDICTION','C0','C1']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p, db_c0, db_c1 = db_pred[1]\n",
    "    raw_p, raw_c0, raw_c1 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    raw_p = f'C{int(raw_p)}'\n",
    "    \n",
    "    assert db_p == raw_p, f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    assert round(db_c0,14) == round(raw_c0,14), f'Something is wrong. Model Table gives {db_c0} but raw model gives {raw_c0}'\n",
    "    assert round(db_c1,14) == round(raw_c1,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "deploying multinomial\n",
      "Uploading file... Done.\n",
      "Deploying model to database...\n",
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2021-06-04 17:19:45.741 - A service worker has found your request\n",
      "INFO     2021-06-04 17:19:45.801 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2021-06-04 17:19:45.861 - Handler is available\n",
      "INFO     2021-06-04 17:19:45.883 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2021-06-04 17:19:45.996 - Retrieved MLFlow Run\n",
      "INFO     2021-06-04 17:19:46.025 - Updating MLFlow Run for the UI\n",
      "INFO     2021-06-04 17:19:46.098 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2021-06-04 17:19:46.126 - Extracting Model from DB with Name: model\n",
      "INFO     2021-06-04 17:19:46.174 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2021-06-04 17:19:46.210 - Decompressing Model Artifact\n",
      "INFO     2021-06-04 17:19:46.243 - Creating raw model representation from MLModel\n",
      "INFO     2021-06-04 17:19:46.274 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2021-06-04 17:19:46.383 - Registering Raw Model Representation...\n",
      "INFO     2021-06-04 17:19:46.415 - Done.\n",
      "INFO     2021-06-04 17:19:46.447 - Adding Model Schema and DF...\n",
      "INFO     2021-06-04 17:19:46.579 - Adding Library Specific Representations...\n",
      "INFO     2021-06-04 17:19:46.608 - Adding Serialized Representation\n",
      "INFO     2021-06-04 17:19:46.739 - Updating Artifact with serialized representation\n",
      "INFO     2021-06-04 17:19:46.769 - Preparing Model Metadata for Deployment...\n",
      "INFO     2021-06-04 17:19:46.798 - Preparing H2O Model metadata for deployment\n",
      "INFO     2021-06-04 17:19:46.829 - Using sanitized labels ['C3', 'C4', 'C5', 'C6', 'C8'] as labels for predictions\n",
      "INFO     2021-06-04 17:19:46.875 - Adding Schema String to model metadata...\n",
      "INFO     2021-06-04 17:19:46.903 - Starting 'creating model deployment table'...\n",
      "INFO     2021-06-04 17:19:46.963 - Executing\n",
      "CREATE TABLE SPLICE.H2O_MULTINOMIAL (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '500c78ba38bf',\n",
      "                DISPLACEMENT FLOAT, POWER SMALLINT, WEIGHT SMALLINT, ACCELERATION FLOAT, YEAR_MAKE TINYINT,MOMENT_KEY INTEGER,PREDICTION VARCHAR(5000),C3 DOUBLE,C4 DOUBLE,C5 DOUBLE,C6 DOUBLE,C8 DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2021-06-04 17:19:47.881 - Done with 'creating model deployment table' [in 977.6310920715332 ms]\n",
      "INFO     2021-06-04 17:19:47.909 - Starting 'creating trigger'...\n",
      "INFO     2021-06-04 17:19:47.935 - Creating VTI Prediction Trigger...\n",
      "INFO     2021-06-04 17:19:48.036 - Executing\n",
      "CREATE TRIGGER SPLICE.runModel_H2O_MULTINOMIAL_500c78ba38bf \n",
      "                        AFTER INSERT ON SPLICE.H2O_MULTINOMIAL REFERENCING NEW TABLE AS NT FOR EACH STATEMENT\n",
      "                        UPDATE SPLICE.H2O_MULTINOMIAL --splice-properties useSpark=False \n",
      "SET (PREDICTION,C3,C4,C5,C6,C8) = (SELECT b.PREDICTION,b.C3,b.C4,b.C5,b.C6,b.C8 FROM new \"com.splicemachine.mlrunner.MLRunner\"('classification', '500c78ba38bf',\n",
      "        new \"com.splicemachine.derby.catalog.TriggerNewTransitionRows\"(),'SPLICE', \n",
      "        'H2O_MULTINOMIAL', 'NULL', 'NULL', \n",
      "        cast(-1 as float), 'displacement,power,weight,acceleration,year_make', 'C3,C4,C5,C6,C8', 10000)\n",
      "         as b (cur_user VARCHAR(50),eval_time TIMESTAMP,run_id VARCHAR(50),displacement FLOAT,power SMALLINT,weight SMALLINT,acceleration FLOAT,year_make SMALLINT,moment_key INTEGER,prediction VARCHAR(5000),c3 FLOAT,c4 FLOAT,c5 FLOAT,c6 FLOAT,c8 FLOAT) --splice-properties useSpark=False, joinStrategy = sortmerge \n",
      "WHERE SPLICE.H2O_MULTINOMIAL.MOMENT_KEY = b.MOMENT_KEY)\n",
      "INFO     2021-06-04 17:19:48.687 - Done with 'creating trigger' [in 778.0215740203857 ms]\n",
      "INFO     2021-06-04 17:19:48.715 - Starting 'add model to metadata table'...\n",
      "INFO     2021-06-04 17:19:48.743 - Adding Model to Metadata table\n",
      "INFO     2021-06-04 17:19:48.884 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2021-06-04 17:19:48.971 - Done executing.\n",
      "INFO     2021-06-04 17:19:49.000 - Done with 'add model to metadata table' [in 284.8649024963379 ms]\n",
      "INFO     2021-06-04 17:19:49.025 - Starting 'Managing Feature Store metadata'...\n",
      "INFO     2021-06-04 17:19:49.057 - Checking if run was created with Feature Store training set\n",
      "INFO     2021-06-04 17:19:49.101 - Done with 'Managing Feature Store metadata' [in 75.77896118164062 ms]\n",
      "INFO     2021-06-04 17:19:49.128 - Flushing\n",
      "INFO     2021-06-04 17:19:49.157 - Committing Transaction to Database\n",
      "INFO     2021-06-04 17:19:49.218 - Committed.\n",
      "INFO     2021-06-04 17:19:49.246 - Cleaning up deployment\n",
      "INFO     2021-06-04 17:19:49.307 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2021-06-04 17:19:49.346 - TASK_COMPLETEDUploading file... Done.\n",
      "Saved artifact as 500c78ba38bf_run_log.ipynb in mlflow\n",
      "Uploading file... Done.\n",
      "Saved artifact as 500c78ba38bf_run_log.html in mlflow\n",
      "Loading model\n",
      "Downloading file model\n",
      "Done. Unpacking artifact\n",
      "Running model\n",
      "Getting results\n",
      "Comparing DB results to model results\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars[\"cylinders\"] = cars[\"cylinders\"].asfactor()\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response_col = \"cylinders\"\n",
    "distribution = \"multinomial\"\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "\n",
    "train.rename(columns={'year':'year_make'})\n",
    "\n",
    "model = H2OGradientBoostingEstimator(nfolds=3,\n",
    "                                   distribution=distribution)\n",
    "model.train(x=predictors,\n",
    "          y=response_col,\n",
    "          training_frame=train,\n",
    "          validation_frame=valid)\n",
    "\n",
    "\n",
    "\n",
    "print('deploying multinomial')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_multinomial')\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_multinomial',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key={'MOMENT_KEY':'INTEGER'})\n",
    "    mlflow.watch_job(jid)\n",
    "print(f'Loading model {run.info.run_uuid}')\n",
    "mlflow.load_model(run.info.run_uuid)\n",
    "print('Running model')\n",
    "splice.execute(\"insert into h2o_multinomial (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1)\")\n",
    "splice.execute(\"insert into h2o_multinomial (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2)\")\n",
    "print('Getting results')\n",
    "data = splice.df(\"select displacement,power,weight,acceleration,year_make,prediction, c3,c4,c5,c6,c8 from h2o_multinomial\").toPandas()\n",
    "print('Comparing DB results to model results')\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION','C3','C4','C5','C6','C8']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p, db_c0, db_c1, db_c2, db_c3, db_c4 = db_pred[1]\n",
    "    raw_p, raw_c0, raw_c1, raw_c2, raw_c3, raw_c4 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    raw_p = f'C{int(raw_p)}'\n",
    "    \n",
    "    assert db_p == raw_p, f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    assert round(db_c0,14) == round(raw_c0,14), f'Something is wrong. Model Table gives {db_c0} but raw model gives {raw_c0}'\n",
    "    assert round(db_c1,14) == round(raw_c1,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c2,14) == round(raw_c2,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c3,14) == round(raw_c3,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c4,14) == round(raw_c4,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reached maximum number of iterations 50!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploying ordinal\n",
      "Uploading file... Done.\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2021-06-04 17:21:55.037 - A service worker has found your request\n",
      "INFO     2021-06-04 17:21:55.089 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2021-06-04 17:21:55.141 - Handler is available\n",
      "INFO     2021-06-04 17:21:55.160 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2021-06-04 17:21:55.260 - Retrieved MLFlow Run\n",
      "INFO     2021-06-04 17:21:55.288 - Updating MLFlow Run for the UI\n",
      "INFO     2021-06-04 17:21:55.361 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2021-06-04 17:21:55.390 - Extracting Model from DB with Name: model\n",
      "INFO     2021-06-04 17:21:55.428 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2021-06-04 17:21:55.463 - Decompressing Model Artifact\n",
      "INFO     2021-06-04 17:21:55.491 - Creating raw model representation from MLModel\n",
      "INFO     2021-06-04 17:21:55.519 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2021-06-04 17:21:55.670 - Registering Raw Model Representation...\n",
      "INFO     2021-06-04 17:21:55.702 - Done.\n",
      "INFO     2021-06-04 17:21:55.726 - Adding Model Schema and DF...\n",
      "INFO     2021-06-04 17:21:55.814 - Adding Library Specific Representations...\n",
      "INFO     2021-06-04 17:21:55.843 - Adding Serialized Representation\n",
      "INFO     2021-06-04 17:21:55.948 - Updating Artifact with serialized representation\n",
      "INFO     2021-06-04 17:21:55.975 - Preparing Model Metadata for Deployment...\n",
      "INFO     2021-06-04 17:21:56.003 - Preparing H2O Model metadata for deployment\n",
      "INFO     2021-06-04 17:21:56.033 - Using sanitized labels ['C3', 'C4', 'C5', 'C6', 'C8'] as labels for predictions\n",
      "INFO     2021-06-04 17:21:56.077 - Adding Schema String to model metadata...\n",
      "INFO     2021-06-04 17:21:56.101 - Starting 'creating model deployment table'...\n",
      "INFO     2021-06-04 17:21:56.158 - Executing\n",
      "CREATE TABLE SPLICE.H2O_ORDINAL (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '3a3bfe61d4a0',\n",
      "                DISPLACEMENT FLOAT, POWER SMALLINT, WEIGHT SMALLINT, ACCELERATION FLOAT, YEAR_MAKE TINYINT,MOMENT_KEY INTEGER,PREDICTION VARCHAR(5000),C3 DOUBLE,C4 DOUBLE,C5 DOUBLE,C6 DOUBLE,C8 DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2021-06-04 17:21:57.073 - Done with 'creating model deployment table' [in 971.677303314209 ms]\n",
      "INFO     2021-06-04 17:21:57.101 - Starting 'creating trigger'...\n",
      "INFO     2021-06-04 17:21:57.127 - Creating VTI Prediction Trigger...\n",
      "INFO     2021-06-04 17:21:57.222 - Executing\n",
      "CREATE TRIGGER SPLICE.runModel_H2O_ORDINAL_3a3bfe61d4a0 \n",
      "                        AFTER INSERT ON SPLICE.H2O_ORDINAL REFERENCING NEW TABLE AS NT FOR EACH STATEMENT\n",
      "                        UPDATE SPLICE.H2O_ORDINAL --splice-properties useSpark=False \n",
      "SET (PREDICTION,C3,C4,C5,C6,C8) = (SELECT b.PREDICTION,b.C3,b.C4,b.C5,b.C6,b.C8 FROM new \"com.splicemachine.mlrunner.MLRunner\"('classification', '3a3bfe61d4a0',\n",
      "        new \"com.splicemachine.derby.catalog.TriggerNewTransitionRows\"(),'SPLICE', \n",
      "        'H2O_ORDINAL', 'NULL', 'NULL', \n",
      "        cast(-1 as float), 'displacement,power,weight,acceleration,year_make', 'C3,C4,C5,C6,C8', 10000)\n",
      "         as b (cur_user VARCHAR(50),eval_time TIMESTAMP,run_id VARCHAR(50),displacement FLOAT,power SMALLINT,weight SMALLINT,acceleration FLOAT,year_make SMALLINT,moment_key INTEGER,prediction VARCHAR(5000),c3 FLOAT,c4 FLOAT,c5 FLOAT,c6 FLOAT,c8 FLOAT) --splice-properties useSpark=False, joinStrategy = sortmerge \n",
      "WHERE SPLICE.H2O_ORDINAL.MOMENT_KEY = b.MOMENT_KEY)\n",
      "INFO     2021-06-04 17:21:57.839 - Done with 'creating trigger' [in 738.0290031433105 ms]\n",
      "INFO     2021-06-04 17:21:57.867 - Starting 'add model to metadata table'...\n",
      "INFO     2021-06-04 17:21:57.894 - Adding Model to Metadata table\n",
      "INFO     2021-06-04 17:21:58.026 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2021-06-04 17:21:58.125 - Done executing.\n",
      "INFO     2021-06-04 17:21:58.167 - Done with 'add model to metadata table' [in 299.6828556060791 ms]\n",
      "INFO     2021-06-04 17:21:58.193 - Starting 'Managing Feature Store metadata'...\n",
      "INFO     2021-06-04 17:21:58.220 - Checking if run was created with Feature Store training set\n",
      "INFO     2021-06-04 17:21:58.262 - Done with 'Managing Feature Store metadata' [in 68.39370727539062 ms]\n",
      "INFO     2021-06-04 17:21:58.291 - Flushing\n",
      "INFO     2021-06-04 17:21:58.317 - Committing Transaction to Database\n",
      "INFO     2021-06-04 17:21:58.374 - Committed.\n",
      "INFO     2021-06-04 17:21:58.399 - Cleaning up deployment\n",
      "INFO     2021-06-04 17:21:58.459 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2021-06-04 17:21:58.490 - TASK_COMPLETEDUploading file... Done.\n",
      "Saved artifact as 3a3bfe61d4a0_run_log.ipynb in mlflow\n",
      "Uploading file... Done.\n",
      "Saved artifact as 3a3bfe61d4a0_run_log.html in mlflow\n",
      "Loading model 3a3bfe61d4a0\n",
      "Downloading file model\n",
      "Done. Unpacking artifact\n",
      "Running model\n",
      "Getting results\n",
      "Comparing DB results to model results\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars[\"cylinders\"] = cars[\"cylinders\"].asfactor()\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response = \"cylinders\"\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "model = H2OGeneralizedLinearEstimator(seed=1234,\n",
    "                                         family='ordinal')\n",
    "model.train(x=predictors,\n",
    "               y=response,\n",
    "               training_frame=train,\n",
    "               validation_frame=valid)\n",
    "\n",
    "\n",
    "print('deploying ordinal')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_ordinal')\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_ordinal',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key={'MOMENT_KEY':'INTEGER'})\n",
    "    mlflow.watch_job(jid)\n",
    "    \n",
    "print(f'Loading model {run.info.run_uuid}')\n",
    "mlflow.load_model(run.info.run_uuid)\n",
    "print('Running model')\n",
    "splice.execute(\"insert into h2o_ordinal (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 )\")\n",
    "splice.execute(\"insert into h2o_ordinal (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2)\")\n",
    "print('Getting results')\n",
    "data = splice.df(\"select displacement,power,weight,acceleration,year_make,prediction, c3,c4,c5,c6,c8 from h2o_ordinal\").toPandas()\n",
    "print('Comparing DB results to model results')\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION','C3','C4','C5','C6','C8']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p, db_c0, db_c1, db_c2, db_c3, db_c4 = db_pred[1]\n",
    "    raw_p, raw_c0, raw_c1, raw_c2, raw_c3, raw_c4 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    raw_p = f'C{int(raw_p)}'\n",
    "    \n",
    "    assert db_p == raw_p, f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    assert round(db_c0,14) == round(raw_c0,14), f'Something is wrong. Model Table gives {db_c0} but raw model gives {raw_c0}'\n",
    "    assert round(db_c1,14) == round(raw_c1,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c2,14) == round(raw_c2,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c3,14) == round(raw_c3,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c4,14) == round(raw_c4,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression (Gradient Boosting Estimator) Model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "deploying regression\n",
      "Table exists. Dropping table\n",
      "Uploading file... Done.\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2021-06-04 17:26:18.294 - A service worker has found your request\n",
      "INFO     2021-06-04 17:26:18.396 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2021-06-04 17:26:18.549 - Handler is available\n",
      "INFO     2021-06-04 17:26:18.566 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2021-06-04 17:26:18.783 - Retrieved MLFlow Run\n",
      "INFO     2021-06-04 17:26:18.808 - Updating MLFlow Run for the UI\n",
      "INFO     2021-06-04 17:26:18.875 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2021-06-04 17:26:18.902 - Extracting Model from DB with Name: model\n",
      "INFO     2021-06-04 17:26:18.942 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2021-06-04 17:26:18.997 - Decompressing Model Artifact\n",
      "INFO     2021-06-04 17:26:19.024 - Creating raw model representation from MLModel\n",
      "INFO     2021-06-04 17:26:19.053 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2021-06-04 17:26:19.123 - Registering Raw Model Representation...\n",
      "INFO     2021-06-04 17:26:19.152 - Done.\n",
      "INFO     2021-06-04 17:26:19.176 - Adding Model Schema and DF...\n",
      "INFO     2021-06-04 17:26:19.268 - Adding Library Specific Representations...\n",
      "INFO     2021-06-04 17:26:19.297 - Adding Serialized Representation\n",
      "INFO     2021-06-04 17:26:19.445 - Updating Artifact with serialized representation\n",
      "INFO     2021-06-04 17:26:19.473 - Preparing Model Metadata for Deployment...\n",
      "INFO     2021-06-04 17:26:19.505 - Preparing H2O Model metadata for deployment\n",
      "INFO     2021-06-04 17:26:19.551 - Adding Schema String to model metadata...\n",
      "INFO     2021-06-04 17:26:19.578 - Starting 'creating model deployment table'...\n",
      "INFO     2021-06-04 17:26:19.645 - Executing\n",
      "CREATE TABLE SPLICE.H2O_REGRESSION (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT 'a69ccbe5ec53',\n",
      "                DISPLACEMENT FLOAT, POWER SMALLINT, WEIGHT SMALLINT, ACCELERATION FLOAT, YEAR_MAKE TINYINT,MOMENT_KEY INTEGER,PREDICTION DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2021-06-04 17:26:20.691 - Done with 'creating model deployment table' [in 1113.1856441497803 ms]\n",
      "INFO     2021-06-04 17:26:20.716 - Starting 'creating trigger'...\n",
      "INFO     2021-06-04 17:26:20.743 - Creating VTI Prediction Trigger...\n",
      "INFO     2021-06-04 17:26:20.972 - Executing\n",
      "CREATE TRIGGER SPLICE.runModel_H2O_REGRESSION_a69ccbe5ec53 \n",
      "                        AFTER INSERT ON SPLICE.H2O_REGRESSION REFERENCING NEW TABLE AS NT FOR EACH STATEMENT\n",
      "                        UPDATE SPLICE.H2O_REGRESSION --splice-properties useSpark=False \n",
      "SET (PREDICTION) = (SELECT b.PREDICTION FROM new \"com.splicemachine.mlrunner.MLRunner\"('regression', 'a69ccbe5ec53',\n",
      "        new \"com.splicemachine.derby.catalog.TriggerNewTransitionRows\"(),'SPLICE', \n",
      "        'H2O_REGRESSION', 'NULL', 'NULL', \n",
      "        cast(-1 as float), 'displacement,power,weight,acceleration,year_make', '', 10000)\n",
      "         as b (cur_user VARCHAR(50),eval_time TIMESTAMP,run_id VARCHAR(50),displacement FLOAT,power SMALLINT,weight SMALLINT,acceleration FLOAT,year_make SMALLINT,moment_key INTEGER,prediction FLOAT) --splice-properties useSpark=False, joinStrategy = sortmerge \n",
      "WHERE SPLICE.H2O_REGRESSION.MOMENT_KEY = b.MOMENT_KEY)\n",
      "INFO     2021-06-04 17:26:21.580 - Done with 'creating trigger' [in 864.3918037414551 ms]\n",
      "INFO     2021-06-04 17:26:21.608 - Starting 'add model to metadata table'...\n",
      "INFO     2021-06-04 17:26:21.635 - Adding Model to Metadata table\n",
      "INFO     2021-06-04 17:26:21.765 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2021-06-04 17:26:21.857 - Done executing.\n",
      "INFO     2021-06-04 17:26:21.884 - Done with 'add model to metadata table' [in 276.1228084564209 ms]\n",
      "INFO     2021-06-04 17:26:21.918 - Starting 'Managing Feature Store metadata'...\n",
      "INFO     2021-06-04 17:26:21.943 - Checking if run was created with Feature Store training set\n",
      "INFO     2021-06-04 17:26:22.008 - Done with 'Managing Feature Store metadata' [in 90.32201766967773 ms]\n",
      "INFO     2021-06-04 17:26:22.032 - Flushing\n",
      "INFO     2021-06-04 17:26:22.059 - Committing Transaction to Database\n",
      "INFO     2021-06-04 17:26:22.116 - Committed.\n",
      "INFO     2021-06-04 17:26:22.149 - Cleaning up deployment\n",
      "INFO     2021-06-04 17:26:22.207 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2021-06-04 17:26:22.268 - TASK_COMPLETEDUploading file... Done.\n",
      "Saved artifact as a69ccbe5ec53_run_log.ipynb in mlflow\n",
      "Uploading file... Done.\n",
      "Saved artifact as a69ccbe5ec53_run_log.html in mlflow\n",
      "Loading model a69ccbe5ec53\n",
      "Downloading file model\n",
      "Done. Unpacking artifact\n",
      "Running model\n",
      "Getting results\n",
      "Comparing DB results to model results\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Models do not match to 14 decimals. Testing precision\n",
      "Values match to 13 decimals\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response_col = \"economy\"\n",
    "distribution = \"gaussian\"\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "model = H2OGradientBoostingEstimator(nfolds=3,\n",
    "                                   distribution=distribution,\n",
    "                                   fold_assignment=\"Random\")\n",
    "model.train(x=predictors,\n",
    "          y=response_col,\n",
    "          training_frame=train,\n",
    "          validation_frame=valid)\n",
    "model.plot(timestep=\"AUTO\", metric=\"AUTO\",)\n",
    "\n",
    "\n",
    "print('deploying regression')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_regression')\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_regression',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key={'MOMENT_KEY':'INTEGER'})\n",
    "    mlflow.watch_job(jid)\n",
    "    \n",
    "print(f'Loading model {run.info.run_uuid}')\n",
    "mlflow.load_model(run.info.run_uuid)\n",
    "print('Running model')\n",
    "splice.execute(\"insert into h2o_regression (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 )\")\n",
    "splice.execute(\"insert into h2o_regression (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2)\")\n",
    "print('Getting results')\n",
    "data = splice.df(\"select displacement,power,weight,acceleration,year_make,prediction from h2o_regression\").toPandas()\n",
    "print('Comparing DB results to model results')\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p = db_pred[1]['PREDICTION']\n",
    "    raw_p = raw_pred[1]['predict']\n",
    "    \n",
    "    l = min(16, len(str(db_p)), len(str(raw_p))) -2 # -2 because of the decimal point and final value\n",
    "    try:\n",
    "        assert round(db_p,l) == round(raw_p,l), f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    except:\n",
    "        print(f\"Models do not match to {l} decimals. Testing precision\")\n",
    "        while l > 8:\n",
    "            if round(db_p,l) == round(raw_p,l):\n",
    "                print(f'Values match to {l} decimals')\n",
    "                break\n",
    "            l -= 1\n",
    "        if l <= 8:\n",
    "            raise Exception(f\"Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}\")\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HGLM Model example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "deploying hglm\n",
      "Uploading file... Done.\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2021-06-04 17:27:20.187 - A service worker has found your request\n",
      "INFO     2021-06-04 17:27:20.239 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2021-06-04 17:27:20.289 - Handler is available\n",
      "INFO     2021-06-04 17:27:20.308 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2021-06-04 17:27:20.409 - Retrieved MLFlow Run\n",
      "INFO     2021-06-04 17:27:20.436 - Updating MLFlow Run for the UI\n",
      "INFO     2021-06-04 17:27:20.522 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2021-06-04 17:27:20.545 - Extracting Model from DB with Name: model\n",
      "INFO     2021-06-04 17:27:20.580 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2021-06-04 17:27:20.609 - Decompressing Model Artifact\n",
      "INFO     2021-06-04 17:27:20.639 - Creating raw model representation from MLModel\n",
      "INFO     2021-06-04 17:27:20.663 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2021-06-04 17:27:20.741 - Registering Raw Model Representation...\n",
      "INFO     2021-06-04 17:27:20.767 - Done.\n",
      "INFO     2021-06-04 17:27:20.793 - Adding Model Schema and DF...\n",
      "INFO     2021-06-04 17:27:20.868 - Adding Library Specific Representations...\n",
      "INFO     2021-06-04 17:27:20.893 - Adding Serialized Representation\n",
      "INFO     2021-06-04 17:27:20.953 - Updating Artifact with serialized representation\n",
      "INFO     2021-06-04 17:27:20.983 - Preparing Model Metadata for Deployment...\n",
      "INFO     2021-06-04 17:27:21.007 - Preparing H2O Model metadata for deployment\n",
      "INFO     2021-06-04 17:27:21.050 - Adding Schema String to model metadata...\n",
      "INFO     2021-06-04 17:27:21.074 - Starting 'creating model deployment table'...\n",
      "INFO     2021-06-04 17:27:21.134 - Executing\n",
      "CREATE TABLE SPLICE.H2O_HGLM (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '0ffc3b7178fa',\n",
      "                DISPLACEMENT SMALLINT, POWER SMALLINT, WEIGHT SMALLINT, ACCELERATION FLOAT, YEAR_MAKE TINYINT,MOMENT_KEY INTEGER,PREDICTION DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2021-06-04 17:27:22.006 - Done with 'creating model deployment table' [in 931.4210414886475 ms]\n",
      "INFO     2021-06-04 17:27:22.033 - Starting 'creating trigger'...\n",
      "INFO     2021-06-04 17:27:22.055 - Creating VTI Prediction Trigger...\n",
      "INFO     2021-06-04 17:27:22.143 - Executing\n",
      "CREATE TRIGGER SPLICE.runModel_H2O_HGLM_0ffc3b7178fa \n",
      "                        AFTER INSERT ON SPLICE.H2O_HGLM REFERENCING NEW TABLE AS NT FOR EACH STATEMENT\n",
      "                        UPDATE SPLICE.H2O_HGLM --splice-properties useSpark=False \n",
      "SET (PREDICTION) = (SELECT b.PREDICTION FROM new \"com.splicemachine.mlrunner.MLRunner\"('regression', '0ffc3b7178fa',\n",
      "        new \"com.splicemachine.derby.catalog.TriggerNewTransitionRows\"(),'SPLICE', \n",
      "        'H2O_HGLM', 'NULL', 'NULL', \n",
      "        cast(-1 as float), 'displacement,power,weight,acceleration,year_make', '', 10000)\n",
      "         as b (cur_user VARCHAR(50),eval_time TIMESTAMP,run_id VARCHAR(50),displacement SMALLINT,power SMALLINT,weight SMALLINT,acceleration FLOAT,year_make SMALLINT,moment_key INTEGER,prediction FLOAT) --splice-properties useSpark=False, joinStrategy = sortmerge \n",
      "WHERE SPLICE.H2O_HGLM.MOMENT_KEY = b.MOMENT_KEY)\n",
      "INFO     2021-06-04 17:27:22.654 - Done with 'creating trigger' [in 620.7480430603027 ms]\n",
      "INFO     2021-06-04 17:27:22.681 - Starting 'add model to metadata table'...\n",
      "INFO     2021-06-04 17:27:22.705 - Adding Model to Metadata table\n",
      "INFO     2021-06-04 17:27:22.833 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2021-06-04 17:27:22.909 - Done executing.\n",
      "INFO     2021-06-04 17:27:22.937 - Done with 'add model to metadata table' [in 255.48267364501953 ms]\n",
      "INFO     2021-06-04 17:27:22.960 - Starting 'Managing Feature Store metadata'...\n",
      "INFO     2021-06-04 17:27:22.987 - Checking if run was created with Feature Store training set\n",
      "INFO     2021-06-04 17:27:23.027 - Done with 'Managing Feature Store metadata' [in 67.74568557739258 ms]\n",
      "INFO     2021-06-04 17:27:23.054 - Flushing\n",
      "INFO     2021-06-04 17:27:23.077 - Committing Transaction to Database\n",
      "INFO     2021-06-04 17:27:23.132 - Committed.\n",
      "INFO     2021-06-04 17:27:23.153 - Cleaning up deployment\n",
      "INFO     2021-06-04 17:27:23.212 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2021-06-04 17:27:23.243 - TASK_COMPLETEDUploading file... Done.\n",
      "Saved artifact as 0ffc3b7178fa_run_log.ipynb in mlflow\n",
      "Uploading file... Done.\n",
      "Saved artifact as 0ffc3b7178fa_run_log.html in mlflow\n",
      "Loading model 0ffc3b7178fa\n",
      "Downloading file model\n",
      "Done. Unpacking artifact\n",
      "Running model\n",
      "Getting results\n",
      "Comparing DB results to model results\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response = \"economy\"\n",
    "distribution = \"gaussian\"\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "model = H2OGeneralizedLinearEstimator(alpha=.25)\n",
    "model.train(x=predictors,\n",
    "                 y=response,\n",
    "                 training_frame=train,\n",
    "                 validation_frame=valid)\n",
    "\n",
    "\n",
    "print('deploying hglm')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_hglm')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_hglm',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key={'MOMENT_KEY':'INTEGER'})\n",
    "    mlflow.watch_job(jid)\n",
    "    \n",
    "print(f'Loading model {run.info.run_uuid}')\n",
    "mlflow.load_model(run.info.run_uuid)\n",
    "print('Running model')\n",
    "splice.execute(\"insert into h2o_hglm (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 )\")\n",
    "splice.execute(\"insert into h2o_hglm (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2)\")\n",
    "print('Getting results')\n",
    "data = splice.df(\"select displacement,power,weight,acceleration,year_make,prediction from h2o_hglm\").toPandas()\n",
    "print('Comparing DB results to model results')\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p = db_pred[1]['PREDICTION']\n",
    "    raw_p = raw_pred[1]['predict']\n",
    "    \n",
    "    l = min(16, len(str(db_p)), len(str(raw_p))) -2    \n",
    "    try:\n",
    "        assert round(db_p,l) == round(raw_p,l), f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    except:\n",
    "        print(f\"Models do not match to {l} decimals. Testing precision\")\n",
    "        while l > 8:\n",
    "            if round(db_p,l) == round(raw_p,l):\n",
    "                print(f'Values match to {l} decimals')\n",
    "                break\n",
    "            l -= 1\n",
    "        if l <= 8:\n",
    "            raise Exception(f\"Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}\")\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Build word2vec model\n",
      "word2vec Model Build progress: |██████████████████████████████████████████| 100%\n",
      "Sanity check - find synonyms for the word 'teacher'\n",
      "deploying w2v\n",
      "Uploading file... Done.\n",
      "Deploying model to database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing in primary keys as a list of tuples is deprecated. Use dictionary {column name: type}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2021-06-04 17:28:51.422 - A service worker has found your request\n",
      "INFO     2021-06-04 17:28:51.509 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2021-06-04 17:28:51.599 - Handler is available\n",
      "INFO     2021-06-04 17:28:51.614 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2021-06-04 17:28:51.721 - Retrieved MLFlow Run\n",
      "INFO     2021-06-04 17:28:51.744 - Updating MLFlow Run for the UI\n",
      "INFO     2021-06-04 17:28:51.847 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2021-06-04 17:28:51.873 - Extracting Model from DB with Name: model\n",
      "INFO     2021-06-04 17:28:51.901 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2021-06-04 17:28:51.934 - Decompressing Model Artifact\n",
      "INFO     2021-06-04 17:28:51.957 - Creating raw model representation from MLModel\n",
      "INFO     2021-06-04 17:28:51.983 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2021-06-04 17:28:52.063 - Registering Raw Model Representation...\n",
      "INFO     2021-06-04 17:28:52.094 - Done.\n",
      "INFO     2021-06-04 17:28:52.119 - Adding Model Schema and DF...\n",
      "INFO     2021-06-04 17:28:52.207 - Adding Library Specific Representations...\n",
      "INFO     2021-06-04 17:28:52.229 - Adding Serialized Representation\n",
      "INFO     2021-06-04 17:28:52.360 - Updating Artifact with serialized representation\n",
      "INFO     2021-06-04 17:28:52.383 - Preparing Model Metadata for Deployment...\n",
      "INFO     2021-06-04 17:28:52.410 - Preparing H2O Model metadata for deployment\n",
      "INFO     2021-06-04 17:28:52.452 - Using sanitized labels ['word_C0', 'word_C1', 'word_C2', 'word_C3', 'word_C4', 'word_C5', 'word_C6', 'word_C7', 'word_C8', 'word_C9', 'word_C10', 'word_C11', 'word_C12', 'word_C13', 'word_C14'] as labels for predictions\n",
      "INFO     2021-06-04 17:28:52.499 - Adding Schema String to model metadata...\n",
      "INFO     2021-06-04 17:28:52.519 - Starting 'creating model deployment table'...\n",
      "INFO     2021-06-04 17:28:52.575 - Executing\n",
      "CREATE TABLE SPLICE.H2O_W2V (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '04b9877ef43b',\n",
      "                WORD VARCHAR(20000),MOMENT_KEY INTEGER,WORD_C0 DOUBLE,WORD_C1 DOUBLE,WORD_C2 DOUBLE,WORD_C3 DOUBLE,WORD_C4 DOUBLE,WORD_C5 DOUBLE,WORD_C6 DOUBLE,WORD_C7 DOUBLE,WORD_C8 DOUBLE,WORD_C9 DOUBLE,WORD_C10 DOUBLE,WORD_C11 DOUBLE,WORD_C12 DOUBLE,WORD_C13 DOUBLE,WORD_C14 DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2021-06-04 17:28:53.475 - Done with 'creating model deployment table' [in 955.1675319671631 ms]\n",
      "INFO     2021-06-04 17:28:53.501 - Starting 'creating trigger'...\n",
      "INFO     2021-06-04 17:28:53.524 - Creating VTI Prediction Trigger...\n",
      "INFO     2021-06-04 17:28:53.628 - Executing\n",
      "CREATE TRIGGER SPLICE.runModel_H2O_W2V_04b9877ef43b \n",
      "                        AFTER INSERT ON SPLICE.H2O_W2V REFERENCING NEW TABLE AS NT FOR EACH STATEMENT\n",
      "                        UPDATE SPLICE.H2O_W2V --splice-properties useSpark=False \n",
      "SET (word_C0,word_C1,word_C2,word_C3,word_C4,word_C5,word_C6,word_C7,word_C8,word_C9,word_C10,word_C11,word_C12,word_C13,word_C14) = (SELECT b.word_C0,b.word_C1,b.word_C2,b.word_C3,b.word_C4,b.word_C5,b.word_C6,b.word_C7,b.word_C8,b.word_C9,b.word_C10,b.word_C11,b.word_C12,b.word_C13,b.word_C14 FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', '04b9877ef43b',\n",
      "        new \"com.splicemachine.derby.catalog.TriggerNewTransitionRows\"(),'SPLICE', \n",
      "        'H2O_W2V', 'NULL', 'NULL', \n",
      "        cast(-1 as float), 'word', 'WORD_C0,WORD_C1,WORD_C2,WORD_C3,WORD_C4,WORD_C5,WORD_C6,WORD_C7,WORD_C8,WORD_C9,WORD_C10,WORD_C11,WORD_C12,WORD_C13,WORD_C14', 10000)\n",
      "         as b (cur_user VARCHAR(50),eval_time TIMESTAMP,run_id VARCHAR(50),word VARCHAR(20000),moment_key INTEGER,word_c0 FLOAT,word_c1 FLOAT,word_c2 FLOAT,word_c3 FLOAT,word_c4 FLOAT,word_c5 FLOAT,word_c6 FLOAT,word_c7 FLOAT,word_c8 FLOAT,word_c9 FLOAT,word_c10 FLOAT,word_c11 FLOAT,word_c12 FLOAT,word_c13 FLOAT,word_c14 FLOAT) --splice-properties useSpark=False, joinStrategy = sortmerge \n",
      "WHERE SPLICE.H2O_W2V.MOMENT_KEY = b.MOMENT_KEY)\n",
      "INFO     2021-06-04 17:28:54.268 - Done with 'creating trigger' [in 766.5631771087646 ms]\n",
      "INFO     2021-06-04 17:28:54.294 - Starting 'add model to metadata table'...\n",
      "INFO     2021-06-04 17:28:54.316 - Adding Model to Metadata table\n",
      "INFO     2021-06-04 17:28:54.443 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2021-06-04 17:28:54.518 - Done executing.\n",
      "INFO     2021-06-04 17:28:54.546 - Done with 'add model to metadata table' [in 251.54829025268555 ms]\n",
      "INFO     2021-06-04 17:28:54.569 - Starting 'Managing Feature Store metadata'...\n",
      "INFO     2021-06-04 17:28:54.595 - Checking if run was created with Feature Store training set\n",
      "INFO     2021-06-04 17:28:54.631 - Done with 'Managing Feature Store metadata' [in 61.35821342468262 ms]\n",
      "INFO     2021-06-04 17:28:54.657 - Flushing\n",
      "INFO     2021-06-04 17:28:54.678 - Committing Transaction to Database\n",
      "INFO     2021-06-04 17:28:54.734 - Committed.\n",
      "INFO     2021-06-04 17:28:54.756 - Cleaning up deployment\n",
      "INFO     2021-06-04 17:28:54.817 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2021-06-04 17:28:54.848 - TASK_COMPLETEDUploading file... Done.\n",
      "Saved artifact as 04b9877ef43b_run_log.ipynb in mlflow\n",
      "Uploading file... Done.\n",
      "Saved artifact as 04b9877ef43b_run_log.html in mlflow\n",
      "Loading model 04b9877ef43b\n",
      "Downloading file model\n",
      "Done. Unpacking artifact\n",
      "Running model\n",
      "Getting results\n",
      "Comparing DB results to model results\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.word2vec import H2OWord2vecEstimator\n",
    "job_titles_path = \"https://raw.githubusercontent.com/h2oai/sparkling-water/rel-1.6/examples/smalldata/craigslistJobTitles.csv\"\n",
    "job_titles = h2o.import_file(job_titles_path, destination_frame = \"jobtitles\",\n",
    "                             col_names = [\"category\", \"jobtitle\"], col_types = [\"enum\", \"string\"], header = 1)\n",
    "STOP_WORDS = [\"ax\",\"i\",\"you\",\"edu\",\"s\",\"t\",\"m\",\"subject\",\"can\",\"lines\",\"re\",\"what\",\n",
    "               \"there\",\"all\",\"we\",\"one\",\"the\",\"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\n",
    "               \"but\",\"is\",\"in\",\"a\",\"not\",\"with\",\"as\",\"was\",\"if\",\"they\",\"are\",\"this\",\"and\",\"it\",\"have\",\n",
    "               \"from\",\"at\",\"my\",\"be\",\"by\",\"not\",\"that\",\"to\",\"from\",\"com\",\"org\",\"like\",\"likes\",\"so\"]\n",
    "\n",
    "def tokenize(sentences, stop_word = STOP_WORDS):\n",
    "    tokenized = sentences.tokenize(\"\\\\W+\")\n",
    "    tokenized_lower = tokenized.tolower()\n",
    "    tokenized_filtered = tokenized_lower[(tokenized_lower.nchar() >= 2) | (tokenized_lower.isna()),:]\n",
    "    tokenized_words = tokenized_filtered[tokenized_filtered.grep(\"[0-9]\",invert=True,output_logical=True),:]\n",
    "    tokenized_words = tokenized_words[(tokenized_words.isna()) | (~ tokenized_words.isin(STOP_WORDS)),:]\n",
    "    return tokenized_words\n",
    "\n",
    "\n",
    "words = tokenize(job_titles[\"jobtitle\"])\n",
    "words.columns = ['word']\n",
    "\n",
    "print(\"Build word2vec model\")\n",
    "model = H2OWord2vecEstimator(sent_sample_rate = 0.0, epochs = 10, vec_size=15)\n",
    "model.train(training_frame=words)\n",
    "\n",
    "\n",
    "print(\"Sanity check - find synonyms for the word 'teacher'\")\n",
    "model.find_synonyms(\"teacher\", count = 5)\n",
    "\n",
    "print('deploying w2v')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_w2v')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_w2v',mlflow.current_run_id(), df=hc.asSparkFrame(words), create_model_table=True, primary_key={'MOMENT_KEY':'INTEGER'})\n",
    "    mlflow.watch_job(jid)\n",
    "    \n",
    "print(f'Loading model {run.info.run_uuid}')\n",
    "mlflow.load_model(run.info.run_uuid)\n",
    "print('Running model')\n",
    "\n",
    "splice.execute(\"insert into h2o_w2v (word, moment_key) values('teacher', 1)\")\n",
    "splice.execute(\"insert into h2o_w2v (word, moment_key) values('teachers', 2)\")\n",
    "splice.execute(\"insert into h2o_w2v (word, moment_key) values('elementary', 3)\")\n",
    "print('Getting results')\n",
    "data = splice.df(\"select * from h2o_w2v\").toPandas()\n",
    "print('Comparing DB results to model results')\n",
    "features = h2o.H2OFrame(data[['WORD']])\n",
    "db_preds = data[['WORD_C0','WORD_C1','WORD_C2','WORD_C3','WORD_C4','WORD_C5','WORD_C6','WORD_C7','WORD_C8','WORD_C9','WORD_C10','WORD_C11','WORD_C12','WORD_C13','WORD_C14']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.transform(features,aggregate_method=None).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "#     db_p, db_c0, db_c1, db_c2, db_c3, db_c4 = db_pred[1]\n",
    "#     raw_p, raw_c0, raw_c1, raw_c2, raw_c3, raw_c4 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,14) == round(raw,14), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  reconstr_C1.SE</th><th style=\"text-align: right;\">  reconstr_C2.SE</th><th style=\"text-align: right;\">  reconstr_C3.SE</th><th style=\"text-align: right;\">  reconstr_C4.SE</th><th style=\"text-align: right;\">  reconstr_C5.SE</th><th style=\"text-align: right;\">  reconstr_C6.SE</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">      0.0593547 </td><td style=\"text-align: right;\">     0.00875459 </td><td style=\"text-align: right;\">      0.0477355 </td><td style=\"text-align: right;\">      0.0933169 </td><td style=\"text-align: right;\">     0.00361706 </td><td style=\"text-align: right;\">     3.04805e-06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">      0.131604  </td><td style=\"text-align: right;\">     0.0485755  </td><td style=\"text-align: right;\">      0.101616  </td><td style=\"text-align: right;\">      0.0259252 </td><td style=\"text-align: right;\">     0.0259555  </td><td style=\"text-align: right;\">     0.0575199  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      0.00913057</td><td style=\"text-align: right;\">     8.38834e-06</td><td style=\"text-align: right;\">      0.177314  </td><td style=\"text-align: right;\">      0.0649745 </td><td style=\"text-align: right;\">     0.0945497  </td><td style=\"text-align: right;\">     0.0310709  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      0.0599686 </td><td style=\"text-align: right;\">     0.00177825 </td><td style=\"text-align: right;\">      0.00718096</td><td style=\"text-align: right;\">      0.270593  </td><td style=\"text-align: right;\">     0.00650925 </td><td style=\"text-align: right;\">     0.00312805 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      0.0179738 </td><td style=\"text-align: right;\">     0.00337873 </td><td style=\"text-align: right;\">      0.0634103 </td><td style=\"text-align: right;\">      0.102517  </td><td style=\"text-align: right;\">     0.0947999  </td><td style=\"text-align: right;\">     0.0236578  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      0.0422885 </td><td style=\"text-align: right;\">     6.55559e-05</td><td style=\"text-align: right;\">      0.322466  </td><td style=\"text-align: right;\">      0.00214568</td><td style=\"text-align: right;\">     0.0302279  </td><td style=\"text-align: right;\">     0.0119136  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      0.0187796 </td><td style=\"text-align: right;\">     0.0109573  </td><td style=\"text-align: right;\">      0.00151358</td><td style=\"text-align: right;\">      0.0633876 </td><td style=\"text-align: right;\">     0.0867147  </td><td style=\"text-align: right;\">     0.00207403 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      0.00595111</td><td style=\"text-align: right;\">     0.0299952  </td><td style=\"text-align: right;\">      0.00264518</td><td style=\"text-align: right;\">      0.0835673 </td><td style=\"text-align: right;\">     0.104071   </td><td style=\"text-align: right;\">     0.00372481 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      0.00092647</td><td style=\"text-align: right;\">     0.00302635 </td><td style=\"text-align: right;\">      0.0556849 </td><td style=\"text-align: right;\">      0.0752193 </td><td style=\"text-align: right;\">     0.022254   </td><td style=\"text-align: right;\">     0.00675892 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">      0.00114563</td><td style=\"text-align: right;\">     0.00165328 </td><td style=\"text-align: right;\">      0.0992462 </td><td style=\"text-align: right;\">      0.0444607 </td><td style=\"text-align: right;\">     0.000335413</td><td style=\"text-align: right;\">     0.00705533 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n",
      "deploying autoencoder\n",
      "Uploading file... Done.\n",
      "Deploying model to database...\n",
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2021-06-04 17:31:49.765 - A service worker has found your request\n",
      "INFO     2021-06-04 17:31:49.811 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2021-06-04 17:31:49.859 - Handler is available\n",
      "INFO     2021-06-04 17:31:49.873 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2021-06-04 17:31:49.993 - Retrieved MLFlow Run\n",
      "INFO     2021-06-04 17:31:50.015 - Updating MLFlow Run for the UI\n",
      "INFO     2021-06-04 17:31:50.078 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2021-06-04 17:31:50.104 - Extracting Model from DB with Name: model\n",
      "INFO     2021-06-04 17:31:50.136 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2021-06-04 17:31:50.168 - Decompressing Model Artifact\n",
      "INFO     2021-06-04 17:31:50.192 - Creating raw model representation from MLModel\n",
      "INFO     2021-06-04 17:31:50.217 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2021-06-04 17:31:50.352 - Registering Raw Model Representation...\n",
      "INFO     2021-06-04 17:31:50.382 - Done.\n",
      "INFO     2021-06-04 17:31:50.406 - Adding Model Schema and DF...\n",
      "INFO     2021-06-04 17:31:50.491 - Adding Library Specific Representations...\n",
      "INFO     2021-06-04 17:31:50.517 - Adding Serialized Representation\n",
      "INFO     2021-06-04 17:31:50.621 - Updating Artifact with serialized representation\n",
      "INFO     2021-06-04 17:31:50.644 - Preparing Model Metadata for Deployment...\n",
      "INFO     2021-06-04 17:31:50.669 - Preparing H2O Model metadata for deployment\n",
      "INFO     2021-06-04 17:31:50.696 - Using sanitized labels ['C1_reconstr', 'C2_reconstr', 'C3_reconstr', 'C4_reconstr', 'C5_reconstr', 'C6_reconstr', 'MSE_reconstr'] as labels for predictions\n",
      "INFO     2021-06-04 17:31:50.733 - Adding Schema String to model metadata...\n",
      "INFO     2021-06-04 17:31:50.755 - Starting 'creating model deployment table'...\n",
      "INFO     2021-06-04 17:31:50.809 - Executing\n",
      "CREATE TABLE SPLICE.H2O_AE (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '9125a5e5e28d',\n",
      "                C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT,MOMENT_KEY INTEGER,C1_RECONSTR DOUBLE,C2_RECONSTR DOUBLE,C3_RECONSTR DOUBLE,C4_RECONSTR DOUBLE,C5_RECONSTR DOUBLE,C6_RECONSTR DOUBLE,MSE_RECONSTR DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2021-06-04 17:31:51.697 - Done with 'creating model deployment table' [in 942.5930976867676 ms]\n",
      "INFO     2021-06-04 17:31:51.724 - Starting 'creating trigger'...\n",
      "INFO     2021-06-04 17:31:51.746 - Creating VTI Prediction Trigger...\n",
      "INFO     2021-06-04 17:31:51.842 - Executing\n",
      "CREATE TRIGGER SPLICE.runModel_H2O_AE_9125a5e5e28d \n",
      "                        AFTER INSERT ON SPLICE.H2O_AE REFERENCING NEW TABLE AS NT FOR EACH STATEMENT\n",
      "                        UPDATE SPLICE.H2O_AE --splice-properties useSpark=False \n",
      "SET (C1_reconstr,C2_reconstr,C3_reconstr,C4_reconstr,C5_reconstr,C6_reconstr,MSE_reconstr) = (SELECT b.C1_reconstr,b.C2_reconstr,b.C3_reconstr,b.C4_reconstr,b.C5_reconstr,b.C6_reconstr,b.MSE_reconstr FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', '9125a5e5e28d',\n",
      "        new \"com.splicemachine.derby.catalog.TriggerNewTransitionRows\"(),'SPLICE', \n",
      "        'H2O_AE', 'NULL', 'NULL', \n",
      "        cast(-1 as float), 'C1,C2,C3,C4,C5,C6', 'C1_RECONSTR,C2_RECONSTR,C3_RECONSTR,C4_RECONSTR,C5_RECONSTR,C6_RECONSTR,MSE_RECONSTR', 10000)\n",
      "         as b (cur_user VARCHAR(50),eval_time TIMESTAMP,run_id VARCHAR(50),c1 FLOAT,c2 FLOAT,c3 FLOAT,c4 FLOAT,c5 FLOAT,c6 FLOAT,moment_key INTEGER,c1_reconstr FLOAT,c2_reconstr FLOAT,c3_reconstr FLOAT,c4_reconstr FLOAT,c5_reconstr FLOAT,c6_reconstr FLOAT,mse_reconstr FLOAT) --splice-properties useSpark=False, joinStrategy = sortmerge \n",
      "WHERE SPLICE.H2O_AE.MOMENT_KEY = b.MOMENT_KEY)\n",
      "INFO     2021-06-04 17:31:52.430 - Done with 'creating trigger' [in 706.7041397094727 ms]\n",
      "INFO     2021-06-04 17:31:52.456 - Starting 'add model to metadata table'...\n",
      "INFO     2021-06-04 17:31:52.482 - Adding Model to Metadata table\n",
      "INFO     2021-06-04 17:31:52.618 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2021-06-04 17:31:52.695 - Done executing.\n",
      "INFO     2021-06-04 17:31:52.722 - Done with 'add model to metadata table' [in 265.6857967376709 ms]\n",
      "INFO     2021-06-04 17:31:52.746 - Starting 'Managing Feature Store metadata'...\n",
      "INFO     2021-06-04 17:31:52.771 - Checking if run was created with Feature Store training set\n",
      "INFO     2021-06-04 17:31:52.808 - Done with 'Managing Feature Store metadata' [in 62.091827392578125 ms]\n",
      "INFO     2021-06-04 17:31:52.835 - Flushing\n",
      "INFO     2021-06-04 17:31:52.857 - Committing Transaction to Database\n",
      "INFO     2021-06-04 17:31:52.918 - Committed.\n",
      "INFO     2021-06-04 17:31:52.940 - Cleaning up deployment\n",
      "INFO     2021-06-04 17:31:53.004 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2021-06-04 17:31:53.032 - TASK_COMPLETEDUploading file... Done.\n",
      "Saved artifact as 9125a5e5e28d_run_log.ipynb in mlflow\n",
      "Uploading file... Done.\n",
      "Saved artifact as 9125a5e5e28d_run_log.html in mlflow\n",
      "Loading model 9125a5e5e28d\n",
      "Downloading file model\n",
      "Done. Unpacking artifact\n",
      "Running model\n",
      "Getting results\n",
      "Comparing DB results to model results\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
    "# train = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/bigdata/laptop/mnist/train.csv.gz\")\n",
    "# test = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/bigdata/laptop/mnist/test.csv.gz\")\n",
    "\n",
    "import random\n",
    "train = []\n",
    "test = []\n",
    "for i in range(60000):\n",
    "    train.append([random.random()*4 for i in range(6)])\n",
    "    test.append([random.random()*4 for i in range(6)])\n",
    "\n",
    "train = h2o.H2OFrame(train)\n",
    "test = h2o.H2OFrame(test)\n",
    "predictors = [f'C{i}' for i in range(1,7)]\n",
    "\n",
    "\n",
    "model = H2OAutoEncoderEstimator(activation=\"Tanh\",\n",
    "                                   hidden=[2],\n",
    "                                   l1=1e-5,\n",
    "                                   ignore_const_cols=False,\n",
    "                                   epochs=1)\n",
    "model.train(x=predictors,training_frame=train)\n",
    "test_rec_error = model.anomaly(test)\n",
    "test_rec_error\n",
    "test_rec_error_features = model.anomaly(test, per_feature=True)\n",
    "print(test_rec_error_features)\n",
    "model.predict(test)\n",
    "\n",
    "print('deploying autoencoder')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_ae')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_ae',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key={'MOMENT_KEY':'INTEGER'})\n",
    "    mlflow.watch_job(jid)\n",
    "    \n",
    "print(f'Loading model {run.info.run_uuid}')\n",
    "mlflow.load_model(run.info.run_uuid)\n",
    "\n",
    "print('Running model')\n",
    "splice.execute(\"insert into h2o_ae (moment_key,c1,c2,c3,c4,c5,c6) values(1,0, 0, 0, 0, 0, 0)\")\n",
    "splice.execute(\"insert into h2o_ae (moment_key,c1,c2,c3,c4,c5,c6) values(2,1, 1, 1, 1, 1, 1)\")\n",
    "splice.execute(\"insert into h2o_ae (moment_key,c1,c2,c3,c4,c5,c6) values(3,0.25, 0.99, 0.623, 0.21, 0.52, 0.66)\")\n",
    "\n",
    "print('Getting results')\n",
    "data = splice.df(\"select * from h2o_ae\").toPandas()\n",
    "\n",
    "print('Comparing DB results to model results')\n",
    "features = h2o.H2OFrame(data[['C1','C2','C3','C4','C5','C6']])\n",
    "db_preds = data[['C1_RECONSTR','C2_RECONSTR','C3_RECONSTR','C4_RECONSTR','C5_RECONSTR','C6_RECONSTR']]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "# Check the MSE score\n",
    "raw_mses = model.anomaly(features).as_data_frame(use_pandas=True)\n",
    "db_mses = data[['MSE_RECONSTR']]\n",
    "for db_mse, raw_mse in zip(db_mses.iterrows(), raw_mses.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "    \n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "kmeans Model Build progress: |████████████████████████████████████████████| 100%\n",
      "deploying clustering\n",
      "Uploading file... Done.\n",
      "Deploying model to database...\n",
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2021-06-04 17:33:43.067 - A service worker has found your request\n",
      "INFO     2021-06-04 17:33:43.110 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2021-06-04 17:33:43.158 - Handler is available\n",
      "INFO     2021-06-04 17:33:43.175 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2021-06-04 17:33:43.279 - Retrieved MLFlow Run\n",
      "INFO     2021-06-04 17:33:43.298 - Updating MLFlow Run for the UI\n",
      "INFO     2021-06-04 17:33:43.359 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2021-06-04 17:33:43.385 - Extracting Model from DB with Name: model\n",
      "INFO     2021-06-04 17:33:43.419 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2021-06-04 17:33:43.451 - Decompressing Model Artifact\n",
      "INFO     2021-06-04 17:33:43.475 - Creating raw model representation from MLModel\n",
      "INFO     2021-06-04 17:33:43.499 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2021-06-04 17:33:43.578 - Registering Raw Model Representation...\n",
      "INFO     2021-06-04 17:33:43.602 - Done.\n",
      "INFO     2021-06-04 17:33:43.622 - Adding Model Schema and DF...\n",
      "INFO     2021-06-04 17:33:43.695 - Adding Library Specific Representations...\n",
      "INFO     2021-06-04 17:33:43.717 - Adding Serialized Representation\n",
      "INFO     2021-06-04 17:33:43.775 - Updating Artifact with serialized representation\n",
      "INFO     2021-06-04 17:33:43.796 - Preparing Model Metadata for Deployment...\n",
      "INFO     2021-06-04 17:33:43.822 - Preparing H2O Model metadata for deployment\n",
      "INFO     2021-06-04 17:33:43.857 - Adding Schema String to model metadata...\n",
      "INFO     2021-06-04 17:33:43.880 - Starting 'creating model deployment table'...\n",
      "INFO     2021-06-04 17:33:43.926 - Executing\n",
      "CREATE TABLE SPLICE.H2O_CLUSTER (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '4ea23ef04c6a',\n",
      "                C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT,MOMENT_KEY INTEGER,PREDICTION INT,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2021-06-04 17:33:44.793 - Done with 'creating model deployment table' [in 913.1214618682861 ms]\n",
      "INFO     2021-06-04 17:33:44.816 - Starting 'creating trigger'...\n",
      "INFO     2021-06-04 17:33:44.840 - Creating VTI Prediction Trigger...\n",
      "INFO     2021-06-04 17:33:44.922 - Executing\n",
      "CREATE TRIGGER SPLICE.runModel_H2O_CLUSTER_4ea23ef04c6a \n",
      "                        AFTER INSERT ON SPLICE.H2O_CLUSTER REFERENCING NEW TABLE AS NT FOR EACH STATEMENT\n",
      "                        UPDATE SPLICE.H2O_CLUSTER --splice-properties useSpark=False \n",
      "SET (PREDICTION) = (SELECT b.PREDICTION FROM new \"com.splicemachine.mlrunner.MLRunner\"('cluster', '4ea23ef04c6a',\n",
      "        new \"com.splicemachine.derby.catalog.TriggerNewTransitionRows\"(),'SPLICE', \n",
      "        'H2O_CLUSTER', 'NULL', 'NULL', \n",
      "        cast(-1 as float), 'C1,C2,C3,C4,C5,C6', '', 10000)\n",
      "         as b (cur_user VARCHAR(50),eval_time TIMESTAMP,run_id VARCHAR(50),c1 FLOAT,c2 FLOAT,c3 FLOAT,c4 FLOAT,c5 FLOAT,c6 FLOAT,moment_key INTEGER,prediction INTEGER) --splice-properties useSpark=False, joinStrategy = sortmerge \n",
      "WHERE SPLICE.H2O_CLUSTER.MOMENT_KEY = b.MOMENT_KEY)\n",
      "INFO     2021-06-04 17:33:45.415 - Done with 'creating trigger' [in 599.036693572998 ms]\n",
      "INFO     2021-06-04 17:33:45.438 - Starting 'add model to metadata table'...\n",
      "INFO     2021-06-04 17:33:45.463 - Adding Model to Metadata table\n",
      "INFO     2021-06-04 17:33:45.589 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2021-06-04 17:33:45.669 - Done executing.\n",
      "INFO     2021-06-04 17:33:45.688 - Done with 'add model to metadata table' [in 250.1242160797119 ms]\n",
      "INFO     2021-06-04 17:33:45.713 - Starting 'Managing Feature Store metadata'...\n",
      "INFO     2021-06-04 17:33:45.734 - Checking if run was created with Feature Store training set\n",
      "INFO     2021-06-04 17:33:45.775 - Done with 'Managing Feature Store metadata' [in 61.705827713012695 ms]\n",
      "INFO     2021-06-04 17:33:45.797 - Flushing\n",
      "INFO     2021-06-04 17:33:45.823 - Committing Transaction to Database\n",
      "INFO     2021-06-04 17:33:45.876 - Committed.\n",
      "INFO     2021-06-04 17:33:45.901 - Cleaning up deployment\n",
      "INFO     2021-06-04 17:33:45.958 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2021-06-04 17:33:45.994 - TASK_COMPLETEDUploading file... Done.\n",
      "Saved artifact as 4ea23ef04c6a_run_log.ipynb in mlflow\n",
      "Uploading file... Done.\n",
      "Saved artifact as 4ea23ef04c6a_run_log.html in mlflow\n",
      "Loading model 4ea23ef04c6a\n",
      "Downloading file model\n",
      "Done. Unpacking artifact\n",
      "Running model\n",
      "Getting results\n",
      "Comparing DB results to model results\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "kmeans prediction progress: |█████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.kmeans import H2OKMeansEstimator\n",
    "import random\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "for i in range(60000):\n",
    "    train.append([random.random()*4 for i in range(6)])\n",
    "    test.append([random.random()*4 for i in range(6)])\n",
    "\n",
    "train = h2o.H2OFrame(train)\n",
    "test = h2o.H2OFrame(test)\n",
    "predictors = [f'C{i}' for i in range(1,7)]\n",
    "\n",
    "\n",
    "model = H2OKMeansEstimator(k=3, nfolds=3)\n",
    "model.train(x=list(range(4)), training_frame=train)\n",
    "\n",
    "\n",
    "print('deploying clustering')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_cluster')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_cluster',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key={'MOMENT_KEY':'INTEGER'})\n",
    "    mlflow.watch_job(jid)\n",
    "    \n",
    "print(f'Loading model {run.info.run_uuid}')\n",
    "mlflow.load_model(run.info.run_uuid)\n",
    "\n",
    "print('Running model')\n",
    "splice.execute(\"insert into h2o_cluster (moment_key,c1,c2,c3,c4,c5,c6) values(1,0, 0, 0, 0, 0, 0)\")\n",
    "splice.execute(\"insert into h2o_cluster (moment_key,c1,c2,c3,c4,c5,c6) values(2,0.258682,2.03961,3.13087,2.71747,2.46077,0.24339)\")\n",
    "splice.execute(\"insert into h2o_cluster (moment_key,c1,c2,c3,c4,c5,c6) values(3,0.25, 0.99, 0.623, 0.21, 0.52, 0.66)\")\n",
    "\n",
    "print('Getting results')\n",
    "data = splice.df(\"select * from h2o_cluster\").toPandas()\n",
    "\n",
    "print('Comparing DB results to model results')\n",
    "features = h2o.H2OFrame(data[['C1','C2','C3','C4','C5','C6']])\n",
    "db_preds = data[['PREDICTION']]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "    \n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "pca Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_train: PCA Power method failed to converge within TOLERANCE.  Increase max_iterations or reduce TOLERANCE to mitigate this problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploying pca\n",
      "Uploading file... Done.\n",
      "Deploying model to database...\n",
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2021-06-04 20:38:40.439 - A service worker has found your request\n",
      "INFO     2021-06-04 20:38:40.504 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2021-06-04 20:38:40.569 - Handler is available\n",
      "INFO     2021-06-04 20:38:40.585 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2021-06-04 20:38:40.679 - Retrieved MLFlow Run\n",
      "INFO     2021-06-04 20:38:40.702 - Updating MLFlow Run for the UI\n",
      "INFO     2021-06-04 20:38:40.763 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2021-06-04 20:38:40.787 - Extracting Model from DB with Name: model\n",
      "INFO     2021-06-04 20:38:40.819 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2021-06-04 20:38:40.850 - Decompressing Model Artifact\n",
      "INFO     2021-06-04 20:38:40.877 - Creating raw model representation from MLModel\n",
      "INFO     2021-06-04 20:38:40.898 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2021-06-04 20:38:41.103 - Registering Raw Model Representation...\n",
      "INFO     2021-06-04 20:38:41.126 - Done.\n",
      "INFO     2021-06-04 20:38:41.148 - Adding Model Schema and DF...\n",
      "INFO     2021-06-04 20:38:41.269 - Adding Library Specific Representations...\n",
      "INFO     2021-06-04 20:38:41.292 - Adding Serialized Representation\n",
      "INFO     2021-06-04 20:38:41.397 - Updating Artifact with serialized representation\n",
      "INFO     2021-06-04 20:38:41.420 - Preparing Model Metadata for Deployment...\n",
      "INFO     2021-06-04 20:38:41.440 - Preparing H2O Model metadata for deployment\n",
      "INFO     2021-06-04 20:38:41.464 - Using sanitized labels ['PC0', 'PC1', 'PC2', 'PC3'] as labels for predictions\n",
      "INFO     2021-06-04 20:38:41.499 - Adding Schema String to model metadata...\n",
      "INFO     2021-06-04 20:38:41.520 - Starting 'creating model deployment table'...\n",
      "INFO     2021-06-04 20:38:41.609 - Executing\n",
      "CREATE TABLE SPLICE.H2O_PCA (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT 'fe387a59862d',\n",
      "                C1 FLOAT, C2 FLOAT, C3 FLOAT, C4 FLOAT, C5 FLOAT, C6 FLOAT,MOMENT_KEY INTEGER,PC0 DOUBLE,PC1 DOUBLE,PC2 DOUBLE,PC3 DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2021-06-04 20:38:42.508 - Done with 'creating model deployment table' [in 987.5888824462891 ms]\n",
      "INFO     2021-06-04 20:38:42.529 - Starting 'creating trigger'...\n",
      "INFO     2021-06-04 20:38:42.555 - Creating VTI Prediction Trigger...\n",
      "INFO     2021-06-04 20:38:42.636 - Executing\n",
      "CREATE TRIGGER SPLICE.runModel_H2O_PCA_fe387a59862d \n",
      "                        AFTER INSERT ON SPLICE.H2O_PCA REFERENCING NEW TABLE AS NT FOR EACH STATEMENT\n",
      "                        UPDATE SPLICE.H2O_PCA --splice-properties useSpark=False \n",
      "SET (PC0,PC1,PC2,PC3) = (SELECT b.PC0,b.PC1,b.PC2,b.PC3 FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', 'fe387a59862d',\n",
      "        new \"com.splicemachine.derby.catalog.TriggerNewTransitionRows\"(),'SPLICE', \n",
      "        'H2O_PCA', 'NULL', 'NULL', \n",
      "        cast(-1 as float), 'C1,C2,C3,C4,C5,C6', 'PC0,PC1,PC2,PC3', 10000)\n",
      "         as b (cur_user VARCHAR(50),eval_time TIMESTAMP,run_id VARCHAR(50),c1 FLOAT,c2 FLOAT,c3 FLOAT,c4 FLOAT,c5 FLOAT,c6 FLOAT,moment_key INTEGER,pc0 FLOAT,pc1 FLOAT,pc2 FLOAT,pc3 FLOAT) --splice-properties useSpark=False, joinStrategy = sortmerge \n",
      "WHERE SPLICE.H2O_PCA.MOMENT_KEY = b.MOMENT_KEY)\n",
      "INFO     2021-06-04 20:38:43.055 - Done with 'creating trigger' [in 525.4108905792236 ms]\n",
      "INFO     2021-06-04 20:38:43.078 - Starting 'add model to metadata table'...\n",
      "INFO     2021-06-04 20:38:43.100 - Adding Model to Metadata table\n",
      "INFO     2021-06-04 20:38:43.228 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2021-06-04 20:38:43.328 - Done executing.\n",
      "INFO     2021-06-04 20:38:43.351 - Done with 'add model to metadata table' [in 272.37987518310547 ms]\n",
      "INFO     2021-06-04 20:38:43.372 - Starting 'Managing Feature Store metadata'...\n",
      "INFO     2021-06-04 20:38:43.393 - Checking if run was created with Feature Store training set\n",
      "INFO     2021-06-04 20:38:43.441 - Done with 'Managing Feature Store metadata' [in 69.1838264465332 ms]\n",
      "INFO     2021-06-04 20:38:43.464 - Flushing\n",
      "INFO     2021-06-04 20:38:43.486 - Committing Transaction to Database\n",
      "INFO     2021-06-04 20:38:43.536 - Committed.\n",
      "INFO     2021-06-04 20:38:43.558 - Cleaning up deployment\n",
      "INFO     2021-06-04 20:38:43.613 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2021-06-04 20:38:43.646 - TASK_COMPLETEDUploading file... Done.\n",
      "Saved artifact as fe387a59862d_run_log.ipynb in mlflow\n",
      "Uploading file... Done.\n",
      "Saved artifact as fe387a59862d_run_log.html in mlflow\n",
      "Loading model fe387a59862d\n",
      "Downloading file model\n",
      "Done. Unpacking artifact\n",
      "Running model\n",
      "Getting results\n",
      "Comparing DB results to model results\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "pca prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators import H2OPrincipalComponentAnalysisEstimator\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "for i in range(60000):\n",
    "    train.append([random.random()*4 for i in range(6)])\n",
    "    test.append([random.random()*4 for i in range(6)])\n",
    "\n",
    "train = h2o.H2OFrame(train)\n",
    "test = h2o.H2OFrame(test)\n",
    "predictors = [f'C{i}' for i in range(1,7)]\n",
    "\n",
    "model = H2OPrincipalComponentAnalysisEstimator(k = 4, transform = \"STANDARDIZE\", pca_method=\"Power\",\n",
    "                   use_all_factor_levels=True, impute_missing=True)\n",
    "model.train(x=train.names, training_frame=train)\n",
    "\n",
    "\n",
    "print('deploying pca')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_pca')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_pca',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key={'MOMENT_KEY':'INTEGER'})\n",
    "    mlflow.watch_job(jid)\n",
    "\n",
    "\n",
    "print(f'Loading model {run.info.run_uuid}')\n",
    "mlflow.load_model(run.info.run_uuid)\n",
    "\n",
    "print('Running model')\n",
    "splice.execute(\"insert into h2o_pca (moment_key,c1,c2,c3,c4,c5,c6) values(1,0, 0, 0, 0, 0, 0)\")\n",
    "splice.execute(\"insert into h2o_pca (moment_key,c1,c2,c3,c4,c5,c6) values(2,0.258682,2.03961,3.13087,2.71747,2.46077,0.24339)\")\n",
    "splice.execute(\"insert into h2o_pca (moment_key,c1,c2,c3,c4,c5,c6) values(3,0.25, 0.99, 0.623, 0.21, 0.52, 0.66)\")\n",
    "\n",
    "print('Getting results')\n",
    "data = splice.df(\"select * from h2o_pca\").toPandas()\n",
    "\n",
    "print('Comparing DB results to model results')\n",
    "features = h2o.H2OFrame(data[['C1','C2','C3','C4','C5','C6']])\n",
    "db_preds = data[['PC0','PC1','PC2','PC3']]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "    \n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "isolationforest Model Build progress: |███████████████████████████████████| 100%\n",
      "deploying isoforect\n",
      "Uploading file... Done.\n",
      "Deploying model to database...\n",
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2021-06-04 20:40:13.679 - A service worker has found your request\n",
      "INFO     2021-06-04 20:40:13.724 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2021-06-04 20:40:13.768 - Handler is available\n",
      "INFO     2021-06-04 20:40:13.784 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2021-06-04 20:40:13.893 - Retrieved MLFlow Run\n",
      "INFO     2021-06-04 20:40:13.915 - Updating MLFlow Run for the UI\n",
      "INFO     2021-06-04 20:40:13.971 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2021-06-04 20:40:13.992 - Extracting Model from DB with Name: model\n",
      "INFO     2021-06-04 20:40:14.022 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2021-06-04 20:40:14.051 - Decompressing Model Artifact\n",
      "INFO     2021-06-04 20:40:14.075 - Creating raw model representation from MLModel\n",
      "INFO     2021-06-04 20:40:14.097 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2021-06-04 20:40:14.175 - Registering Raw Model Representation...\n",
      "INFO     2021-06-04 20:40:14.197 - Done.\n",
      "INFO     2021-06-04 20:40:14.219 - Adding Model Schema and DF...\n",
      "INFO     2021-06-04 20:40:14.306 - Adding Library Specific Representations...\n",
      "INFO     2021-06-04 20:40:14.330 - Adding Serialized Representation\n",
      "INFO     2021-06-04 20:40:14.440 - Updating Artifact with serialized representation\n",
      "INFO     2021-06-04 20:40:14.463 - Preparing Model Metadata for Deployment...\n",
      "INFO     2021-06-04 20:40:14.484 - Preparing H2O Model metadata for deployment\n",
      "INFO     2021-06-04 20:40:14.506 - Using sanitized labels ['score', 'normalizedScore'] as labels for predictions\n",
      "INFO     2021-06-04 20:40:14.540 - Adding Schema String to model metadata...\n",
      "INFO     2021-06-04 20:40:14.563 - Starting 'creating model deployment table'...\n",
      "INFO     2021-06-04 20:40:14.610 - Executing\n",
      "CREATE TABLE SPLICE.H2O_ISO (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT 'fbc48baaf795',\n",
      "                DISPLACEMENT FLOAT, POWER SMALLINT, WEIGHT SMALLINT, ACCELERATION FLOAT, YEAR_MAKE TINYINT,MOMENT_KEY INTEGER,SCORE DOUBLE,NORMALIZEDSCORE DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2021-06-04 20:40:15.482 - Done with 'creating model deployment table' [in 919.1641807556152 ms]\n",
      "INFO     2021-06-04 20:40:15.503 - Starting 'creating trigger'...\n",
      "INFO     2021-06-04 20:40:15.526 - Creating VTI Prediction Trigger...\n",
      "INFO     2021-06-04 20:40:15.613 - Executing\n",
      "CREATE TRIGGER SPLICE.runModel_H2O_ISO_fbc48baaf795 \n",
      "                        AFTER INSERT ON SPLICE.H2O_ISO REFERENCING NEW TABLE AS NT FOR EACH STATEMENT\n",
      "                        UPDATE SPLICE.H2O_ISO --splice-properties useSpark=False \n",
      "SET (score,normalizedScore) = (SELECT b.score,b.normalizedScore FROM new \"com.splicemachine.mlrunner.MLRunner\"('key_value', 'fbc48baaf795',\n",
      "        new \"com.splicemachine.derby.catalog.TriggerNewTransitionRows\"(),'SPLICE', \n",
      "        'H2O_ISO', 'NULL', 'NULL', \n",
      "        cast(-1 as float), 'displacement,power,weight,acceleration,year_make', 'SCORE,NORMALIZEDSCORE', 10000)\n",
      "         as b (cur_user VARCHAR(50),eval_time TIMESTAMP,run_id VARCHAR(50),displacement FLOAT,power SMALLINT,weight SMALLINT,acceleration FLOAT,year_make SMALLINT,moment_key INTEGER,score FLOAT,normalizedscore FLOAT) --splice-properties useSpark=False, joinStrategy = sortmerge \n",
      "WHERE SPLICE.H2O_ISO.MOMENT_KEY = b.MOMENT_KEY)\n",
      "INFO     2021-06-04 20:40:15.997 - Done with 'creating trigger' [in 494.0943717956543 ms]\n",
      "INFO     2021-06-04 20:40:16.020 - Starting 'add model to metadata table'...\n",
      "INFO     2021-06-04 20:40:16.044 - Adding Model to Metadata table\n",
      "INFO     2021-06-04 20:40:16.148 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2021-06-04 20:40:16.222 - Done executing.\n",
      "INFO     2021-06-04 20:40:16.247 - Done with 'add model to metadata table' [in 227.04339027404785 ms]\n",
      "INFO     2021-06-04 20:40:16.271 - Starting 'Managing Feature Store metadata'...\n",
      "INFO     2021-06-04 20:40:16.296 - Checking if run was created with Feature Store training set\n",
      "INFO     2021-06-04 20:40:16.335 - Done with 'Managing Feature Store metadata' [in 63.38620185852051 ms]\n",
      "INFO     2021-06-04 20:40:16.357 - Flushing\n",
      "INFO     2021-06-04 20:40:16.379 - Committing Transaction to Database\n",
      "INFO     2021-06-04 20:40:16.429 - Committed.\n",
      "INFO     2021-06-04 20:40:16.452 - Cleaning up deployment\n",
      "INFO     2021-06-04 20:40:16.506 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2021-06-04 20:40:16.539 - TASK_COMPLETEDUploading file... Done.\n",
      "Saved artifact as fbc48baaf795_run_log.ipynb in mlflow\n",
      "Uploading file... Done.\n",
      "Saved artifact as fbc48baaf795_run_log.html in mlflow\n",
      "Loading model fbc48baaf795\n",
      "Downloading file model\n",
      "Done. Unpacking artifact\n",
      "Running model\n",
      "Getting results\n",
      "Comparing DB results to model results\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "isolationforest prediction progress: |████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "model = H2OIsolationForestEstimator(seed=1234,score_each_iteration=True,score_tree_interval=5)\n",
    "model.train(x=predictors,\n",
    "              training_frame=cars)\n",
    "model.model_performance()\n",
    "\n",
    "\n",
    "print('deploying isoforect')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_iso')\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_iso',mlflow.current_run_id(), df=hc.asSparkFrame(cars).select(predictors), create_model_table=True, primary_key={'MOMENT_KEY':'INTEGER'})\n",
    "    mlflow.watch_job(jid)\n",
    "    \n",
    "print(f'Loading model {run.info.run_uuid}')\n",
    "mlflow.load_model(run.info.run_uuid)\n",
    "\n",
    "print('Running model')\n",
    "splice.execute(\"insert into h2o_iso (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 )\")\n",
    "splice.execute(\"insert into h2o_iso (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2)\")\n",
    "\n",
    "print('Getting results')\n",
    "data = splice.df(\"select displacement,power,weight,acceleration,year_make, normalizedScore,score from h2o_iso\").toPandas()\n",
    "\n",
    "print('Comparing DB results to model results')\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['NORMALIZEDSCORE','SCORE']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deploying neural network\n",
      "Table exists. Dropping table\n",
      "Uploading file... Done.\n",
      "Deploying model to database...\n",
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2021-06-04 20:43:40.713 - A service worker has found your request\n",
      "INFO     2021-06-04 20:43:40.757 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2021-06-04 20:43:40.801 - Handler is available\n",
      "INFO     2021-06-04 20:43:40.816 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2021-06-04 20:43:40.903 - Retrieved MLFlow Run\n",
      "INFO     2021-06-04 20:43:40.923 - Updating MLFlow Run for the UI\n",
      "INFO     2021-06-04 20:43:40.977 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2021-06-04 20:43:40.999 - Extracting Model from DB with Name: model\n",
      "INFO     2021-06-04 20:43:41.031 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2021-06-04 20:43:41.065 - Decompressing Model Artifact\n",
      "INFO     2021-06-04 20:43:41.094 - Creating raw model representation from MLModel\n",
      "INFO     2021-06-04 20:43:41.116 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2021-06-04 20:43:41.182 - Registering Raw Model Representation...\n",
      "INFO     2021-06-04 20:43:41.207 - Done.\n",
      "INFO     2021-06-04 20:43:41.230 - Adding Model Schema and DF...\n",
      "INFO     2021-06-04 20:43:41.384 - Adding Library Specific Representations...\n",
      "INFO     2021-06-04 20:43:41.408 - Adding Serialized Representation\n",
      "INFO     2021-06-04 20:43:41.531 - Updating Artifact with serialized representation\n",
      "INFO     2021-06-04 20:43:41.554 - Preparing Model Metadata for Deployment...\n",
      "INFO     2021-06-04 20:43:41.576 - Preparing H2O Model metadata for deployment\n",
      "INFO     2021-06-04 20:43:41.604 - Using sanitized labels ['C3', 'C4', 'C5', 'C6', 'C8'] as labels for predictions\n",
      "INFO     2021-06-04 20:43:41.640 - Adding Schema String to model metadata...\n",
      "INFO     2021-06-04 20:43:41.661 - Starting 'creating model deployment table'...\n",
      "INFO     2021-06-04 20:43:41.709 - Executing\n",
      "CREATE TABLE SPLICE.H2O_NN (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '66e314efe9de',\n",
      "                DISPLACEMENT SMALLINT, POWER SMALLINT, WEIGHT SMALLINT, ACCELERATION FLOAT, YEAR_MAKE TINYINT,MOMENT_KEY INTEGER,PREDICTION VARCHAR(5000),C3 DOUBLE,C4 DOUBLE,C5 DOUBLE,C6 DOUBLE,C8 DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2021-06-04 20:43:43.067 - Done with 'creating model deployment table' [in 1405.625343322754 ms]\n",
      "INFO     2021-06-04 20:43:43.089 - Starting 'creating trigger'...\n",
      "INFO     2021-06-04 20:43:43.111 - Creating VTI Prediction Trigger...\n",
      "INFO     2021-06-04 20:43:43.186 - Executing\n",
      "CREATE TRIGGER SPLICE.runModel_H2O_NN_66e314efe9de \n",
      "                        AFTER INSERT ON SPLICE.H2O_NN REFERENCING NEW TABLE AS NT FOR EACH STATEMENT\n",
      "                        UPDATE SPLICE.H2O_NN --splice-properties useSpark=False \n",
      "SET (PREDICTION,C3,C4,C5,C6,C8) = (SELECT b.PREDICTION,b.C3,b.C4,b.C5,b.C6,b.C8 FROM new \"com.splicemachine.mlrunner.MLRunner\"('classification', '66e314efe9de',\n",
      "        new \"com.splicemachine.derby.catalog.TriggerNewTransitionRows\"(),'SPLICE', \n",
      "        'H2O_NN', 'NULL', 'NULL', \n",
      "        cast(-1 as float), 'displacement,power,weight,acceleration,year_make', 'C3,C4,C5,C6,C8', 10000)\n",
      "         as b (cur_user VARCHAR(50),eval_time TIMESTAMP,run_id VARCHAR(50),displacement SMALLINT,power SMALLINT,weight SMALLINT,acceleration FLOAT,year_make SMALLINT,moment_key INTEGER,prediction VARCHAR(5000),c3 FLOAT,c4 FLOAT,c5 FLOAT,c6 FLOAT,c8 FLOAT) --splice-properties useSpark=False, joinStrategy = sortmerge \n",
      "WHERE SPLICE.H2O_NN.MOMENT_KEY = b.MOMENT_KEY)\n",
      "INFO     2021-06-04 20:43:43.550 - Done with 'creating trigger' [in 460.39628982543945 ms]\n",
      "INFO     2021-06-04 20:43:43.574 - Starting 'add model to metadata table'...\n",
      "INFO     2021-06-04 20:43:43.597 - Adding Model to Metadata table\n",
      "INFO     2021-06-04 20:43:43.692 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2021-06-04 20:43:43.765 - Done executing.\n",
      "INFO     2021-06-04 20:43:43.789 - Done with 'add model to metadata table' [in 214.3082618713379 ms]\n",
      "INFO     2021-06-04 20:43:43.811 - Starting 'Managing Feature Store metadata'...\n",
      "INFO     2021-06-04 20:43:43.833 - Checking if run was created with Feature Store training set\n",
      "INFO     2021-06-04 20:43:43.871 - Done with 'Managing Feature Store metadata' [in 59.303998947143555 ms]\n",
      "INFO     2021-06-04 20:43:43.892 - Flushing\n",
      "INFO     2021-06-04 20:43:43.914 - Committing Transaction to Database\n",
      "INFO     2021-06-04 20:43:43.964 - Committed.\n",
      "INFO     2021-06-04 20:43:43.995 - Cleaning up deployment\n",
      "INFO     2021-06-04 20:43:44.050 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2021-06-04 20:43:44.081 - TASK_COMPLETEDUploading file... Done.\n",
      "Saved artifact as 66e314efe9de_run_log.ipynb in mlflow\n",
      "Uploading file... Done.\n",
      "Saved artifact as 66e314efe9de_run_log.html in mlflow\n",
      "Loading model 66e314efe9de\n",
      "Downloading file model\n",
      "Done. Unpacking artifact\n",
      "Running model\n",
      "Getting results\n",
      "Comparing DB results to model results\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "cars[\"cylinders\"] = cars[\"cylinders\"].asfactor()\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response_col = \"cylinders\"\n",
    "\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "\n",
    "\n",
    "\n",
    "model = H2ODeepLearningEstimator(variable_importances=True,loss =\"Automatic\")\n",
    "\n",
    "model.train(\n",
    "    x = predictors,\n",
    "    y = response_col,\n",
    "    training_frame = train,\n",
    "    validation_frame = valid\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print('deploying neural network')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_nn')\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_nn',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key={'MOMENT_KEY':'INTEGER'})\n",
    "    mlflow.watch_job(jid)\n",
    "\n",
    "print(f'Loading model {run.info.run_uuid}')\n",
    "mlflow.load_model(run.info.run_uuid)\n",
    "\n",
    "print('Running model')\n",
    "splice.execute(\"insert into h2o_nn (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 )\")\n",
    "splice.execute(\"insert into h2o_nn (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2)\")\n",
    "\n",
    "print('Getting results')\n",
    "data = splice.df(\"select displacement,power,weight,acceleration,year_make,prediction, c3,c4,c5,c6,c8 from h2o_nn\").toPandas()\n",
    "\n",
    "print('Comparing DB results to model results')\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION','C3','C4','C5','C6','C8']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        if isinstance(db,str):\n",
    "            raw = f'C{int(raw)}'\n",
    "            assert db==raw, f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "        else:\n",
    "            assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "    \n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "xgboost Model Build progress: |███████████████████████████████████████████| 100%\n",
      "xgboost prediction progress: |████████████████████████████████████████████| 100%\n",
      "deploying xgb\n",
      "Uploading file... Done.\n",
      "Deploying model to database...\n",
      "Your Job has been submitted. The returned value of this function is the job id, which you can use to monitor the your task in real-time. Run mlflow.watch_job(<job id>) tostream them to stdout, or mlflow.fetch_logs(<job id>) to read them one time to a list\n",
      "\n",
      "---Job Logs---\n",
      "INFO     2021-06-04 20:44:35.134 - A service worker has found your request\n",
      "INFO     2021-06-04 20:44:35.222 - Checking whether handler DEPLOY_DATABASE is enabled\n",
      "INFO     2021-06-04 20:44:35.306 - Handler is available\n",
      "INFO     2021-06-04 20:44:35.322 - Retrieving Run from MLFlow Tracking Server...\n",
      "INFO     2021-06-04 20:44:35.409 - Retrieved MLFlow Run\n",
      "INFO     2021-06-04 20:44:35.431 - Updating MLFlow Run for the UI\n",
      "INFO     2021-06-04 20:44:35.525 - Reading Model Artifact Stream from Splice Machine\n",
      "INFO     2021-06-04 20:44:35.544 - Extracting Model from DB with Name: model\n",
      "INFO     2021-06-04 20:44:35.576 - Decoding Model Artifact Binary Stream for Deployment\n",
      "INFO     2021-06-04 20:44:35.603 - Decompressing Model Artifact\n",
      "INFO     2021-06-04 20:44:35.626 - Creating raw model representation from MLModel\n",
      "INFO     2021-06-04 20:44:35.647 - Reading MLModel Flavor from Extracted Archive\n",
      "INFO     2021-06-04 20:44:35.783 - Registering Raw Model Representation...\n",
      "INFO     2021-06-04 20:44:35.807 - Done.\n",
      "INFO     2021-06-04 20:44:35.829 - Adding Model Schema and DF...\n",
      "INFO     2021-06-04 20:44:35.932 - Adding Library Specific Representations...\n",
      "INFO     2021-06-04 20:44:35.958 - Adding Serialized Representation\n",
      "INFO     2021-06-04 20:44:36.078 - Updating Artifact with serialized representation\n",
      "INFO     2021-06-04 20:44:36.099 - Preparing Model Metadata for Deployment...\n",
      "INFO     2021-06-04 20:44:36.120 - Preparing H2O Model metadata for deployment\n",
      "INFO     2021-06-04 20:44:36.144 - Using sanitized labels ['C0', 'C1'] as labels for predictions\n",
      "INFO     2021-06-04 20:44:36.220 - Adding Schema String to model metadata...\n",
      "INFO     2021-06-04 20:44:36.241 - Starting 'creating model deployment table'...\n",
      "INFO     2021-06-04 20:44:36.286 - Executing\n",
      "CREATE TABLE SPLICE.H2O_XGB (\n",
      "                CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "                EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "                RUN_ID VARCHAR(50) DEFAULT '4c511ab69c35',\n",
      "                SIBSP TINYINT, SEX VARCHAR(20000), AGE FLOAT,MOMENT_KEY INTEGER,PREDICTION VARCHAR(5000),C0 DOUBLE,C1 DOUBLE,PRIMARY KEY(MOMENT_KEY))\n",
      "INFO     2021-06-04 20:44:37.118 - Done with 'creating model deployment table' [in 876.542329788208 ms]\n",
      "INFO     2021-06-04 20:44:37.138 - Starting 'creating trigger'...\n",
      "INFO     2021-06-04 20:44:37.163 - Creating VTI Prediction Trigger...\n",
      "INFO     2021-06-04 20:44:37.238 - Executing\n",
      "CREATE TRIGGER SPLICE.runModel_H2O_XGB_4c511ab69c35 \n",
      "                        AFTER INSERT ON SPLICE.H2O_XGB REFERENCING NEW TABLE AS NT FOR EACH STATEMENT\n",
      "                        UPDATE SPLICE.H2O_XGB --splice-properties useSpark=False \n",
      "SET (PREDICTION,C0,C1) = (SELECT b.PREDICTION,b.C0,b.C1 FROM new \"com.splicemachine.mlrunner.MLRunner\"('classification', '4c511ab69c35',\n",
      "        new \"com.splicemachine.derby.catalog.TriggerNewTransitionRows\"(),'SPLICE', \n",
      "        'H2O_XGB', 'NULL', 'NULL', \n",
      "        cast(-1 as float), 'sibsp,sex,age', 'C0,C1', 10000)\n",
      "         as b (cur_user VARCHAR(50),eval_time TIMESTAMP,run_id VARCHAR(50),sibsp SMALLINT,sex VARCHAR(20000),age FLOAT,moment_key INTEGER,prediction VARCHAR(5000),c0 FLOAT,c1 FLOAT) --splice-properties useSpark=False, joinStrategy = sortmerge \n",
      "WHERE SPLICE.H2O_XGB.MOMENT_KEY = b.MOMENT_KEY)\n",
      "INFO     2021-06-04 20:44:37.568 - Done with 'creating trigger' [in 429.32915687561035 ms]\n",
      "INFO     2021-06-04 20:44:37.589 - Starting 'add model to metadata table'...\n",
      "INFO     2021-06-04 20:44:37.610 - Adding Model to Metadata table\n",
      "INFO     2021-06-04 20:44:37.722 - Executing SQL to insert Database Deployed Metadata\n",
      "INFO     2021-06-04 20:44:37.786 - Done executing.\n",
      "INFO     2021-06-04 20:44:37.807 - Done with 'add model to metadata table' [in 217.6647186279297 ms]\n",
      "INFO     2021-06-04 20:44:37.829 - Starting 'Managing Feature Store metadata'...\n",
      "INFO     2021-06-04 20:44:37.850 - Checking if run was created with Feature Store training set\n",
      "INFO     2021-06-04 20:44:37.884 - Done with 'Managing Feature Store metadata' [in 55.02796173095703 ms]\n",
      "INFO     2021-06-04 20:44:37.905 - Flushing\n",
      "INFO     2021-06-04 20:44:37.926 - Committing Transaction to Database\n",
      "INFO     2021-06-04 20:44:37.975 - Committed.\n",
      "INFO     2021-06-04 20:44:37.996 - Cleaning up deployment\n",
      "INFO     2021-06-04 20:44:38.091 - Success! Target 'DEPLOY_DATABASE' completed successfully.\n",
      "INFO     2021-06-04 20:44:38.123 - TASK_COMPLETEDUploading file... Done.\n",
      "Saved artifact as 4c511ab69c35_run_log.ipynb in mlflow\n",
      "Uploading file... Done.\n",
      "Saved artifact as 4c511ab69c35_run_log.html in mlflow\n",
      "Loading model 4c511ab69c35\n",
      "Downloading file model\n",
      "Done. Unpacking artifact\n",
      "Running model\n",
      "Getting results\n",
      "Comparing DB results to model results\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "xgboost prediction progress: |████████████████████████████████████████████| 100%\n",
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.estimators import H2OXGBoostEstimator\n",
    "\n",
    "# Import the titanic dataset into H2O:\n",
    "titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "\n",
    "# Set the predictors and response; set the response as a factor:\n",
    "titanic[\"survived\"] = titanic[\"survived\"].asfactor()\n",
    "predictors = ['sibsp', 'sex', 'age']\n",
    "response = \"survived\"\n",
    "\n",
    "# Split the dataset into a train and valid set:\n",
    "train, valid = titanic.split_frame(ratios=[.8], seed=1234)\n",
    "\n",
    "# Build and train the model:\n",
    "model = H2OXGBoostEstimator(booster='dart',\n",
    "                                  normalize_type=\"tree\",\n",
    "                                  seed=1234)\n",
    "model.train(x=predictors,\n",
    "                  y=response,\n",
    "                  training_frame=train,\n",
    "                  validation_frame=valid)\n",
    "\n",
    "# Eval performance:\n",
    "perf = model.model_performance()\n",
    "\n",
    "# Generate predictions on a test set (if necessary):\n",
    "pred = model.predict(valid)\n",
    "\n",
    "print('deploying xgb')\n",
    "splice.dropTableIfExists('splice.h2o_xgb')\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db('splice','h2o_xgb',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key={'MOMENT_KEY':'INTEGER'})\n",
    "    mlflow.watch_job(jid)\n",
    "\n",
    "print(f'Loading model {run.info.run_uuid}')\n",
    "mlflow.load_model(run.info.run_uuid)\n",
    "\n",
    "print('Running model')\n",
    "splice.execute(\"insert into splice.h2o_xgb (moment_key,sibsp,sex,age) values(0, 5,'female',2.496)\")\n",
    "splice.execute(\"insert into splice.h2o_xgb (moment_key,sibsp,sex,age) values(1, 1,'male',-7.048)\")\n",
    "\n",
    "print('Getting results')\n",
    "data = splice.df(\"select sibsp, sex, age, prediction, c0, c1 from splice.h2o_xgb\").toPandas()\n",
    "\n",
    "print('Comparing DB results to model results')\n",
    "features = h2o.H2OFrame(data[['SIBSP','SEX','AGE']])\n",
    "db_preds = data[['PREDICTION','C0','C1']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p, db_c0, db_c1 = db_pred[1]\n",
    "    raw_p, raw_c0, raw_c1 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    raw_p = f'C{int(raw_p)}'\n",
    "    \n",
    "    assert db_p == raw_p, f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    assert round(db_c0,14) == round(raw_c0,14), f'Something is wrong. Model Table gives {db_c0} but raw model gives {raw_c0}'\n",
    "    assert round(db_c1,14) == round(raw_c1,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "\n",
    "print('test passed!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP\n",
    "# ===================================== Below is Broken =====================================\n",
    "\n",
    "## GLRM (not broken but can't test), TargetEncoder (broken on deploy)\n",
    "\n",
    "### GLRM explanation https://0xdata.atlassian.net/browse/PUBDEV-7761"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "for i in range(60000):\n",
    "    train.append([random.random()*4 for i in range(6)])\n",
    "\n",
    "train = h2o.H2OFrame(train)\n",
    "predictors = [f'C{i}' for i in range(1,7)]\n",
    "\n",
    "model = H2OGeneralizedLowRankEstimator(k=6,seed=1234, impute_original=True,transform='Normalize')\n",
    "model.train(x=predictors, training_frame=train)\n",
    "\n",
    "print('deploying glrm')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_glrm')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_glrm',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.reconstruct(h2o.H2OFrame([[0,0,0,0,0,0]]))\n",
    "# dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "truncate table h2o_glrm;\n",
    "insert into h2o_glrm (moment_key,c1,c2,c3,c4,c5,c6) values(1,0, 0, 0, 0, 0, 0);\n",
    "insert into h2o_glrm (moment_key,c1,c2,c3,c4,c5,c6) values(2,0.258682,2.03961,3.13087,2.71747,2.46077,0.24339);\n",
    "insert into h2o_glrm (moment_key,c1,c2,c3,c4,c5,c6) values(3,0.25, 0.99, 0.623, 0.21, 0.52, 0.66);\n",
    "\n",
    "select * from h2o_glrm;\n",
    "select * into ${data_and_preds} from h2o_glrm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "## GLRM Can act as both autoencoders in that they reconstruct data, and also perform PCA. In the database, we always do PCA (maybe something to change later)\n",
    "## For reconstruction, you call predict. I don't know how to get components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['C1','C2','C3','C4','C5','C6']])\n",
    "db_preds = data[['PC0','PC1','PC2','PC3','PC4','PC5']]\n",
    "\n",
    "# GLRM Can act as both autoencoders in that they reconstruct data, and also perform PCA. In the database, we always do PCA (maybe something to change later)\n",
    "# To get the PCA, you call proj_archetypes, for reconstruction, you call predict\n",
    "raw_preds = model.proj_archetypes(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLRM is weird because it can act as either Dim Reduction or an Autoencoder... Which should we pick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_path = model.download_mojo('/tmp/gbm.zip')\n",
    "\n",
    "\n",
    "from py4j.java_gateway import java_import\n",
    "java_import(splice.jvm, 'hex.genmodel.easy.EasyPredictModelWrapper')\n",
    "java_import(splice.jvm, 'hex.genmodel.MojoModel')\n",
    "java_import(splice.jvm, 'java.io.ByteArrayOutputStream')\n",
    "java_import(splice.jvm, 'java.io.ObjectOutputStream') \n",
    "java_import(splice.jvm, 'hex.genmodel.easy.RowData')\n",
    "java_import(splice.jvm, 'hex.genmodel.easy.prediction.DimReductionModelPrediction')\n",
    "\n",
    "\n",
    "java_mojo_c = splice.jvm.EasyPredictModelWrapper.Config().setModel(splice.jvm.MojoModel.load(pca_path))\n",
    "java_mojo = splice.jvm.EasyPredictModelWrapper(java_mojo_c)\n",
    "\n",
    "\n",
    "\n",
    "m = splice.jvm.MojoModel.load(pca_path)\n",
    "\n",
    "# java_mojo.predictDimReduction(train)\n",
    "\n",
    "\n",
    "print(java_mojo.getModelCategory().toString())\n",
    "\n",
    "\n",
    "row = splice.jvm.RowData()\n",
    "row.put(\"C1\", \"0\")\n",
    "row.put(\"C2\", \"0\")\n",
    "row.put(\"C3\", \"0\")\n",
    "row.put(\"C4\", \"0\")\n",
    "row.put(\"C5\", \"0\")\n",
    "row.put(\"C6\", \"0\")\n",
    "\n",
    "d = splice.jvm.DimReductionModelPrediction\n",
    "\n",
    "# pred = m.predictDimReduction(row)\n",
    "\n",
    "# list(java_mojo.predictDimReduction(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splicemachine.notebook import hide_toggle\n",
    "hide_toggle(toggle_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java\n",
    "%classpath add jar db-client-3.0.0.1950.jar\n",
    "%classpath add jar /home/jovyan/nn_model.jar\n",
    "import java.sql.*; \n",
    "import java.util.*; \n",
    "import hex.genmodel.easy.RowData;\n",
    "import hex.genmodel.easy.EasyPredictModelWrapper;\n",
    "import hex.genmodel.easy.prediction.*;\n",
    "import java.io.*;\n",
    "import hex.genmodel.MojoModel;\n",
    "import hex.genmodel.InMemoryMojoReaderBackend;\n",
    "import java.sql.Driver;  \n",
    "import com.splicemachine.db.jdbc.*;\n",
    "\n",
    "\n",
    "Driver d = new com.splicemachine.db.jdbc.ClientDriver();  \n",
    "DriverManager.registerDriver(d);\n",
    "Connection conn = DriverManager.getConnection(\"jdbc:splice://jdbc-test-aks-dev1.dev.splicemachine-dev.io:1527/splicedb;ssl=basic\",\"splice\",\"admin\");\n",
    "PreparedStatement pstmt = conn.prepareStatement(\"select \\\"binary\\\" from mlmanager.artifacts where RUN_UUID=? and NAME=?\");\n",
    "        pstmt.setString(1, \"6ba390856894\");\n",
    "        pstmt.setString(2,\"h2omojo\");\n",
    "        ResultSet rs = pstmt.executeQuery();\n",
    "        EasyPredictModelWrapper model = null;\n",
    "        if(rs.next()) {\n",
    "            Blob blobModel = rs.getBlob(1);\n",
    "            InputStream bis = blobModel.getBinaryStream();\n",
    "            ObjectInputStream ois = new ObjectInputStream(bis);\n",
    "            model = (EasyPredictModelWrapper) (ois.readObject());\n",
    "            ois.close();\n",
    "        }\n",
    "\n",
    "        \n",
    "\n",
    "RowData row = new RowData();\n",
    "\n",
    "row.put(\"SDSS_J\", \"000009.26+151754.5\");\n",
    "row.put(\"R.A.\", \"9.08519705868309\");\n",
    "row.put(\"Dec.\", \"4.932083187033184\");\n",
    "row.put(\"z\", \"7.139249327431729\");\n",
    "row.put(\"u_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_u\", \"7.139249327431729\");\n",
    "row.put(\"g_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_g\", \"7.139249327431729\");\n",
    "row.put(\"r_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_r\", \"7.139249327431729\");\n",
    "row.put(\"i_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_i\", \"7.139249327431729\");\n",
    "row.put(\"z_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_z\", \"7.139249327431729\");\n",
    "row.put(\"Radio\", \"7.139249327431729\");\n",
    "row.put(\"X-ray\", \"7.139249327431729\");\n",
    "row.put(\"J_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_J\", \"7.139249327431729\");\n",
    "row.put(\"H_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_H\", \"7.139249327431729\");\n",
    "row.put(\"K_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_K\", \"7.139249327431729\");\n",
    "row.put(\"M_i\", \"7.139249327431729\");\n",
    "\n",
    "\n",
    "AbstractPrediction p;\n",
    "p = model.predictDimReduction(row);\n",
    "\n",
    "final StringBuilder builder = new StringBuilder();\n",
    "//for(int i = 0; i < classProbs.length; i++){\n",
    "//    builder.append(i).append(\"=\").append(classProbs[i]).append(\";\");\n",
    "//}\n",
    "//return builder.substring(0, builder.length() - 1);\n",
    "//return c;\n",
    "\n",
    "final double[] dim = ((DimReductionModelPrediction) p).dimensions;\n",
    "//AutoEncoderModelPrediction\n",
    "\n",
    "\n",
    "//for(int i = 0; i < dim.length; i++){\n",
    "//    builder.append(\"PC\" + i).append(\"=\").append(Double.toString(dim[i])).append(\";\");\n",
    "//}\n",
    "\n",
    "return dim;\n",
    "//return builder.substring(0, builder.length() - 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TargetEncoder (BROKEN on Deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "titanic.rename(columns={'home.dest':'home_dest'})\n",
    "predictors = [\"home_dest\", \"cabin\", \"embarked\"]\n",
    "response = \"survived\"\n",
    "titanic[\"survived\"] = titanic[\"survived\"].asfactor()\n",
    "fold_col = \"kfold_column\"\n",
    "titanic[fold_col] = titanic.kfold_column(n_folds=5, seed=1234)\n",
    "model = H2OTargetEncoderEstimator(k=35,\n",
    "                                       f=25,\n",
    "                                       blending=True)\n",
    "model.train(x=predictors,\n",
    "                 y=response,\n",
    "                 training_frame=titanic)\n",
    "\n",
    "\n",
    "print('deploying target encoder')\n",
    "splice.dropTableIfExists('splice.te')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db('splice','te',mlflow.current_run_id(), df=hc.asSparkFrame(titanic).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.download_mojo(f'./h2o_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
