{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from h2o.estimators import *\n",
    "from pysparkling import *\n",
    "import h2o\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "spark = SparkSession.builder.config('spark.dynamicAllocation.enabled','false').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create H2O Sparkling Water cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf = H2OConf().setInternalClusterMode()\n",
    "hc = H2OContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splicemachine.spark.context import PySpliceContext\n",
    "splice = PySpliceContext(spark)\n",
    "from splicemachine.mlflow_support import *\n",
    "from splicemachine.mlflow_support.utilities import get_user\n",
    "mlflow.register_splice_context(splice)\n",
    "mlflow.set_experiment('h2o deployment')\n",
    "schema = get_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "\n",
    "\n",
    "# Import the titanic dataset into H2O:\n",
    "titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "\n",
    "# Set the predictors and response; set the response as a factor:\n",
    "titanic[\"survived\"] = titanic[\"survived\"].asfactor()\n",
    "predictors = ['sibsp', 'sex', 'age']\n",
    "response = \"survived\"\n",
    "\n",
    "# Split the dataset into a train and valid set:\n",
    "train, valid = titanic.split_frame(ratios=[.8], seed=1234)\n",
    "\n",
    "\n",
    "model = H2OGradientBoostingEstimator(ntrees         =50,\n",
    "                                        max_depth      =6,\n",
    "                                        learn_rate     =0.1, \n",
    "                                        nfolds         =2)\n",
    "\n",
    "model.train(x               =predictors,\n",
    "               y               =response,\n",
    "               training_frame  =train,\n",
    "               validation_frame=valid\n",
    "               )\n",
    "\n",
    "\n",
    "print('deploying gbm')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_gbm')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_gbm',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlflow.load_model('9edc0c29a5bb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_id='39078bdc5593'\n",
    "# name=mlflow.client.get_run('39078bdc5593').data.tags.get('splice.model_name')\n",
    "# from splicemachine.mlflow_support.mlflow_support import SparkUtils\n",
    "# model_blob, _ = SparkUtils.retrieve_artifact_stream(mlflow._splice_context, run_id, name)\n",
    "# from io import BytesIO\n",
    "# buffer = BytesIO()\n",
    "# buffer.seek(0)\n",
    "# buffer.write(model_blob)\n",
    "# from zipfile import ZipFile\n",
    "# !mkdir my_model\n",
    "# ZipFile(buffer).extractall(path='my_model')\n",
    "# import h2o\n",
    "# model = h2o.upload_model('/home/jovyan/splice_notebooks/my_model/model.h2o/GBM_model_python_1613416470383_1241')\n",
    "# type(model)\n",
    "# import yaml\n",
    "# import os\n",
    "# path = os.path.abspath('my_model/model.h2o')\n",
    "# print(path)\n",
    "# with open(os.path.join(path,'h2o.yaml')) as f:\n",
    "#     params = yaml.safe_load(f.read())\n",
    "# model = h2o.upload_model(os.path.join(path,params['model_file']))\n",
    "# type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_gbm (moment_key,sibsp,sex,age) values(0, 5,'female',2.496);\n",
    "insert into h2o_gbm (moment_key,sibsp,sex,age) values(1, 1,'male',-7.048);\n",
    "select * from h2o_gbm;\n",
    "select sibsp, sex, age, prediction, c0, c1 into ${data_and_preds} from h2o_gbm;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['SIBSP','SEX','AGE']])\n",
    "db_preds = data[['PREDICTION','C0','C1']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p, db_c0, db_c1 = db_pred[1]\n",
    "    raw_p, raw_c0, raw_c1 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    raw_p = f'C{int(raw_p)}'\n",
    "    \n",
    "    assert db_p == raw_p, f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    assert round(db_c0,14) == round(raw_c0,14), f'Something is wrong. Model Table gives {db_c0} but raw model gives {raw_c0}'\n",
    "    assert round(db_c1,14) == round(raw_c1,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars[\"cylinders\"] = cars[\"cylinders\"].asfactor()\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response_col = \"cylinders\"\n",
    "distribution = \"multinomial\"\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "\n",
    "train.rename(columns={'year':'year_make'})\n",
    "\n",
    "model = H2OGradientBoostingEstimator(nfolds=3,\n",
    "                                   distribution=distribution)\n",
    "model.train(x=predictors,\n",
    "          y=response_col,\n",
    "          training_frame=train,\n",
    "          validation_frame=valid)\n",
    "\n",
    "\n",
    "\n",
    "print('deploying multinomial')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_multinomial')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_multinomial',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_multinomial (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_multinomial (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_multinomial;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make,prediction, c3,c4,c5,c6,c8 into ${data_and_preds} from h2o_multinomial;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION','C3','C4','C5','C6','C8']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p, db_c0, db_c1, db_c2, db_c3, db_c4 = db_pred[1]\n",
    "    raw_p, raw_c0, raw_c1, raw_c2, raw_c3, raw_c4 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    raw_p = f'C{int(raw_p)}'\n",
    "    \n",
    "    assert db_p == raw_p, f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    assert round(db_c0,14) == round(raw_c0,14), f'Something is wrong. Model Table gives {db_c0} but raw model gives {raw_c0}'\n",
    "    assert round(db_c1,14) == round(raw_c1,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c2,14) == round(raw_c2,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c3,14) == round(raw_c3,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c4,14) == round(raw_c4,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars[\"cylinders\"] = cars[\"cylinders\"].asfactor()\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response = \"cylinders\"\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "model = H2OGeneralizedLinearEstimator(seed=1234,\n",
    "                                         family='ordinal')\n",
    "model.train(x=predictors,\n",
    "               y=response,\n",
    "               training_frame=train,\n",
    "               validation_frame=valid)\n",
    "\n",
    "\n",
    "print('deploying ordinal')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_ordinal')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_ordinal',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_ordinal (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_ordinal (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_ordinal;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make,prediction, c3,c4,c5,c6,c8 into ${data_and_preds} from h2o_ordinal;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION','C3','C4','C5','C6','C8']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p, db_c0, db_c1, db_c2, db_c3, db_c4 = db_pred[1]\n",
    "    raw_p, raw_c0, raw_c1, raw_c2, raw_c3, raw_c4 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    raw_p = f'C{int(raw_p)}'\n",
    "    \n",
    "    assert db_p == raw_p, f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    assert round(db_c0,14) == round(raw_c0,14), f'Something is wrong. Model Table gives {db_c0} but raw model gives {raw_c0}'\n",
    "    assert round(db_c1,14) == round(raw_c1,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c2,14) == round(raw_c2,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c3,14) == round(raw_c3,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "    assert round(db_c4,14) == round(raw_c4,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response_col = \"economy\"\n",
    "distribution = \"gaussian\"\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "model = H2OGradientBoostingEstimator(nfolds=3,\n",
    "                                   distribution=distribution,\n",
    "                                   fold_assignment=\"Random\")\n",
    "model.train(x=predictors,\n",
    "          y=response_col,\n",
    "          training_frame=train,\n",
    "          validation_frame=valid)\n",
    "model.plot(timestep=\"AUTO\", metric=\"AUTO\",)\n",
    "\n",
    "\n",
    "print('deploying regression')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_regression')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_regression',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_regression (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_regression (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_regression;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make,prediction into ${data_and_preds} from h2o_regression;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p = db_pred[1]['PREDICTION']\n",
    "    raw_p = raw_pred[1]['predict']\n",
    "    \n",
    "    l = min(16, len(str(db_p)), len(str(raw_p))) -2 # -2 because of the decimal point and final value\n",
    "    assert round(db_p,l) == round(raw_p,l), f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HGLM Model example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response = \"economy\"\n",
    "distribution = \"gaussian\"\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "model = H2OGeneralizedLinearEstimator(alpha=.25)\n",
    "model.train(x=predictors,\n",
    "                 y=response,\n",
    "                 training_frame=train,\n",
    "                 validation_frame=valid)\n",
    "\n",
    "\n",
    "print('deploying hglm')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_hglm')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_hglm',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlflow.load_model('1a5a810832e9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_hglm (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_hglm (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_hglm;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make,prediction into ${data_and_preds} from h2o_hglm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p = db_pred[1]['PREDICTION']\n",
    "    raw_p = raw_pred[1]['predict']\n",
    "    \n",
    "    l = min(16, len(str(db_p)), len(str(raw_p))) -2\n",
    "    assert round(db_p,l) == round(raw_p,l), f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.word2vec import H2OWord2vecEstimator\n",
    "job_titles_path = \"https://raw.githubusercontent.com/h2oai/sparkling-water/rel-1.6/examples/smalldata/craigslistJobTitles.csv\"\n",
    "job_titles = h2o.import_file(job_titles_path, destination_frame = \"jobtitles\",\n",
    "                             col_names = [\"category\", \"jobtitle\"], col_types = [\"enum\", \"string\"], header = 1)\n",
    "STOP_WORDS = [\"ax\",\"i\",\"you\",\"edu\",\"s\",\"t\",\"m\",\"subject\",\"can\",\"lines\",\"re\",\"what\",\n",
    "               \"there\",\"all\",\"we\",\"one\",\"the\",\"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\n",
    "               \"but\",\"is\",\"in\",\"a\",\"not\",\"with\",\"as\",\"was\",\"if\",\"they\",\"are\",\"this\",\"and\",\"it\",\"have\",\n",
    "               \"from\",\"at\",\"my\",\"be\",\"by\",\"not\",\"that\",\"to\",\"from\",\"com\",\"org\",\"like\",\"likes\",\"so\"]\n",
    "\n",
    "def tokenize(sentences, stop_word = STOP_WORDS):\n",
    "    tokenized = sentences.tokenize(\"\\\\W+\")\n",
    "    tokenized_lower = tokenized.tolower()\n",
    "    tokenized_filtered = tokenized_lower[(tokenized_lower.nchar() >= 2) | (tokenized_lower.isna()),:]\n",
    "    tokenized_words = tokenized_filtered[tokenized_filtered.grep(\"[0-9]\",invert=True,output_logical=True),:]\n",
    "    tokenized_words = tokenized_words[(tokenized_words.isna()) | (~ tokenized_words.isin(STOP_WORDS)),:]\n",
    "    return tokenized_words\n",
    "\n",
    "\n",
    "words = tokenize(job_titles[\"jobtitle\"])\n",
    "words.columns = ['word']\n",
    "\n",
    "print(\"Build word2vec model\")\n",
    "model = H2OWord2vecEstimator(sent_sample_rate = 0.0, epochs = 10, vec_size=15)\n",
    "model.train(training_frame=words)\n",
    "\n",
    "\n",
    "print(\"Sanity check - find synonyms for the word 'teacher'\")\n",
    "model.find_synonyms(\"teacher\", count = 5)\n",
    "\n",
    "print('deploying w2v')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_w2v')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_w2v',mlflow.current_run_id(), df=hc.asSparkFrame(words), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.load_model('6ca03ec2b8c3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "insert into h2o_w2v (word, moment_key) values('teacher', 1);\n",
    "insert into h2o_w2v (word, moment_key) values('teachers', 2);\n",
    "insert into h2o_w2v (word, moment_key) values('elementary', 3);\n",
    "\n",
    "select * from h2o_w2v;\n",
    "select * into ${data_and_preds} from h2o_w2v;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['WORD']])\n",
    "db_preds = data[['word_C0','word_C1','word_C2','word_C3','word_C4','word_C5','word_C6','word_C7','word_C8','word_C9','word_C10','word_C11','word_C12','word_C13','word_C14']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.transform(features,aggregate_method=None).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "#     db_p, db_c0, db_c1, db_c2, db_c3, db_c4 = db_pred[1]\n",
    "#     raw_p, raw_c0, raw_c1, raw_c2, raw_c3, raw_c4 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,14) == round(raw,14), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
    "# train = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/bigdata/laptop/mnist/train.csv.gz\")\n",
    "# test = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/bigdata/laptop/mnist/test.csv.gz\")\n",
    "\n",
    "import random\n",
    "train = []\n",
    "test = []\n",
    "for i in range(60000):\n",
    "    train.append([random.random()*4 for i in range(6)])\n",
    "    test.append([random.random()*4 for i in range(6)])\n",
    "\n",
    "train = h2o.H2OFrame(train)\n",
    "test = h2o.H2OFrame(test)\n",
    "predictors = [f'C{i}' for i in range(1,7)]\n",
    "\n",
    "\n",
    "model = H2OAutoEncoderEstimator(activation=\"Tanh\",\n",
    "                                   hidden=[2],\n",
    "                                   l1=1e-5,\n",
    "                                   ignore_const_cols=False,\n",
    "                                   epochs=1)\n",
    "model.train(x=predictors,training_frame=train)\n",
    "test_rec_error = model.anomaly(test)\n",
    "test_rec_error\n",
    "test_rec_error_features = model.anomaly(test, per_feature=True)\n",
    "print(test_rec_error_features)\n",
    "model.predict(test)\n",
    "\n",
    "print('deploying autoencoder')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_ae')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_ae',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlflow.load_model('76ef627994a7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_ae (moment_key,c1,c2,c3,c4,c5,c6) values(1,0, 0, 0, 0, 0, 0);\n",
    "insert into h2o_ae (moment_key,c1,c2,c3,c4,c5,c6) values(2,1, 1, 1, 1, 1, 1);\n",
    "insert into h2o_ae (moment_key,c1,c2,c3,c4,c5,c6) values(3,0.25, 0.99, 0.623, 0.21, 0.52, 0.66);\n",
    "\n",
    "select * from h2o_ae;\n",
    "select * into ${data_and_preds} from h2o_ae;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['C1','C2','C3','C4','C5','C6']])\n",
    "db_preds = data[['C1_reconstr','C2_reconstr','C3_reconstr','C4_reconstr','C5_reconstr','C6_reconstr']]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "# Check the MSE score\n",
    "raw_mses = model.anomaly(features).as_data_frame(use_pandas=True)\n",
    "db_mses = data[['MSE_reconstr']]\n",
    "for db_mse, raw_mse in zip(db_mses.iterrows(), raw_mses.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "    \n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.kmeans import H2OKMeansEstimator\n",
    "import random\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "for i in range(60000):\n",
    "    train.append([random.random()*4 for i in range(6)])\n",
    "    test.append([random.random()*4 for i in range(6)])\n",
    "\n",
    "train = h2o.H2OFrame(train)\n",
    "test = h2o.H2OFrame(test)\n",
    "predictors = [f'C{i}' for i in range(1,7)]\n",
    "\n",
    "\n",
    "model = H2OKMeansEstimator(k=3, nfolds=3)\n",
    "model.train(x=list(range(4)), training_frame=train)\n",
    "\n",
    "\n",
    "print('deploying clustering')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_cluster')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_cluster',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlflow.load_model('9f72150963d3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_cluster (moment_key,c1,c2,c3,c4,c5,c6) values(1,0, 0, 0, 0, 0, 0);\n",
    "insert into h2o_cluster (moment_key,c1,c2,c3,c4,c5,c6) values(2,0.258682,2.03961,3.13087,2.71747,2.46077,0.24339);\n",
    "insert into h2o_cluster (moment_key,c1,c2,c3,c4,c5,c6) values(3,0.25, 0.99, 0.623, 0.21, 0.52, 0.66);\n",
    "\n",
    "select * from h2o_cluster;\n",
    "select * into ${data_and_preds} from h2o_cluster;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['C1','C2','C3','C4','C5','C6']])\n",
    "db_preds = data[['PREDICTION']]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "    \n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators import H2OPrincipalComponentAnalysisEstimator\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "for i in range(60000):\n",
    "    train.append([random.random()*4 for i in range(6)])\n",
    "    test.append([random.random()*4 for i in range(6)])\n",
    "\n",
    "train = h2o.H2OFrame(train)\n",
    "test = h2o.H2OFrame(test)\n",
    "predictors = [f'C{i}' for i in range(1,7)]\n",
    "\n",
    "model = H2OPrincipalComponentAnalysisEstimator(k = 4, transform = \"STANDARDIZE\", pca_method=\"Power\",\n",
    "                   use_all_factor_levels=True, impute_missing=True)\n",
    "model.train(x=train.names, training_frame=train)\n",
    "\n",
    "\n",
    "print('deploying pca')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_pca')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_pca',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_pca (moment_key,c1,c2,c3,c4,c5,c6) values(1,0, 0, 0, 0, 0, 0);\n",
    "insert into h2o_pca (moment_key,c1,c2,c3,c4,c5,c6) values(2,0.258682,2.03961,3.13087,2.71747,2.46077,0.24339);\n",
    "insert into h2o_pca (moment_key,c1,c2,c3,c4,c5,c6) values(3,0.25, 0.99, 0.623, 0.21, 0.52, 0.66);\n",
    "\n",
    "select * from h2o_pca;\n",
    "select * into ${data_and_preds} from h2o_pca;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['C1','C2','C3','C4','C5','C6']])\n",
    "db_preds = data[['PC0','PC1','PC2','PC3']]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "    \n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "model = H2OIsolationForestEstimator(seed=1234,score_each_iteration=True,score_tree_interval=5)\n",
    "model.train(x=predictors,\n",
    "              training_frame=cars)\n",
    "model.model_performance()\n",
    "\n",
    "\n",
    "print('deploying isoforect')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_iso')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_iso',mlflow.current_run_id(), df=hc.asSparkFrame(cars).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_iso (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_iso (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_iso;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make, \"normalizedScore\",\"score\" into ${data_and_preds} from h2o_iso;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['normalizedScore','score']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
    "cars.rename(columns={'year':'year_make'})\n",
    "cars[\"cylinders\"] = cars[\"cylinders\"].asfactor()\n",
    "r = cars[0].runif()\n",
    "train = cars[r > .2]\n",
    "valid = cars[r <= .2]\n",
    "response_col = \"cylinders\"\n",
    "\n",
    "predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year_make\"]\n",
    "\n",
    "\n",
    "\n",
    "model = H2ODeepLearningEstimator(variable_importances=True,loss =\"Automatic\")\n",
    "\n",
    "model.train(x                =predictors,\n",
    "              y                =response_col,\n",
    "               training_frame  =train,\n",
    "              validation_frame=valid)\n",
    "\n",
    "\n",
    "\n",
    "print('deploying neural network')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_nn')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_nn',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_nn (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_nn (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_nn;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make,prediction, c3,c4,c5,c6,c8 into ${data_and_preds} from h2o_nn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['DISPLACEMENT','POWER','WEIGHT','ACCELERATION','YEAR_MAKE']])\n",
    "db_preds = data[['PREDICTION','C3','C4','C5','C6','C8']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        if isinstance(db,str):\n",
    "            raw = f'C{int(raw)}'\n",
    "            assert db==raw, f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "        else:\n",
    "            assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "    \n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.estimators import H2OXGBoostEstimator\n",
    "\n",
    "# Import the titanic dataset into H2O:\n",
    "titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "\n",
    "# Set the predictors and response; set the response as a factor:\n",
    "titanic[\"survived\"] = titanic[\"survived\"].asfactor()\n",
    "predictors = ['sibsp', 'sex', 'age']\n",
    "response = \"survived\"\n",
    "\n",
    "# Split the dataset into a train and valid set:\n",
    "train, valid = titanic.split_frame(ratios=[.8], seed=1234)\n",
    "\n",
    "# Build and train the model:\n",
    "model = H2OXGBoostEstimator(booster='dart',\n",
    "                                  normalize_type=\"tree\",\n",
    "                                  seed=1234)\n",
    "model.train(x=predictors,\n",
    "                  y=response,\n",
    "                  training_frame=train,\n",
    "                  validation_frame=valid)\n",
    "\n",
    "# Eval performance:\n",
    "perf = model.model_performance()\n",
    "\n",
    "# Generate predictions on a test set (if necessary):\n",
    "pred = model.predict(valid)\n",
    "\n",
    "print('deploying xgb')\n",
    "splice.dropTableIfExists('splice.h2o_xgb')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db('splice','h2o_xgb',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "insert into splice.h2o_xgb (moment_key,sibsp,sex,age) values(0, 5,'female',2.496);\n",
    "insert into splice.h2o_xgb (moment_key,sibsp,sex,age) values(1, 1,'male',-7.048);\n",
    "select * from h2o_xgb;\n",
    "select sibsp, sex, age, prediction, c0, c1 into ${data_and_preds} from splice.h2o_xgb;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['SIBSP','SEX','AGE']])\n",
    "db_preds = data[['PREDICTION','C0','C1']]\n",
    "features.columns = [i.lower() for i in features.columns]\n",
    "\n",
    "raw_preds = model.predict(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    db_p, db_c0, db_c1 = db_pred[1]\n",
    "    raw_p, raw_c0, raw_c1 = raw_pred[1]\n",
    "    # Table returns string but h2o returns int index\n",
    "    raw_p = f'C{int(raw_p)}'\n",
    "    \n",
    "    assert db_p == raw_p, f'Something is wrong. Model Table gives {db_p} but raw model gives {raw_p}'\n",
    "    assert round(db_c0,14) == round(raw_c0,14), f'Something is wrong. Model Table gives {db_c0} but raw model gives {raw_c0}'\n",
    "    assert round(db_c1,14) == round(raw_c1,14), f'Something is wrong. Model Table gives {db_c1} but raw model gives {raw_c1}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h2o.explain(model, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================================== Below is Broken =====================================\n",
    "\n",
    "## GLRM (not broken but can't test), TargetEncoder (broken on deploy)\n",
    "\n",
    "### GLRM explanation https://0xdata.atlassian.net/browse/PUBDEV-7761"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "for i in range(60000):\n",
    "    train.append([random.random()*4 for i in range(6)])\n",
    "\n",
    "train = h2o.H2OFrame(train)\n",
    "predictors = [f'C{i}' for i in range(1,7)]\n",
    "\n",
    "model = H2OGeneralizedLowRankEstimator(k=6,seed=1234, impute_original=True,transform='Normalize')\n",
    "model.train(x=predictors, training_frame=train)\n",
    "\n",
    "print('deploying glrm')\n",
    "splice.dropTableIfExists(f'{schema}.h2o_glrm')\n",
    "\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db(schema,'h2o_glrm',mlflow.current_run_id(), df=hc.asSparkFrame(train).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.reconstruct(h2o.H2OFrame([[0,0,0,0,0,0]]))\n",
    "# dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "truncate table h2o_glrm;\n",
    "insert into h2o_glrm (moment_key,c1,c2,c3,c4,c5,c6) values(1,0, 0, 0, 0, 0, 0);\n",
    "insert into h2o_glrm (moment_key,c1,c2,c3,c4,c5,c6) values(2,0.258682,2.03961,3.13087,2.71747,2.46077,0.24339);\n",
    "insert into h2o_glrm (moment_key,c1,c2,c3,c4,c5,c6) values(3,0.25, 0.99, 0.623, 0.21, 0.52, 0.66);\n",
    "\n",
    "select * from h2o_glrm;\n",
    "select * into ${data_and_preds} from h2o_glrm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "## GLRM Can act as both autoencoders in that they reconstruct data, and also perform PCA. In the database, we always do PCA (maybe something to change later)\n",
    "## For reconstruction, you call predict. I don't know how to get components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx\n",
    "data = beakerx.get('data_and_preds')\n",
    "\n",
    "features = h2o.H2OFrame(data[['C1','C2','C3','C4','C5','C6']])\n",
    "db_preds = data[['PC0','PC1','PC2','PC3','PC4','PC5']]\n",
    "\n",
    "# GLRM Can act as both autoencoders in that they reconstruct data, and also perform PCA. In the database, we always do PCA (maybe something to change later)\n",
    "# To get the PCA, you call proj_archetypes, for reconstruction, you call predict\n",
    "raw_preds = model.proj_archetypes(features).as_data_frame(use_pandas=True)\n",
    "\n",
    "\n",
    "for db_pred, raw_pred in zip(db_preds.iterrows(), raw_preds.iterrows()):\n",
    "    # Check reconstruction values\n",
    "    for db, raw in zip(db_pred[1], raw_pred[1]):\n",
    "        assert round(db,13) == round(raw,13), f'Something is wrong. Model Table gives {db} but raw model gives {raw}'\n",
    "\n",
    "print('test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLRM is weird because it can act as either Dim Reduction or an Autoencoder... Which should we pick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_path = model.download_mojo('/tmp/gbm.zip')\n",
    "\n",
    "\n",
    "from py4j.java_gateway import java_import\n",
    "java_import(splice.jvm, 'hex.genmodel.easy.EasyPredictModelWrapper')\n",
    "java_import(splice.jvm, 'hex.genmodel.MojoModel')\n",
    "java_import(splice.jvm, 'java.io.ByteArrayOutputStream')\n",
    "java_import(splice.jvm, 'java.io.ObjectOutputStream') \n",
    "java_import(splice.jvm, 'hex.genmodel.easy.RowData')\n",
    "java_import(splice.jvm, 'hex.genmodel.easy.prediction.DimReductionModelPrediction')\n",
    "\n",
    "\n",
    "java_mojo_c = splice.jvm.EasyPredictModelWrapper.Config().setModel(splice.jvm.MojoModel.load(pca_path))\n",
    "java_mojo = splice.jvm.EasyPredictModelWrapper(java_mojo_c)\n",
    "\n",
    "\n",
    "\n",
    "m = splice.jvm.MojoModel.load(pca_path)\n",
    "\n",
    "# java_mojo.predictDimReduction(train)\n",
    "\n",
    "\n",
    "print(java_mojo.getModelCategory().toString())\n",
    "\n",
    "\n",
    "row = splice.jvm.RowData()\n",
    "row.put(\"C1\", \"0\")\n",
    "row.put(\"C2\", \"0\")\n",
    "row.put(\"C3\", \"0\")\n",
    "row.put(\"C4\", \"0\")\n",
    "row.put(\"C5\", \"0\")\n",
    "row.put(\"C6\", \"0\")\n",
    "\n",
    "d = splice.jvm.DimReductionModelPrediction\n",
    "\n",
    "# pred = m.predictDimReduction(row)\n",
    "\n",
    "# list(java_mojo.predictDimReduction(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splicemachine.notebook import hide_toggle\n",
    "hide_toggle(toggle_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java\n",
    "%classpath add jar db-client-3.0.0.1950.jar\n",
    "%classpath add jar /home/jovyan/nn_model.jar\n",
    "import java.sql.*; \n",
    "import java.util.*; \n",
    "import hex.genmodel.easy.RowData;\n",
    "import hex.genmodel.easy.EasyPredictModelWrapper;\n",
    "import hex.genmodel.easy.prediction.*;\n",
    "import java.io.*;\n",
    "import hex.genmodel.MojoModel;\n",
    "import hex.genmodel.InMemoryMojoReaderBackend;\n",
    "import java.sql.Driver;  \n",
    "import com.splicemachine.db.jdbc.*;\n",
    "\n",
    "\n",
    "Driver d = new com.splicemachine.db.jdbc.ClientDriver();  \n",
    "DriverManager.registerDriver(d);\n",
    "Connection conn = DriverManager.getConnection(\"jdbc:splice://jdbc-test-aks-dev1.dev.splicemachine-dev.io:1527/splicedb;ssl=basic\",\"splice\",\"admin\");\n",
    "PreparedStatement pstmt = conn.prepareStatement(\"select \\\"binary\\\" from mlmanager.artifacts where RUN_UUID=? and NAME=?\");\n",
    "        pstmt.setString(1, \"6ba390856894\");\n",
    "        pstmt.setString(2,\"h2omojo\");\n",
    "        ResultSet rs = pstmt.executeQuery();\n",
    "        EasyPredictModelWrapper model = null;\n",
    "        if(rs.next()) {\n",
    "            Blob blobModel = rs.getBlob(1);\n",
    "            InputStream bis = blobModel.getBinaryStream();\n",
    "            ObjectInputStream ois = new ObjectInputStream(bis);\n",
    "            model = (EasyPredictModelWrapper) (ois.readObject());\n",
    "            ois.close();\n",
    "        }\n",
    "\n",
    "        \n",
    "\n",
    "RowData row = new RowData();\n",
    "\n",
    "row.put(\"SDSS_J\", \"000009.26+151754.5\");\n",
    "row.put(\"R.A.\", \"9.08519705868309\");\n",
    "row.put(\"Dec.\", \"4.932083187033184\");\n",
    "row.put(\"z\", \"7.139249327431729\");\n",
    "row.put(\"u_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_u\", \"7.139249327431729\");\n",
    "row.put(\"g_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_g\", \"7.139249327431729\");\n",
    "row.put(\"r_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_r\", \"7.139249327431729\");\n",
    "row.put(\"i_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_i\", \"7.139249327431729\");\n",
    "row.put(\"z_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_z\", \"7.139249327431729\");\n",
    "row.put(\"Radio\", \"7.139249327431729\");\n",
    "row.put(\"X-ray\", \"7.139249327431729\");\n",
    "row.put(\"J_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_J\", \"7.139249327431729\");\n",
    "row.put(\"H_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_H\", \"7.139249327431729\");\n",
    "row.put(\"K_mag\", \"7.139249327431729\");\n",
    "row.put(\"sig_K\", \"7.139249327431729\");\n",
    "row.put(\"M_i\", \"7.139249327431729\");\n",
    "\n",
    "\n",
    "AbstractPrediction p;\n",
    "p = model.predictDimReduction(row);\n",
    "\n",
    "final StringBuilder builder = new StringBuilder();\n",
    "//for(int i = 0; i < classProbs.length; i++){\n",
    "//    builder.append(i).append(\"=\").append(classProbs[i]).append(\";\");\n",
    "//}\n",
    "//return builder.substring(0, builder.length() - 1);\n",
    "//return c;\n",
    "\n",
    "final double[] dim = ((DimReductionModelPrediction) p).dimensions;\n",
    "//AutoEncoderModelPrediction\n",
    "\n",
    "\n",
    "//for(int i = 0; i < dim.length; i++){\n",
    "//    builder.append(\"PC\" + i).append(\"=\").append(Double.toString(dim[i])).append(\";\");\n",
    "//}\n",
    "\n",
    "return dim;\n",
    "//return builder.substring(0, builder.length() - 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TargetEncoder (BROKEN on Deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "titanic.rename(columns={'home.dest':'home_dest'})\n",
    "predictors = [\"home_dest\", \"cabin\", \"embarked\"]\n",
    "response = \"survived\"\n",
    "titanic[\"survived\"] = titanic[\"survived\"].asfactor()\n",
    "fold_col = \"kfold_column\"\n",
    "titanic[fold_col] = titanic.kfold_column(n_folds=5, seed=1234)\n",
    "model = H2OTargetEncoderEstimator(k=35,\n",
    "                                       f=25,\n",
    "                                       blending=True)\n",
    "model.train(x=predictors,\n",
    "                 y=response,\n",
    "                 training_frame=titanic)\n",
    "\n",
    "\n",
    "print('deploying target encoder')\n",
    "splice.dropTableIfExists('splice.te')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_model(model, 'model')\n",
    "    jid = mlflow.deploy_db('splice','te',mlflow.current_run_id(), df=hc.asSparkFrame(titanic).select(predictors), create_model_table=True, primary_key=[('MOMENT_KEY','INTEGER')])\n",
    "    mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into h2o_nn (displacement,power,weight,acceleration,year_make, moment_key) values(18,101,22,23.142,1,1 );\n",
    "insert into h2o_nn (displacement,power,weight,acceleration,year_make, moment_key) values(18,6,232,100,3,2);\n",
    "\n",
    "select * from h2o_nn;\n",
    "\n",
    "select displacement,power,weight,acceleration,year_make,prediction, c3,c4,c5,c6,c8 into ${data_and_preds} from h2o_nn;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "438.542px",
    "left": "10px",
    "top": "150px",
    "width": "194.219px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
